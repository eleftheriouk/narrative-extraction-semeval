{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "852c56be-3ebf-4f40-bf4e-53898a78ec63",
   "metadata": {},
   "source": [
    "# Semeval 2025 Task 10\n",
    "### Subtask 2: Narrative Classification\n",
    "\n",
    "Given a news article and a [two-level taxonomy of narrative labels](https://propaganda.math.unipd.it/semeval2025task10/NARRATIVE-TAXONOMIES.pdf) (where each narrative is subdivided into subnarratives) from a particular domain, assign to the article all the appropriate subnarrative labels. This is a multi-label multi-class document classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "865e2b23-473a-4597-b1e6-07f9188eb7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560c281b-63af-4939-b1f2-a1784c25263a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Setting random state\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "if random_state:\n",
    "    print('[WARNING] Setting random state')\n",
    "    torch.manual_seed(random_state)\n",
    "    np.random.seed(random_state) \n",
    "    random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03220268-ecc3-4bf0-a8fb-cdf6413a32c7",
   "metadata": {},
   "source": [
    "## Loss Weighting by Language\n",
    "\n",
    "As of now,  we trained a model in 5 different languages just so that we can face the problem of having limited data. Our final submission is going to be in one of those languages. \n",
    "This is our current target right now, to make our model somewhat focus on a specified language.\n",
    "\n",
    "One way to account for that is to add an extra penalty in our current loss. We know the language of each training sample, so we can double or triple the loss for that sample, in a way to tell the model to pay more attention to it.\n",
    "\n",
    "This can help improve performance in a target language, especially when having limited data.\n",
    "\n",
    "We will demo this, specifically for English data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0c0bbce-4fbd-4523-9d4d-ef46b14fef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_save_folder_dir = '../../saved/'\n",
    "dataset_folder = os.path.join(base_save_folder_dir, 'Dataset')\n",
    "\n",
    "with open(os.path.join(dataset_folder, 'dataset_train_cleaned.pkl'), 'rb') as f:\n",
    "    dataset_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b419f7b3-706c-44e4-b9ee-20e72537b577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "      <th>narratives</th>\n",
       "      <th>subnarratives</th>\n",
       "      <th>narratives_encoded</th>\n",
       "      <th>subnarratives_encoded</th>\n",
       "      <th>aggregated_subnarratives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1161.txt</td>\n",
       "      <td>&lt;PARA&gt;в ближайшие два месяца сша будут стремит...</td>\n",
       "      <td>[URW: Blaming the war on others rather than th...</td>\n",
       "      <td>[The West are the aggressors, Other, The West ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 1, 0], [0, 1, 0], [0, 0, 0, 1], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1175.txt</td>\n",
       "      <td>&lt;PARA&gt;в ес испугались последствий популярности...</td>\n",
       "      <td>[URW: Discrediting the West, Diplomacy, URW: D...</td>\n",
       "      <td>[The West is weak, Other, The EU is divided]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 1, 0], [0, 1, 0], [0, 0, 0, 1], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1149.txt</td>\n",
       "      <td>&lt;PARA&gt;возможность признания аллы пугачевой ино...</td>\n",
       "      <td>[URW: Distrust towards Media]</td>\n",
       "      <td>[Western media is an instrument of propaganda]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1015.txt</td>\n",
       "      <td>&lt;PARA&gt;азаров рассказал о смене риторики киева ...</td>\n",
       "      <td>[URW: Discrediting Ukraine, URW: Discrediting ...</td>\n",
       "      <td>[Ukraine is a puppet of the West, Discrediting...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1001.txt</td>\n",
       "      <td>&lt;PARA&gt;в россиянах проснулась массовая любовь к...</td>\n",
       "      <td>[URW: Praise of Russia]</td>\n",
       "      <td>[Russia is a guarantor of peace and prosperity]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language       article_id  \\\n",
       "0       RU  RU-URW-1161.txt   \n",
       "1       RU  RU-URW-1175.txt   \n",
       "2       RU  RU-URW-1149.txt   \n",
       "3       RU  RU-URW-1015.txt   \n",
       "4       RU  RU-URW-1001.txt   \n",
       "\n",
       "                                             content  \\\n",
       "0  <PARA>в ближайшие два месяца сша будут стремит...   \n",
       "1  <PARA>в ес испугались последствий популярности...   \n",
       "2  <PARA>возможность признания аллы пугачевой ино...   \n",
       "3  <PARA>азаров рассказал о смене риторики киева ...   \n",
       "4  <PARA>в россиянах проснулась массовая любовь к...   \n",
       "\n",
       "                                          narratives  \\\n",
       "0  [URW: Blaming the war on others rather than th...   \n",
       "1  [URW: Discrediting the West, Diplomacy, URW: D...   \n",
       "2                      [URW: Distrust towards Media]   \n",
       "3  [URW: Discrediting Ukraine, URW: Discrediting ...   \n",
       "4                            [URW: Praise of Russia]   \n",
       "\n",
       "                                       subnarratives  \\\n",
       "0  [The West are the aggressors, Other, The West ...   \n",
       "1       [The West is weak, Other, The EU is divided]   \n",
       "2     [Western media is an instrument of propaganda]   \n",
       "3  [Ukraine is a puppet of the West, Discrediting...   \n",
       "4    [Russia is a guarantor of peace and prosperity]   \n",
       "\n",
       "                                  narratives_encoded  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                               subnarratives_encoded  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                            aggregated_subnarratives  \n",
       "0  [[0, 0, 0, 1, 0], [0, 1, 0], [0, 0, 0, 1], [0,...  \n",
       "1  [[0, 0, 0, 1, 0], [0, 1, 0], [0, 0, 0, 1], [0,...  \n",
       "2  [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...  \n",
       "3  [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...  \n",
       "4  [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b611b9-f983-4724-9d7d-d46ff3688713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1781, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd076469-7d41-447d-8b2a-01ffc403b0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "BG    401\n",
       "PT    400\n",
       "EN    399\n",
       "HI    366\n",
       "RU    215\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91929ad6-26e8-4adb-b814-d2f7b5653a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "misc_folder = os.path.join(base_save_folder_dir, 'Misc')\n",
    "\n",
    "with open(os.path.join(misc_folder, 'narrative_to_subnarratives.pkl'), 'rb') as f:\n",
    "    narrative_to_subnarratives = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2c80ede-623e-4e21-8f75-fc02e337c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(misc_folder, 'narrative_to_subnarratives_map.pkl'), 'rb') as f:\n",
    "    narrative_to_sub_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff0e6b0b-d49e-4211-8bba-bbf58516a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(misc_folder, 'coarse_classes.pkl'), 'rb') as f:\n",
    "    coarse_classes = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(misc_folder, 'fine_classes.pkl'), 'rb') as f:\n",
    "    fine_classes = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(misc_folder, 'narrative_order.pkl'), 'rb') as f:\n",
    "    narrative_order = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6bc9d85-cdc2-4520-9c2b-ac8dc9213849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'URW: Discrediting Ukraine': ['Ukraine is a puppet of the West',\n",
       "  'Rewriting Ukraine’s history',\n",
       "  'Ukraine is a hub for criminal activities',\n",
       "  'Discrediting Ukrainian nation and society',\n",
       "  'Discrediting Ukrainian government and officials and policies',\n",
       "  'Discrediting Ukrainian military',\n",
       "  'Other',\n",
       "  'Situation in Ukraine is hopeless',\n",
       "  'Ukraine is associated with nazism'],\n",
       " 'URW: Discrediting the West, Diplomacy': ['West is tired of Ukraine',\n",
       "  'Diplomacy does/will not work',\n",
       "  'The West is weak',\n",
       "  'The EU is divided',\n",
       "  'The West does not care about Ukraine, only about its interests',\n",
       "  'Other',\n",
       "  'The West is overreacting'],\n",
       " 'URW: Praise of Russia': ['Russia has international support from a number of countries and people',\n",
       "  'Praise of Russian military might',\n",
       "  'Russia is a guarantor of peace and prosperity',\n",
       "  'Other',\n",
       "  'Praise of Russian President Vladimir Putin',\n",
       "  'Russian invasion has strong national support'],\n",
       " 'URW: Russia is the Victim': ['The West is russophobic',\n",
       "  'UA is anti-RU extremists',\n",
       "  'Other',\n",
       "  'Russia actions in Ukraine are only self-defence'],\n",
       " 'URW: Distrust towards Media': ['Western media is an instrument of propaganda',\n",
       "  'Ukrainian media cannot be trusted',\n",
       "  'Other'],\n",
       " 'URW: Amplifying war-related fears': ['By continuing the war we risk WWIII',\n",
       "  'There is a real possibility that nuclear weapons will be employed',\n",
       "  'Russia will also attack other countries',\n",
       "  'Other',\n",
       "  'NATO should/will directly intervene'],\n",
       " 'URW: Blaming the war on others rather than the invader': ['Ukraine is the aggressor',\n",
       "  'The West are the aggressors',\n",
       "  'Other'],\n",
       " 'URW: Overpraising the West': ['The West belongs in the right side of history',\n",
       "  'NATO will destroy Russia',\n",
       "  'Other',\n",
       "  'The West has the strongest international support'],\n",
       " 'URW: Speculating war outcomes': ['Other',\n",
       "  'Ukrainian army is collapsing',\n",
       "  'Russian army is collapsing',\n",
       "  'Russian army will lose all the occupied territories'],\n",
       " 'URW: Hidden plots by secret schemes of powerful groups': ['Other'],\n",
       " 'Other': ['Other'],\n",
       " 'URW: Negative Consequences for the West': ['The conflict will increase the Ukrainian refugee flows to Europe',\n",
       "  'Sanctions imposed by Western countries will backfire',\n",
       "  'Other'],\n",
       " 'CC: Amplifying Climate Fears': ['Doomsday scenarios for humans',\n",
       "  'Whatever we do it is already too late',\n",
       "  'Amplifying existing fears of global warming',\n",
       "  'Other',\n",
       "  'Earth will be uninhabitable soon'],\n",
       " 'CC: Criticism of institutions and authorities': ['Criticism of national governments',\n",
       "  'Other',\n",
       "  'Criticism of political organizations and figures',\n",
       "  'Criticism of international entities',\n",
       "  'Criticism of the EU'],\n",
       " 'CC: Criticism of climate movement': ['Ad hominem attacks on key activists',\n",
       "  'Climate movement is corrupt',\n",
       "  'Other',\n",
       "  'Climate movement is alarmist'],\n",
       " 'CC: Downplaying climate change': ['Ice is not melting',\n",
       "  'Weather suggests the trend is global cooling',\n",
       "  'Temperature increase does not have significant impact',\n",
       "  'Humans and nature will adapt to the changes',\n",
       "  'Sea levels are not rising',\n",
       "  'Other',\n",
       "  'CO2 concentrations are too small to have an impact',\n",
       "  'Human activities do not impact climate change',\n",
       "  'Climate cycles are natural'],\n",
       " 'CC: Criticism of climate policies': ['Climate policies are only for profit',\n",
       "  'Climate policies are ineffective',\n",
       "  'Other',\n",
       "  'Climate policies have negative impact on the economy'],\n",
       " 'CC: Questioning the measurements and science': ['Data shows no temperature increase',\n",
       "  'Scientific community is unreliable',\n",
       "  'Methodologies/metrics used are unreliable/faulty',\n",
       "  'Greenhouse effect/carbon dioxide do not drive climate change',\n",
       "  'Other'],\n",
       " 'CC: Hidden plots by secret schemes of powerful groups': ['Blaming global elites',\n",
       "  'Climate agenda has hidden motives',\n",
       "  'Other'],\n",
       " 'CC: Climate change is beneficial': ['Temperature increase is beneficial',\n",
       "  'Other',\n",
       "  'CO2 is beneficial'],\n",
       " 'CC: Controversy about green technologies': ['Renewable energy is costly',\n",
       "  'Renewable energy is dangerous',\n",
       "  'Renewable energy is unreliable',\n",
       "  'Other'],\n",
       " 'CC: Green policies are geopolitical instruments': ['Climate-related international relations are abusive/exploitative',\n",
       "  'Green activities are a form of neo-colonialism',\n",
       "  'Other']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narrative_to_subnarratives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "024abfe7-45eb-49d5-82d7-5d19262c1b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_folder = os.path.join(base_save_folder_dir, 'LabelEncoders')\n",
    "\n",
    "with open(os.path.join(label_encoder_folder, 'mlb_narratives.pkl'), 'rb') as f:\n",
    "    mlb_narratives = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(label_encoder_folder, 'mlb_subnarratives.pkl'), 'rb') as f:\n",
    "    mlb_subnarratives = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ed1cc-3faf-4fbe-bc62-912ad4e29a46",
   "metadata": {},
   "source": [
    "We will be using `KaLM` embeddings, as they have proved quite better than `Stella`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df5a3905-3ebe-4e0f-82de-b86ef2b1494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings_folder = os.path.join(base_save_folder_dir, 'Embeddings/embeddings_train_kalm.npy')\n",
    "\n",
    "def load_embeddings(filename):\n",
    "    return np.load(filename)\n",
    "\n",
    "train_embeddings = load_embeddings(embeddings_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a34d7b4f-af40-48e9-bed1-87c97b8a0a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dataset_folder, 'dataset_val_cleaned.pkl'), 'rb') as f:\n",
    "    dataset_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54f91fbc-c03c-41df-a9de-97e28e1f9ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_folder = os.path.join(base_save_folder_dir, 'Embeddings/embeddings_val_kalm.npy')\n",
    "\n",
    "val_embeddings = load_embeddings(embeddings_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "721ab153-b4d6-4dba-970d-66b1136f18c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset_and_embeddings(dataset, embeddings, condition_fn):\n",
    "    filtered_indices = dataset.index[dataset.apply(condition_fn, axis=1)].tolist()\n",
    "    \n",
    "    filtered_dataset = dataset.loc[filtered_indices]\n",
    "    filtered_embeddings = embeddings[filtered_indices]\n",
    "\n",
    "    return filtered_dataset, filtered_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8901a79f-c8ed-4dee-87f6-6042cb8f9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val, val_embeddings = filter_dataset_and_embeddings(\n",
    "    dataset_val,\n",
    "    val_embeddings, \n",
    "    lambda row: row[\"language\"] == \"EN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cea1329-20c0-4c3e-ba13-1a8e02bf7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def custom_shuffling(data, embeddings):\n",
    "    shuffled_indices = np.arange(len(data))\n",
    "    np.random.shuffle(shuffled_indices)\n",
    "    \n",
    "    data = data.iloc[shuffled_indices].reset_index(drop=True)\n",
    "    embeddings = embeddings[shuffled_indices]\n",
    "\n",
    "    return data, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f9468f4-4223-4b51-896c-5d43b23d3bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, train_embeddings = custom_shuffling(dataset_train, train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e39118c-3fb5-4f06-8809-520391c012f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val, val_embeddings = custom_shuffling(dataset_val, val_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "020b2582-5702-44ae-9731-3dd5cbbee0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "misc_folder = os.path.join(base_save_folder_dir, 'Misc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb9a13a1-917f-47ca-b979-d21b3b7bf855",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sub_heads = dataset_train['aggregated_subnarratives'].to_numpy()\n",
    "y_val_sub_heads = dataset_val['aggregated_subnarratives'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48d6cab6-b1bc-41ed-9740-04d4d7d2efe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "prefer_cpu=True\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available() and not prefer_cpu\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e69f8235-7d2f-475e-9876-5166a3ced91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_tensor = torch.tensor(train_embeddings, dtype=torch.float32).to(device)\n",
    "val_embeddings_tensor = torch.tensor(val_embeddings, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "410f575d-85e8-4d53-ba94-6b7e48b8a556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896\n"
     ]
    }
   ],
   "source": [
    "input_size = train_embeddings_tensor.shape[1]\n",
    "print(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63fa1546-578e-49a2-ac03-2b06c1d2fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_params = {\n",
    "    'lr': 0.001,\n",
    "    'hidden_size': 1024,\n",
    "    'dropout': 0.4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7664898e-69c8-4f74-99f3-9fabf247a671",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_nar = dataset_train['narratives_encoded'].tolist()\n",
    "y_val_nar = dataset_val['narratives_encoded'].tolist()\n",
    "\n",
    "y_train_sub_nar = dataset_train['subnarratives_encoded'].tolist()\n",
    "y_val_sub_nar = dataset_val['subnarratives_encoded'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74494f26-ae72-4a72-9ec9-bfab3d9b67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_nar = torch.tensor(y_train_nar, dtype=torch.float32).to(device)\n",
    "y_train_sub_nar = torch.tensor(y_train_sub_nar, dtype=torch.float32).to(device)\n",
    "\n",
    "y_val_nar = torch.tensor(y_val_nar, dtype=torch.float32).to(device)\n",
    "y_val_sub_nar = torch.tensor(y_val_sub_nar, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46fcaf5e-dee1-488d-8c79-f7c2f3d618bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_tensor = torch.tensor(train_embeddings, dtype=torch.float32).to(device)\n",
    "val_embeddings_tensor = torch.tensor(val_embeddings, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89bc1f13-5799-400f-b126-5cfe6fdc4375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def compute_class_weights(y_train):\n",
    "    total_samples = y_train.shape[0]\n",
    "    class_weights = []\n",
    "    for label in range(y_train.shape[1]):\n",
    "        pos_count = y_train[:, label].sum().item()\n",
    "        neg_count = total_samples - pos_count\n",
    "        pos_weight = total_samples / (2 * pos_count) if pos_count > 0 else 0\n",
    "        neg_weight = total_samples / (2 * neg_count) if neg_count > 0 else 0\n",
    "        class_weights.append((pos_weight, neg_weight))\n",
    "    return class_weights\n",
    "\n",
    "class WeightedBCELoss(nn.Module):\n",
    "    def __init__(self, class_weights):\n",
    "        super().__init__()\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def forward(self, probs, targets):\n",
    "        bce_loss = 0\n",
    "        epsilon = 1e-7\n",
    "        for i, (pos_weight, neg_weight) in enumerate(self.class_weights):\n",
    "            prob = probs[:, i]\n",
    "            bce = -pos_weight * targets[:, i] * torch.log(prob + epsilon) - \\\n",
    "                  neg_weight * (1 - targets[:, i]) * torch.log(1 - prob + epsilon)\n",
    "            bce_loss += bce.mean()\n",
    "        return bce_loss / len(self.class_weights)\n",
    "\n",
    "class_weights_sub_nar = compute_class_weights(y_train_sub_nar)\n",
    "class_weights_nar = compute_class_weights(y_train_nar)\n",
    "narrative_criterion = WeightedBCELoss(class_weights_nar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc839d6b-f588-436a-b5f0-464093ce986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_criterion_dict = {}\n",
    "\n",
    "for narr_idx, sub_indices in narrative_to_sub_map.items():\n",
    "    local_weights = [ class_weights_sub_nar[sub_i] for sub_i in sub_indices ]\n",
    "\n",
    "    sub_criterion = WeightedBCELoss(local_weights)\n",
    "    sub_criterion_dict[str(narr_idx)] = sub_criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494c44cc-cfb6-4c8f-80fe-df360cf0a659",
   "metadata": {},
   "source": [
    "We will also select the MultiHeadConcat Model, since this is the one appearing to do the best for our Fine-F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e92f161-370b-409e-bea0-4dc59a28d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskClassifierMultiHeadConcat(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_narratives=len(mlb_narratives.classes_),\n",
    "        narrative_to_sub_map=narrative_to_sub_map,\n",
    "        dropout_rate=network_params['dropout']\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.shared_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size * 2),\n",
    "            nn.BatchNorm1d(hidden_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        self.narrative_head = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, num_narratives),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.subnarrative_heads = nn.ModuleDict()\n",
    "        for narr_idx, sub_indices in narrative_to_sub_map.items():\n",
    "            num_subs_for_this_narr = len(sub_indices)\n",
    "            self.subnarrative_heads[str(narr_idx)] = nn.Sequential(\n",
    "                nn.Linear(hidden_size * 2 + 1, num_subs_for_this_narr),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_out = self.shared_layer(x)\n",
    "\n",
    "        narr_probs = self.narrative_head(shared_out)\n",
    "\n",
    "        sub_probs_dict = {}\n",
    "        for narr_idx, head in self.subnarrative_heads.items():\n",
    "            conditioned_input = torch.cat((shared_out, narr_probs[:, int(narr_idx)].unsqueeze(1)), dim=1)\n",
    "            sub_probs_dict[narr_idx] = head(conditioned_input)\n",
    "\n",
    "        return narr_probs, sub_probs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50b83196-b7fc-46ce-9e90-3cad23e1bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiTaskClassifierMultiHeadConcat(\n",
    "    input_size=input_size,\n",
    "    hidden_size=2048\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860b7fae-61f0-4068-9c91-9f12b2db37a2",
   "metadata": {},
   "source": [
    "We keep the original version of our loss for comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7c3d062-0729-47c5-9d6e-a177659e49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadLoss(nn.Module):\n",
    "    def __init__(self, narrative_criterion, sub_criterion_dict, \n",
    "                 condition_weight=0.3, sub_weight=0.3):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.narrative_criterion = narrative_criterion\n",
    "        self.sub_criterion_dict = sub_criterion_dict\n",
    "        self.condition_weight = condition_weight\n",
    "        self.sub_weight = sub_weight\n",
    "        \n",
    "    def forward(self, narr_probs, sub_probs_dict, y_narr, y_sub_heads):\n",
    "        narr_loss = self.narrative_criterion(narr_probs, y_narr)\n",
    "        sub_loss = 0.0\n",
    "        condition_loss = 0.0\n",
    "        \n",
    "        for narr_idx_str, sub_probs in sub_probs_dict.items():\n",
    "            narr_idx = int(narr_idx_str)\n",
    "            y_sub = [row[narr_idx] for row in y_sub_heads]\n",
    "            y_sub_tensor = torch.tensor(y_sub, dtype=torch.float32, device=sub_probs.device)\n",
    "            \n",
    "            sub_loss_func = self.sub_criterion_dict[narr_idx_str]\n",
    "            sub_loss += sub_loss_func(sub_probs, y_sub_tensor)\n",
    "\n",
    "            narr_pred = narr_probs[:, narr_idx].unsqueeze(1)\n",
    "            condition_term = torch.mean(\n",
    "                # Penalize high probs of sub, based on first level narr predictinos\n",
    "                torch.abs(sub_probs * (1 - narr_pred)) + \n",
    "                # If a narrative is true, then the subnarrative predictions should match their actual true values.\n",
    "                narr_pred * torch.abs(sub_probs - y_sub_tensor.unsqueeze(1))\n",
    "            )\n",
    "            condition_loss += condition_term\n",
    "            \n",
    "        sub_loss = sub_loss / len(sub_probs_dict)\n",
    "        condition_loss = condition_loss / len(sub_probs_dict)\n",
    "        \n",
    "        total_loss = (1 - self.sub_weight) * narr_loss + \\\n",
    "                    self.sub_weight * sub_loss + \\\n",
    "                    self.condition_weight * condition_loss\n",
    "        \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3a4e282-63a9-4321-8c23-dccb7b8f3293",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_head_loss_fn = MultiHeadLoss(narrative_criterion, sub_criterion_dict).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615aed4d-898f-43e7-a100-e8e6198c9add",
   "metadata": {},
   "source": [
    "We add the extra penalty for english samples\n",
    "\n",
    "* In the forwarding step, we check if the sample is an english one, and if it is we apply the extra weight upon the loss to essentially tell them model to pay more attention to those samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db85e674-51d2-4c47-9983-41410a48e2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageAwareMultiHeadLoss(nn.Module):\n",
    "    def __init__(self, narrative_criterion, sub_criterion_dict, \n",
    "                 condition_weight=0.3, sub_weight=0.3,\n",
    "                 english_weight=3.0):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.narrative_criterion = narrative_criterion\n",
    "        self.sub_criterion_dict = sub_criterion_dict\n",
    "        self.condition_weight = condition_weight\n",
    "        self.sub_weight = sub_weight\n",
    "        self.english_weight = english_weight\n",
    "\n",
    "    def forward(self, narr_probs, sub_probs_dict, y_narr, y_sub_heads, is_english):\n",
    "        is_english = is_english.to(narr_probs.device)\n",
    "        sample_weights = torch.where(is_english == 1, self.english_weight, 1.0)\n",
    "\n",
    "        narr_loss = self.narrative_criterion(narr_probs, y_narr)\n",
    "\n",
    "        sub_loss = 0.0\n",
    "        condition_loss = 0.0\n",
    "\n",
    "        for narr_idx_str, sub_probs in sub_probs_dict.items():\n",
    "            narr_idx = int(narr_idx_str)\n",
    "            y_sub = [row[narr_idx] for row in y_sub_heads]\n",
    "            y_sub_tensor = torch.tensor(y_sub, dtype=torch.float32, device=sub_probs.device)\n",
    "            sub_loss_func = self.sub_criterion_dict[narr_idx_str]\n",
    "            sub_batch_loss = sub_loss_func(sub_probs, y_sub_tensor)\n",
    "            sub_loss += sub_batch_loss.mean()\n",
    "\n",
    "            narr_pred = narr_probs[:, narr_idx].unsqueeze(1)\n",
    "            condition_term = torch.abs(sub_probs * (1 - narr_pred)) + \\\n",
    "                             narr_pred * torch.abs(sub_probs - y_sub_tensor.unsqueeze(1))\n",
    "            condition_loss += condition_term.mean()\n",
    "\n",
    "        sub_loss = sub_loss / len(sub_probs_dict)\n",
    "        condition_loss = condition_loss / len(sub_probs_dict)\n",
    "\n",
    "        total_loss = (1 - self.sub_weight) * narr_loss + self.sub_weight * sub_loss + \\\n",
    "                     self.condition_weight * condition_loss\n",
    "\n",
    "        total_loss = (total_loss * sample_weights).mean()\n",
    "\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f8b9c35-d86e-4a69-8bc1-616c9f9406dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_multihead(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    is_english_train, \n",
    "    train_embeddings=train_embeddings_tensor,\n",
    "    y_train_nar=y_train_nar,\n",
    "    y_train_sub_heads=y_train_sub_heads,\n",
    "    val_embeddings=val_embeddings_tensor,\n",
    "    y_val_nar=y_val_nar,\n",
    "    y_val_sub_heads=y_val_sub_heads,\n",
    "    patience=10,\n",
    "    num_epochs=100,\n",
    "    scheduler=None,\n",
    "    min_delta=0.001\n",
    "):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_narr_probs, train_sub_probs_dict = model(train_embeddings)\n",
    "        if is_english_train != None:\n",
    "            train_loss = loss_fn(\n",
    "                train_narr_probs, \n",
    "                train_sub_probs_dict, \n",
    "                y_train_nar, \n",
    "                y_train_sub_heads,\n",
    "                is_english_train\n",
    "            )\n",
    "        else:\n",
    "            train_loss = loss_fn(\n",
    "                train_narr_probs, \n",
    "                train_sub_probs_dict, \n",
    "                y_train_nar, \n",
    "                y_train_sub_heads,\n",
    "            )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_narr_probs, val_sub_probs_dict = model(val_embeddings)\n",
    "            if is_english_train != None:\n",
    "                is_english_val = torch.ones(len(val_embeddings), device=val_embeddings.device)\n",
    "                val_loss = loss_fn(\n",
    "                    val_narr_probs, \n",
    "                    val_sub_probs_dict, \n",
    "                    y_val_nar, \n",
    "                    y_val_sub_heads,\n",
    "                    is_english_val\n",
    "                )\n",
    "            else:\n",
    "                val_loss = loss_fn(\n",
    "                    val_narr_probs, \n",
    "                    val_sub_probs_dict, \n",
    "                    y_val_nar, \n",
    "                    y_val_sub_heads,\n",
    "                )\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "              f\"Training Loss: {train_loss.item():.4f}, \"\n",
    "              f\"Validation Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "            current_lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "            print(f\"Current Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "        if val_loss.item() < best_val_loss - min_delta:\n",
    "            best_val_loss = val_loss.item()\n",
    "            patience_counter = 0\n",
    "            best_model = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Validation loss did not significantly improve for {patience_counter} epoch(s).\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    if best_model:\n",
    "        model.load_state_dict(best_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f52b84b-04bf-411b-9835-59e027f833e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "def initialize_and_train_model(\n",
    "    model,\n",
    "    loss_fn,\n",
    "    num_epochs=100,\n",
    "    lr=0.001,\n",
    "    patience=10,\n",
    "    use_scheduler=True,\n",
    "    scheduler_patience=3,\n",
    "    num_subnarratives=len(mlb_subnarratives.classes_),\n",
    "    device=device,\n",
    "    is_english=None,\n",
    "):\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    scheduler = None\n",
    "    if use_scheduler:\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=scheduler_patience)\n",
    "\n",
    "    trained_model = train_with_multihead(\n",
    "                                    model=model,\n",
    "                                    is_english_train=is_english,\n",
    "                                    optimizer=optimizer,\n",
    "                                    scheduler=scheduler,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    patience=patience\n",
    "                                ).to(device)\n",
    "    return trained_model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87eff7a5-59f7-4d8e-9d82-5adae872b486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.8769, Validation Loss: 1.2969\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 2/100, Training Loss: 0.6681, Validation Loss: 1.2949\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 3/100, Training Loss: 0.5355, Validation Loss: 1.2989\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 4/100, Training Loss: 0.4615, Validation Loss: 1.3020\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 5/100, Training Loss: 0.4236, Validation Loss: 1.2962\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 6/100, Training Loss: 0.3958, Validation Loss: 1.2847\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 7/100, Training Loss: 0.3735, Validation Loss: 1.2736\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 8/100, Training Loss: 0.3536, Validation Loss: 1.2650\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 9/100, Training Loss: 0.3382, Validation Loss: 1.2618\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 10/100, Training Loss: 0.3249, Validation Loss: 1.2648\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 11/100, Training Loss: 0.3113, Validation Loss: 1.2710\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 12/100, Training Loss: 0.3020, Validation Loss: 1.2771\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 13/100, Training Loss: 0.2934, Validation Loss: 1.2806\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Epoch 14/100, Training Loss: 0.2839, Validation Loss: 1.2737\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Epoch 15/100, Training Loss: 0.2795, Validation Loss: 1.2644\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Epoch 16/100, Training Loss: 0.2742, Validation Loss: 1.2540\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 17/100, Training Loss: 0.2686, Validation Loss: 1.2428\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 18/100, Training Loss: 0.2634, Validation Loss: 1.2316\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 19/100, Training Loss: 0.2594, Validation Loss: 1.2225\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 20/100, Training Loss: 0.2541, Validation Loss: 1.2163\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 21/100, Training Loss: 0.2513, Validation Loss: 1.2119\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 22/100, Training Loss: 0.2476, Validation Loss: 1.2092\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 23/100, Training Loss: 0.2430, Validation Loss: 1.2084\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 24/100, Training Loss: 0.2395, Validation Loss: 1.2092\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 25/100, Training Loss: 0.2353, Validation Loss: 1.2109\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 26/100, Training Loss: 0.2318, Validation Loss: 1.2136\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Epoch 27/100, Training Loss: 0.2275, Validation Loss: 1.2164\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Epoch 28/100, Training Loss: 0.2244, Validation Loss: 1.2151\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Epoch 29/100, Training Loss: 0.2224, Validation Loss: 1.2142\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Epoch 30/100, Training Loss: 0.2204, Validation Loss: 1.2140\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Epoch 31/100, Training Loss: 0.2184, Validation Loss: 1.2146\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Epoch 32/100, Training Loss: 0.2172, Validation Loss: 1.2143\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "trained_model, _, _ = initialize_and_train_model(\n",
    "    model,\n",
    "    loss_fn=multi_head_loss_fn,\n",
    "    patience=10,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "550fa66e-d415-461d-9377-df45a0cbdf2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC: Amplifying Climate Fears',\n",
       " 'CC: Climate change is beneficial',\n",
       " 'CC: Controversy about green technologies',\n",
       " 'CC: Criticism of climate movement',\n",
       " 'CC: Criticism of climate policies',\n",
       " 'CC: Criticism of institutions and authorities',\n",
       " 'CC: Downplaying climate change',\n",
       " 'CC: Green policies are geopolitical instruments',\n",
       " 'CC: Hidden plots by secret schemes of powerful groups',\n",
       " 'CC: Questioning the measurements and science',\n",
       " 'Other',\n",
       " 'URW: Amplifying war-related fears',\n",
       " 'URW: Blaming the war on others rather than the invader',\n",
       " 'URW: Discrediting Ukraine',\n",
       " 'URW: Discrediting the West, Diplomacy',\n",
       " 'URW: Distrust towards Media',\n",
       " 'URW: Hidden plots by secret schemes of powerful groups',\n",
       " 'URW: Negative Consequences for the West',\n",
       " 'URW: Overpraising the West',\n",
       " 'URW: Praise of Russia',\n",
       " 'URW: Russia is the Victim',\n",
       " 'URW: Speculating war outcomes']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "435caf0b-cbbe-4130-8782-28a408d3c9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC: Amplifying Climate Fears: Amplifying existing fears of global warming',\n",
       " 'CC: Amplifying Climate Fears: Doomsday scenarios for humans',\n",
       " 'CC: Amplifying Climate Fears: Earth will be uninhabitable soon',\n",
       " 'CC: Amplifying Climate Fears: Other',\n",
       " 'CC: Amplifying Climate Fears: Whatever we do it is already too late',\n",
       " 'CC: Climate change is beneficial: CO2 is beneficial',\n",
       " 'CC: Climate change is beneficial: Other',\n",
       " 'CC: Climate change is beneficial: Temperature increase is beneficial',\n",
       " 'CC: Controversy about green technologies: Other',\n",
       " 'CC: Controversy about green technologies: Renewable energy is costly',\n",
       " 'CC: Controversy about green technologies: Renewable energy is dangerous',\n",
       " 'CC: Controversy about green technologies: Renewable energy is unreliable',\n",
       " 'CC: Criticism of climate movement: Ad hominem attacks on key activists',\n",
       " 'CC: Criticism of climate movement: Climate movement is alarmist',\n",
       " 'CC: Criticism of climate movement: Climate movement is corrupt']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_classes[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "087519a2-98bb-425b-b836-8b093854684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn import metrics\n",
    "\n",
    "class MultiHeadEvaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        classes_coarse=coarse_classes,\n",
    "        classes_fine=fine_classes,\n",
    "        narrative_to_sub_map=narrative_to_sub_map,\n",
    "        narrative_order=narrative_order,\n",
    "        narrative_classes=mlb_narratives.classes_,\n",
    "        subnarrative_classes=mlb_subnarratives.classes_,\n",
    "        device='cpu',\n",
    "        output_dir='../../../submissions',\n",
    "    ):\n",
    "        self.narrative_to_sub_map = narrative_to_sub_map\n",
    "        self.narrative_order = narrative_order\n",
    "        self.narrative_classes = list(narrative_classes)\n",
    "        self.subnarrative_classes = list(subnarrative_classes)\n",
    "        \n",
    "        self.classes_coarse = classes_coarse\n",
    "        self.classes_fine = classes_fine\n",
    "\n",
    "        self.device = device\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    def evaluate(\n",
    "        self,\n",
    "        model,\n",
    "        embeddings=val_embeddings_tensor,\n",
    "        dataset=dataset_val,\n",
    "        thresholds=None,\n",
    "        save=False,\n",
    "        std_weight=0.4,\n",
    "        lower_thres=0.1,\n",
    "        upper_thres=0.60\n",
    "    ):\n",
    "        if thresholds is None:\n",
    "            thresholds = np.arange(lower_thres, upper_thres, 0.05)    \n",
    "        embeddings = embeddings.to(self.device)\n",
    "    \n",
    "        best_results = {\n",
    "            'best_coarse_f1': -1,\n",
    "            'best_coarse_std': float('inf'),\n",
    "            'best_fine_f1': -1,\n",
    "            'best_fine_std': float('inf'),\n",
    "            'narr_threshold': 0,\n",
    "            'sub_threshold': 0,\n",
    "            'predictions': None,\n",
    "            'best_combined_score': -float('inf'),\n",
    "            'coarse_classification_report': None,\n",
    "            'fine_precision': None,\n",
    "            'fine_recall': None,\n",
    "            'samples_f1_fine': None,\n",
    "        }\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            narr_probs, sub_probs_dict = model(embeddings)\n",
    "            narr_probs = narr_probs.cpu().numpy()\n",
    "            sub_probs_dict = {k: v.cpu().numpy() for k, v in sub_probs_dict.items()}\n",
    "    \n",
    "        for narr_threshold in thresholds:\n",
    "            for sub_threshold in thresholds:\n",
    "                predictions = []\n",
    "                for sample_idx, row in dataset.iterrows():\n",
    "                    pred = self._make_prediction(\n",
    "                        row['article_id'],\n",
    "                        sample_idx,\n",
    "                        narr_probs,\n",
    "                        sub_probs_dict,\n",
    "                        narr_threshold,\n",
    "                        sub_threshold\n",
    "                    )\n",
    "                    predictions.append(pred)\n",
    "                \n",
    "                f1_coarse_mean, coarse_std, f1_fine_mean, fine_std, report_coarse, precision_fine, recall_fine, samples_f1_fine = self._compute_metrics_coarse_fine(predictions, dataset)\n",
    "                \n",
    "                combined_score = f1_fine_mean - (std_weight * coarse_std)\n",
    "                \n",
    "                if combined_score > best_results['best_combined_score']:\n",
    "                    best_results.update({\n",
    "                        'best_coarse_f1': f1_coarse_mean,\n",
    "                        'best_coarse_std': coarse_std,\n",
    "                        'best_fine_f1': f1_fine_mean,\n",
    "                        'best_fine_std': fine_std,\n",
    "                        'narr_threshold': narr_threshold,\n",
    "                        'sub_threshold': sub_threshold,\n",
    "                        'predictions': predictions,\n",
    "                        'best_combined_score': combined_score,\n",
    "                        'coarse_classification_report': report_coarse,\n",
    "                        'fine_precision': precision_fine,\n",
    "                        'fine_recall': recall_fine,\n",
    "                        'samples_f1_fine': samples_f1_fine,\n",
    "                    })\n",
    "    \n",
    "        print(\"\\nBest thresholds found:\")\n",
    "        print(f\"Narrative threshold: {best_results['narr_threshold']:.2f}\")\n",
    "        print(f\"Subnarrative threshold: {best_results['sub_threshold']:.2f}\")\n",
    "        print('\\nCompetition Values')\n",
    "        print(f\"Coarse-F1: {best_results['best_coarse_f1']:.3f}\")\n",
    "        print(f\"F1 st. dev. coarse: {best_results['best_coarse_std']:.3f}\")\n",
    "        print(f\"Fine-F1: {best_results['best_fine_f1']:.3f}\")\n",
    "        print(f\"F1 st. dev. fine: {best_results['best_fine_std']:.3f}\")\n",
    "        print(\"\\nCoarse Classification Report:\")\n",
    "        print(best_results['coarse_classification_report'])\n",
    "        print(\"\\nFine Metrics:\")\n",
    "        print(\"Precision: {:.3f}\".format(best_results['fine_precision']))\n",
    "        print(\"Recall: {:.3f}\".format(best_results['fine_recall']))\n",
    "        print(\"F1 Samples: {:.3f}\".format(best_results['samples_f1_fine']))\n",
    "\n",
    "        if save:\n",
    "            self._save_predictions(best_results, os.path.join(self.output_dir, 'submission.txt'))\n",
    "        \n",
    "        return best_results\n",
    "\n",
    "    def _make_prediction(self, article_id, sample_idx, narr_probs, sub_probs_dict, narr_threshold, sub_threshold):\n",
    "        other_idx = self.narrative_classes.index(\"Other\")\n",
    "        active_narratives = [\n",
    "            (n_idx, prob)\n",
    "            for n_idx, prob in enumerate(narr_probs[sample_idx])\n",
    "            if n_idx != other_idx and prob >= narr_threshold\n",
    "        ]\n",
    "        # Fallback, If no active narrartive, output \"Other\" for both\n",
    "        # narrative and subnarratives.\n",
    "        if not active_narratives:\n",
    "            return {\n",
    "                'article_id': article_id,\n",
    "                'narratives': [\"Other\"],\n",
    "                'pairs': [\"Other\"]\n",
    "            }\n",
    "        \n",
    "        narratives = []\n",
    "        pairs = []\n",
    "        seen_pairs = set()\n",
    "        \n",
    "        active_narratives.sort(key=lambda x: x[1], reverse=True)\n",
    "        for narr_idx, _ in active_narratives:\n",
    "            narr_name = self.narrative_classes[narr_idx]\n",
    "            \n",
    "            sub_probs = sub_probs_dict[str(narr_idx)][sample_idx]\n",
    "            # FInd active subnarratives based on the cur threshold\n",
    "            active_subnarratives = [\n",
    "                (local_idx, s_prob)\n",
    "                for local_idx, s_prob in enumerate(sub_probs)\n",
    "                if s_prob >= sub_threshold\n",
    "            ]\n",
    "            # If no active subnarrative, output the predicted Narrative, with Other\n",
    "            # as a pair.\n",
    "            active_subnarratives.sort(key=lambda x: x[1], reverse=True)\n",
    "            if not active_subnarratives:\n",
    "                pairs.append(f\"{narr_name}: Other\")\n",
    "            else:\n",
    "                for local_idx, _ in active_subnarratives:\n",
    "                    global_sub_idx = self.narrative_to_sub_map[narr_idx][local_idx]\n",
    "                    sub_name = self.subnarrative_classes[global_sub_idx]\n",
    "                    pair = f\"{narr_name}: {sub_name}\"\n",
    "                    if pair not in seen_pairs:\n",
    "                        pairs.append(pair)\n",
    "                        seen_pairs.add(pair)\n",
    "            narratives.append(narr_name)\n",
    "        \n",
    "        return {\n",
    "            'article_id': article_id,\n",
    "            'narratives': narratives,\n",
    "            'pairs': pairs\n",
    "        }\n",
    "\n",
    "    def _compute_metrics_coarse_fine(self, predictions, dataset):\n",
    "        \"\"\"\n",
    "        Evaluates the problem predictions with the gold.\n",
    "        Mimics the challenge evaluation function.\n",
    "        \"\"\"\n",
    "        gold_coarse_all = []\n",
    "        gold_fine_all = []\n",
    "        pred_coarse_all = []\n",
    "        pred_fine_all = []\n",
    "\n",
    "        for pred, (_, row) in zip(predictions, dataset.iterrows()):\n",
    "            gold_coarse = row['narratives']\n",
    "            gold_subnarratives = row['subnarratives']\n",
    "            \n",
    "            pred_coarse = pred['narratives']\n",
    "            pred_fine = []\n",
    "            for p in pred['pairs']:\n",
    "                if p == \"Other\":\n",
    "                    pred_fine.append(\"Other\")\n",
    "                else:\n",
    "                    pred_fine.append(p)\n",
    "\n",
    "            gold_fine = []\n",
    "            for gold_nar, gold_sub in zip(gold_coarse, gold_subnarratives):\n",
    "                if gold_nar == \"Other\":\n",
    "                    gold_fine.append(\"Other\")\n",
    "                else:\n",
    "                    gold_fine.append(f\"{gold_nar}: {gold_sub}\")\n",
    "            \n",
    "            gold_coarse_all.append(gold_coarse)\n",
    "            gold_fine_all.append(gold_fine)\n",
    "            pred_coarse_all.append(pred_coarse)\n",
    "            pred_fine_all.append(pred_fine)\n",
    "\n",
    "        f1_coarse_mean, coarse_std = self._evaluate_multi_label(gold_coarse_all, pred_coarse_all, self.classes_coarse)\n",
    "        f1_fine_mean, fine_std = self._evaluate_multi_label(gold_fine_all, pred_fine_all, self.classes_fine)\n",
    "        \n",
    "        gold_coarse_flat = []\n",
    "        pred_coarse_flat = []\n",
    "        for g_labels, p_labels in zip(gold_coarse_all, pred_coarse_all):\n",
    "            g_onehot = np.zeros(len(self.classes_coarse), dtype=int)\n",
    "            for lab in g_labels:\n",
    "                if lab in self.classes_coarse:\n",
    "                    g_onehot[self.classes_coarse.index(lab)] = 1\n",
    "            p_onehot = np.zeros(len(self.classes_coarse), dtype=int)\n",
    "            for lab in p_labels:\n",
    "                if lab in self.classes_coarse:\n",
    "                    p_onehot[self.classes_coarse.index(lab)] = 1\n",
    "            gold_coarse_flat.append(g_onehot)\n",
    "            pred_coarse_flat.append(p_onehot)\n",
    "        gold_coarse_flat = np.array(gold_coarse_flat)\n",
    "        pred_coarse_flat = np.array(pred_coarse_flat)\n",
    "        report_coarse = metrics.classification_report(\n",
    "            gold_coarse_flat, pred_coarse_flat, target_names=self.classes_coarse, zero_division=0\n",
    "        )\n",
    "        \n",
    "        gold_fine_flat = []\n",
    "        pred_fine_flat = []\n",
    "        for g_labels, p_labels in zip(gold_fine_all, pred_fine_all):\n",
    "            g_onehot = np.zeros(len(self.classes_fine), dtype=int)\n",
    "            for lab in g_labels:\n",
    "                if lab in self.classes_fine:\n",
    "                    g_onehot[self.classes_fine.index(lab)] = 1\n",
    "            p_onehot = np.zeros(len(self.classes_fine), dtype=int)\n",
    "            for lab in p_labels:\n",
    "                if lab in self.classes_fine:\n",
    "                    p_onehot[self.classes_fine.index(lab)] = 1\n",
    "            gold_fine_flat.append(g_onehot)\n",
    "            pred_fine_flat.append(p_onehot)\n",
    "        gold_fine_flat = np.array(gold_fine_flat)\n",
    "        pred_fine_flat = np.array(pred_fine_flat)\n",
    "        \n",
    "        precision_fine = metrics.precision_score(gold_fine_flat, pred_fine_flat, average='macro', zero_division=0)\n",
    "        recall_fine = metrics.recall_score(gold_fine_flat, pred_fine_flat, average='macro', zero_division=0)\n",
    "        samples_f1_fine = metrics.f1_score(\n",
    "            gold_fine_flat, \n",
    "            pred_fine_flat, \n",
    "            average='samples',\n",
    "            zero_division=0\n",
    "        )\n",
    "        \n",
    "        return f1_coarse_mean, coarse_std, f1_fine_mean, fine_std, report_coarse, precision_fine, recall_fine, samples_f1_fine\n",
    "\n",
    "    def _evaluate_multi_label(self, gold, predicted, class_list):\n",
    "        \"\"\"\n",
    "        Evaluates the predicted, with the gold and returns the mean and std f1 scores.\n",
    "        Mimics the challenge evaluation function.\n",
    "        \"\"\"\n",
    "        f1_scores = []\n",
    "        for g_labels, p_labels in zip(gold, predicted):\n",
    "            g_onehot = np.zeros(len(class_list), dtype=int)\n",
    "            for lab in g_labels:\n",
    "                if lab in class_list:\n",
    "                    g_onehot[class_list.index(lab)] = 1\n",
    "                    \n",
    "            p_onehot = np.zeros(len(class_list), dtype=int)\n",
    "            for lab in p_labels:\n",
    "                if lab in class_list:\n",
    "                    p_onehot[class_list.index(lab)] = 1\n",
    "\n",
    "            f1_doc = metrics.f1_score(g_onehot, p_onehot, zero_division=0)\n",
    "            f1_scores.append(f1_doc)\n",
    "        \n",
    "        return float(np.mean(f1_scores)), float(np.std(f1_scores))\n",
    "\n",
    "    def _save_predictions(self, best_results, filepath):\n",
    "        predictions = best_results['predictions']\n",
    "        if os.path.exists(filepath):\n",
    "            os.remove(filepath)\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            for pred in predictions:\n",
    "                line = (f\"{pred['article_id']}\\t\"\n",
    "                        f\"{';'.join(pred['narratives'])}\\t\"\n",
    "                        f\"{';'.join(pred['pairs'])}\\n\")\n",
    "                f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebe71798-314a-40ce-8724-506db53bcaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MultiHeadEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d1c49c5-eaf8-47ec-874a-e056b1a22de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.55\n",
      "Subnarrative threshold: 0.55\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.514\n",
      "F1 st. dev. coarse: 0.385\n",
      "Fine-F1: 0.348\n",
      "F1 st. dev. fine: 0.358\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.00      0.00      0.00         0\n",
      "                      CC: Climate change is beneficial       0.00      0.00      0.00         1\n",
      "              CC: Controversy about green technologies       0.50      0.50      0.50         2\n",
      "                     CC: Criticism of climate movement       0.55      0.75      0.63         8\n",
      "                     CC: Criticism of climate policies       0.29      0.67      0.40         3\n",
      "         CC: Criticism of institutions and authorities       0.41      0.88      0.56         8\n",
      "                        CC: Downplaying climate change       0.00      0.00      0.00         2\n",
      "       CC: Green policies are geopolitical instruments       0.00      0.00      0.00         3\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.11      0.25      0.15         4\n",
      "          CC: Questioning the measurements and science       1.00      0.75      0.86         4\n",
      "                                                 Other       0.67      0.55      0.60        11\n",
      "                     URW: Amplifying war-related fears       0.60      1.00      0.75         3\n",
      "URW: Blaming the war on others rather than the invader       0.75      0.50      0.60         6\n",
      "                             URW: Discrediting Ukraine       0.56      0.71      0.62         7\n",
      "                 URW: Discrediting the West, Diplomacy       0.80      0.89      0.84         9\n",
      "                           URW: Distrust towards Media       0.50      0.25      0.33         4\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.00      0.00      0.00         0\n",
      "               URW: Negative Consequences for the West       0.00      0.00      0.00         1\n",
      "                            URW: Overpraising the West       0.00      0.00      0.00         1\n",
      "                                 URW: Praise of Russia       0.00      0.00      0.00         2\n",
      "                             URW: Russia is the Victim       1.00      0.50      0.67         2\n",
      "                         URW: Speculating war outcomes       0.75      0.75      0.75         4\n",
      "\n",
      "                                             micro avg       0.52      0.59      0.55        85\n",
      "                                             macro avg       0.39      0.41      0.38        85\n",
      "                                          weighted avg       0.54      0.59      0.54        85\n",
      "                                           samples avg       0.54      0.56      0.51        85\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.135\n",
      "Recall: 0.191\n",
      "F1 Samples: 0.348\n"
     ]
    }
   ],
   "source": [
    "_ = evaluator.evaluate(\n",
    "    model=trained_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b15fb0-6c03-4bbc-a59a-f7c103ea4fe9",
   "metadata": {},
   "source": [
    "We find the instances of our dataset that are English:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e004556-e74e-4c2a-a4b1-0985643af065",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_english_train = torch.tensor([1 if lang == 'EN' else 0 for lang in dataset_train['language']], \n",
    "                              dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eec0a37b-e514-4ce8-a8d3-597ecf76d91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_english_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c86fbe5-aa41-4372-b2f5-b8dd4f52ba31",
   "metadata": {},
   "source": [
    "Then, we will create variations of how much we penalize the model on focusing on certain languages, to see if any impact is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba32ce33-10da-4aa9-8209-07596a69b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_aware_loss_x3 = LanguageAwareMultiHeadLoss(\n",
    "    narrative_criterion=narrative_criterion,\n",
    "    sub_criterion_dict=sub_criterion_dict,\n",
    "    english_weight=3.0\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "045f04ca-76c4-4989-9e0b-9881c79dbd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_x3 = MultiTaskClassifierMultiHeadConcat(\n",
    "    input_size=input_size,\n",
    "    hidden_size=2048\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a58d8b27-ec9b-425a-bd75-55d7a07c1077",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 1.2613, Validation Loss: 3.9070\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 2/100, Training Loss: 0.9498, Validation Loss: 3.9037\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 3/100, Training Loss: 0.7614, Validation Loss: 3.9131\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 4/100, Training Loss: 0.6582, Validation Loss: 3.9208\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 5/100, Training Loss: 0.6047, Validation Loss: 3.9119\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 6/100, Training Loss: 0.5684, Validation Loss: 3.8847\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 7/100, Training Loss: 0.5345, Validation Loss: 3.8538\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 8/100, Training Loss: 0.5048, Validation Loss: 3.8303\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 9/100, Training Loss: 0.4806, Validation Loss: 3.8220\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 10/100, Training Loss: 0.4624, Validation Loss: 3.8290\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 11/100, Training Loss: 0.4459, Validation Loss: 3.8437\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 12/100, Training Loss: 0.4347, Validation Loss: 3.8495\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 13/100, Training Loss: 0.4190, Validation Loss: 3.8448\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Epoch 14/100, Training Loss: 0.4067, Validation Loss: 3.8199\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 15/100, Training Loss: 0.3983, Validation Loss: 3.7916\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 16/100, Training Loss: 0.3908, Validation Loss: 3.7621\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 17/100, Training Loss: 0.3832, Validation Loss: 3.7342\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 18/100, Training Loss: 0.3764, Validation Loss: 3.7083\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 19/100, Training Loss: 0.3707, Validation Loss: 3.6871\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 20/100, Training Loss: 0.3636, Validation Loss: 3.6735\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 21/100, Training Loss: 0.3593, Validation Loss: 3.6643\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 22/100, Training Loss: 0.3519, Validation Loss: 3.6560\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 23/100, Training Loss: 0.3476, Validation Loss: 3.6518\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 24/100, Training Loss: 0.3430, Validation Loss: 3.6490\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 25/100, Training Loss: 0.3358, Validation Loss: 3.6471\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 26/100, Training Loss: 0.3301, Validation Loss: 3.6484\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 27/100, Training Loss: 0.3246, Validation Loss: 3.6552\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 28/100, Training Loss: 0.3202, Validation Loss: 3.6658\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 29/100, Training Loss: 0.3158, Validation Loss: 3.6839\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Epoch 30/100, Training Loss: 0.3106, Validation Loss: 3.6881\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Epoch 31/100, Training Loss: 0.3085, Validation Loss: 3.6936\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Epoch 32/100, Training Loss: 0.3049, Validation Loss: 3.7029\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Epoch 33/100, Training Loss: 0.3011, Validation Loss: 3.7173\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Epoch 34/100, Training Loss: 0.3007, Validation Loss: 3.7237\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Epoch 35/100, Training Loss: 0.2985, Validation Loss: 3.7332\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "trained_model_x3, _, _ = initialize_and_train_model(\n",
    "    model=model_x3,\n",
    "    loss_fn=language_aware_loss_x3,\n",
    "    patience=10,\n",
    "    device=device,\n",
    "    scheduler_patience=3,\n",
    "    is_english=is_english_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1131f43c-d684-4f77-805d-cc2e15e35a95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.55\n",
      "Subnarrative threshold: 0.45\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.493\n",
      "F1 st. dev. coarse: 0.386\n",
      "Fine-F1: 0.333\n",
      "F1 st. dev. fine: 0.321\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.00      0.00      0.00         0\n",
      "                      CC: Climate change is beneficial       0.00      0.00      0.00         1\n",
      "              CC: Controversy about green technologies       0.33      0.50      0.40         2\n",
      "                     CC: Criticism of climate movement       0.55      0.75      0.63         8\n",
      "                     CC: Criticism of climate policies       0.25      0.67      0.36         3\n",
      "         CC: Criticism of institutions and authorities       0.41      0.88      0.56         8\n",
      "                        CC: Downplaying climate change       0.00      0.00      0.00         2\n",
      "       CC: Green policies are geopolitical instruments       0.00      0.00      0.00         3\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.14      0.25      0.18         4\n",
      "          CC: Questioning the measurements and science       1.00      0.75      0.86         4\n",
      "                                                 Other       0.71      0.45      0.56        11\n",
      "                     URW: Amplifying war-related fears       0.50      1.00      0.67         3\n",
      "URW: Blaming the war on others rather than the invader       0.60      0.50      0.55         6\n",
      "                             URW: Discrediting Ukraine       0.56      0.71      0.62         7\n",
      "                 URW: Discrediting the West, Diplomacy       0.78      0.78      0.78         9\n",
      "                           URW: Distrust towards Media       0.67      0.50      0.57         4\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.00      0.00      0.00         0\n",
      "               URW: Negative Consequences for the West       0.00      0.00      0.00         1\n",
      "                            URW: Overpraising the West       0.00      0.00      0.00         1\n",
      "                                 URW: Praise of Russia       0.00      0.00      0.00         2\n",
      "                             URW: Russia is the Victim       1.00      0.50      0.67         2\n",
      "                         URW: Speculating war outcomes       0.75      0.75      0.75         4\n",
      "\n",
      "                                             micro avg       0.51      0.58      0.54        85\n",
      "                                             macro avg       0.37      0.41      0.37        85\n",
      "                                          weighted avg       0.53      0.58      0.53        85\n",
      "                                           samples avg       0.52      0.54      0.49        85\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.148\n",
      "Recall: 0.299\n",
      "F1 Samples: 0.333\n"
     ]
    }
   ],
   "source": [
    "_ = evaluator.evaluate(\n",
    "    model=trained_model_x3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53866a89-1b90-42b2-b15d-6fe4d9458392",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_aware_loss_x5 = LanguageAwareMultiHeadLoss(\n",
    "    narrative_criterion=narrative_criterion,\n",
    "    sub_criterion_dict=sub_criterion_dict,\n",
    "    english_weight=5.0\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e49dc17c-1cc8-4ff1-a60e-e225e7fb2667",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_x5 = MultiTaskClassifierMultiHeadConcat(\n",
    "    input_size=input_size,\n",
    "    hidden_size=2048\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2776a427-80b9-496d-972c-7ae2f8ba8acd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 1.6793, Validation Loss: 6.4360\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 2/100, Training Loss: 1.2663, Validation Loss: 6.4451\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 3/100, Training Loss: 1.0383, Validation Loss: 6.4886\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 4/100, Training Loss: 0.8822, Validation Loss: 6.5248\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 5/100, Training Loss: 0.8019, Validation Loss: 6.5349\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Epoch 6/100, Training Loss: 0.7583, Validation Loss: 6.4991\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Epoch 7/100, Training Loss: 0.7338, Validation Loss: 6.4434\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Epoch 8/100, Training Loss: 0.7010, Validation Loss: 6.3829\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 9/100, Training Loss: 0.6785, Validation Loss: 6.3241\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 10/100, Training Loss: 0.6571, Validation Loss: 6.2748\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 11/100, Training Loss: 0.6426, Validation Loss: 6.2371\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 12/100, Training Loss: 0.6277, Validation Loss: 6.2107\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 13/100, Training Loss: 0.6098, Validation Loss: 6.1947\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 14/100, Training Loss: 0.5983, Validation Loss: 6.1864\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 15/100, Training Loss: 0.5830, Validation Loss: 6.1836\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 16/100, Training Loss: 0.5698, Validation Loss: 6.1840\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 17/100, Training Loss: 0.5572, Validation Loss: 6.1823\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 18/100, Training Loss: 0.5458, Validation Loss: 6.1768\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 19/100, Training Loss: 0.5351, Validation Loss: 6.1694\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 20/100, Training Loss: 0.5222, Validation Loss: 6.1562\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 21/100, Training Loss: 0.5140, Validation Loss: 6.1381\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 22/100, Training Loss: 0.5012, Validation Loss: 6.1215\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 23/100, Training Loss: 0.4935, Validation Loss: 6.1057\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 24/100, Training Loss: 0.4839, Validation Loss: 6.0837\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 25/100, Training Loss: 0.4753, Validation Loss: 6.0632\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 26/100, Training Loss: 0.4650, Validation Loss: 6.0505\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 27/100, Training Loss: 0.4569, Validation Loss: 6.0474\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 28/100, Training Loss: 0.4473, Validation Loss: 6.0551\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 29/100, Training Loss: 0.4406, Validation Loss: 6.0758\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 30/100, Training Loss: 0.4342, Validation Loss: 6.1021\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 31/100, Training Loss: 0.4268, Validation Loss: 6.1369\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Epoch 32/100, Training Loss: 0.4173, Validation Loss: 6.1384\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Epoch 33/100, Training Loss: 0.4156, Validation Loss: 6.1415\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Epoch 34/100, Training Loss: 0.4112, Validation Loss: 6.1483\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Epoch 35/100, Training Loss: 0.4068, Validation Loss: 6.1535\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Epoch 36/100, Training Loss: 0.4030, Validation Loss: 6.1470\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Epoch 37/100, Training Loss: 0.3992, Validation Loss: 6.1440\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "trained_model_x5, _, _ = initialize_and_train_model(\n",
    "    model=model_x5,\n",
    "    loss_fn=language_aware_loss_x5,\n",
    "    patience=10,\n",
    "    device=device,\n",
    "    scheduler_patience=3,\n",
    "    is_english=is_english_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6981cf1-e547-4765-bf7a-b28fd18f6e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.55\n",
      "Subnarrative threshold: 0.55\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.506\n",
      "F1 st. dev. coarse: 0.399\n",
      "Fine-F1: 0.356\n",
      "F1 st. dev. fine: 0.361\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.00      0.00      0.00         0\n",
      "                      CC: Climate change is beneficial       0.00      0.00      0.00         1\n",
      "              CC: Controversy about green technologies       0.50      0.50      0.50         2\n",
      "                     CC: Criticism of climate movement       0.60      0.75      0.67         8\n",
      "                     CC: Criticism of climate policies       0.33      0.67      0.44         3\n",
      "         CC: Criticism of institutions and authorities       0.43      0.75      0.55         8\n",
      "                        CC: Downplaying climate change       0.00      0.00      0.00         2\n",
      "       CC: Green policies are geopolitical instruments       0.00      0.00      0.00         3\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.14      0.25      0.18         4\n",
      "          CC: Questioning the measurements and science       1.00      0.75      0.86         4\n",
      "                                                 Other       0.55      0.55      0.55        11\n",
      "                     URW: Amplifying war-related fears       0.60      1.00      0.75         3\n",
      "URW: Blaming the war on others rather than the invader       0.60      0.50      0.55         6\n",
      "                             URW: Discrediting Ukraine       0.50      0.71      0.59         7\n",
      "                 URW: Discrediting the West, Diplomacy       0.80      0.89      0.84         9\n",
      "                           URW: Distrust towards Media       0.00      0.00      0.00         4\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.00      0.00      0.00         0\n",
      "               URW: Negative Consequences for the West       0.00      0.00      0.00         1\n",
      "                            URW: Overpraising the West       0.00      0.00      0.00         1\n",
      "                                 URW: Praise of Russia       0.00      0.00      0.00         2\n",
      "                             URW: Russia is the Victim       1.00      0.50      0.67         2\n",
      "                         URW: Speculating war outcomes       0.75      0.75      0.75         4\n",
      "\n",
      "                                             micro avg       0.52      0.56      0.54        85\n",
      "                                             macro avg       0.35      0.39      0.36        85\n",
      "                                          weighted avg       0.49      0.56      0.51        85\n",
      "                                           samples avg       0.51      0.55      0.51        85\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.136\n",
      "Recall: 0.191\n",
      "F1 Samples: 0.356\n"
     ]
    }
   ],
   "source": [
    "_ = evaluator.evaluate(\n",
    "    model=trained_model_x5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b18f7d90-aaf5-4e58-bfdd-ab56abeb694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_x5_more_neurons = MultiTaskClassifierMultiHeadConcat(\n",
    "    input_size=input_size,\n",
    "    hidden_size=4096\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f642c52e-5fa7-430e-a007-591f41bf2f42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 1.6829, Validation Loss: 6.3077\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 2/100, Training Loss: 1.4506, Validation Loss: 6.3359\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 3/100, Training Loss: 1.0072, Validation Loss: 6.4437\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 4/100, Training Loss: 0.8498, Validation Loss: 6.5234\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 5/100, Training Loss: 0.8250, Validation Loss: 6.5162\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Epoch 6/100, Training Loss: 0.7552, Validation Loss: 6.4741\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Epoch 7/100, Training Loss: 0.7048, Validation Loss: 6.4279\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Epoch 8/100, Training Loss: 0.6540, Validation Loss: 6.3897\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Epoch 9/100, Training Loss: 0.6240, Validation Loss: 6.3645\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Epoch 10/100, Training Loss: 0.6129, Validation Loss: 6.3263\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Epoch 11/100, Training Loss: 0.6067, Validation Loss: 6.2922\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 12/100, Training Loss: 0.5993, Validation Loss: 6.2610\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 13/100, Training Loss: 0.5857, Validation Loss: 6.2316\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 14/100, Training Loss: 0.5748, Validation Loss: 6.2029\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 15/100, Training Loss: 0.5616, Validation Loss: 6.1737\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 16/100, Training Loss: 0.5516, Validation Loss: 6.1446\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 17/100, Training Loss: 0.5430, Validation Loss: 6.1164\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 18/100, Training Loss: 0.5352, Validation Loss: 6.0882\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 19/100, Training Loss: 0.5305, Validation Loss: 6.0587\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 20/100, Training Loss: 0.5205, Validation Loss: 6.0308\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 21/100, Training Loss: 0.5148, Validation Loss: 6.0038\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 22/100, Training Loss: 0.5074, Validation Loss: 5.9797\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 23/100, Training Loss: 0.5009, Validation Loss: 5.9563\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 24/100, Training Loss: 0.4937, Validation Loss: 5.9337\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 25/100, Training Loss: 0.4859, Validation Loss: 5.9152\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 26/100, Training Loss: 0.4802, Validation Loss: 5.9008\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 27/100, Training Loss: 0.4740, Validation Loss: 5.8905\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 28/100, Training Loss: 0.4676, Validation Loss: 5.8842\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 29/100, Training Loss: 0.4618, Validation Loss: 5.8819\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 30/100, Training Loss: 0.4587, Validation Loss: 5.8844\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 31/100, Training Loss: 0.4500, Validation Loss: 5.8923\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 32/100, Training Loss: 0.4451, Validation Loss: 5.9056\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 33/100, Training Loss: 0.4406, Validation Loss: 5.9201\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Epoch 34/100, Training Loss: 0.4342, Validation Loss: 5.9203\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Epoch 35/100, Training Loss: 0.4317, Validation Loss: 5.9256\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Epoch 36/100, Training Loss: 0.4297, Validation Loss: 5.9376\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Epoch 37/100, Training Loss: 0.4284, Validation Loss: 5.9550\n",
      "Current Learning Rate: 0.000063\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Epoch 38/100, Training Loss: 0.4234, Validation Loss: 5.9649\n",
      "Current Learning Rate: 0.000063\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Epoch 39/100, Training Loss: 0.4210, Validation Loss: 5.9802\n",
      "Current Learning Rate: 0.000063\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "trained_model_x5_more, _, _ = initialize_and_train_model(\n",
    "    model=model_x5_more_neurons,\n",
    "    loss_fn=language_aware_loss_x5,\n",
    "    patience=10,\n",
    "    device=device,\n",
    "    scheduler_patience=3,\n",
    "    is_english=is_english_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf66b20a-4d17-4e8f-8e3d-854e497bbe01",
   "metadata": {},
   "source": [
    "It seems like adding extra weighting doesn't change the learned model enough to affect performance, the model is more saturated, and the higher loss weight has very little impact.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f35aa056-5be2-4193-8d59-b73acedf20d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.55\n",
      "Subnarrative threshold: 0.50\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.489\n",
      "F1 st. dev. coarse: 0.382\n",
      "Fine-F1: 0.334\n",
      "F1 st. dev. fine: 0.322\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.00      0.00      0.00         0\n",
      "                      CC: Climate change is beneficial       0.00      0.00      0.00         1\n",
      "              CC: Controversy about green technologies       0.33      0.50      0.40         2\n",
      "                     CC: Criticism of climate movement       0.60      0.75      0.67         8\n",
      "                     CC: Criticism of climate policies       0.25      0.67      0.36         3\n",
      "         CC: Criticism of institutions and authorities       0.41      0.88      0.56         8\n",
      "                        CC: Downplaying climate change       0.00      0.00      0.00         2\n",
      "       CC: Green policies are geopolitical instruments       0.00      0.00      0.00         3\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.11      0.25      0.15         4\n",
      "          CC: Questioning the measurements and science       1.00      0.75      0.86         4\n",
      "                                                 Other       0.71      0.45      0.56        11\n",
      "                     URW: Amplifying war-related fears       0.50      1.00      0.67         3\n",
      "URW: Blaming the war on others rather than the invader       0.60      0.50      0.55         6\n",
      "                             URW: Discrediting Ukraine       0.50      0.71      0.59         7\n",
      "                 URW: Discrediting the West, Diplomacy       0.73      0.89      0.80         9\n",
      "                           URW: Distrust towards Media       0.50      0.50      0.50         4\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.00      0.00      0.00         0\n",
      "               URW: Negative Consequences for the West       0.00      0.00      0.00         1\n",
      "                            URW: Overpraising the West       0.00      0.00      0.00         1\n",
      "                                 URW: Praise of Russia       0.00      0.00      0.00         2\n",
      "                             URW: Russia is the Victim       0.50      0.50      0.50         2\n",
      "                         URW: Speculating war outcomes       0.60      0.75      0.67         4\n",
      "\n",
      "                                             micro avg       0.47      0.59      0.52        85\n",
      "                                             macro avg       0.33      0.41      0.36        85\n",
      "                                          weighted avg       0.50      0.59      0.52        85\n",
      "                                           samples avg       0.49      0.55      0.49        85\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.125\n",
      "Recall: 0.243\n",
      "F1 Samples: 0.334\n"
     ]
    }
   ],
   "source": [
    "_ = evaluator.evaluate(\n",
    "    model=trained_model_x5_more,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
