{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc359a13-e78a-40a6-8481-56d671a82533",
   "metadata": {},
   "source": [
    "# Semeval 2025 Task 10\n",
    "### Subtask 2: Narrative Classification\n",
    "\n",
    "Given a news article and a [two-level taxonomy of narrative labels](https://propaganda.math.unipd.it/semeval2025task10/NARRATIVE-TAXONOMIES.pdf) (where each narrative is subdivided into subnarratives) from a particular domain, assign to the article all the appropriate subnarrative labels. This is a multi-label multi-class document classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20f31eb2-7e66-43ca-b9a9-d89784d5e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de79452-a38d-4014-b0db-b256ef3b826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "if random_state:\n",
    "    print('[WARNING] Setting random state')\n",
    "    torch.manual_seed(random_state)\n",
    "    np.random.seed(random_state) \n",
    "    random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c267d496-fc3d-49e0-8082-5b005af2c867",
   "metadata": {},
   "source": [
    "## Ensemble Model Using Cross-Validation\n",
    "\n",
    "As of now, we’ve been training on a combined dataset of all languages to handle limited data. Our final submission will focus on a single test set, but we want to leverage as much training data as possible.\n",
    "\n",
    "One practical approach is to perform n-fold cross-validation on our combined set, which creates n different models—each learning slightly different patterns. \n",
    "* Then, at prediction time, we can load each fold model and average their outputs.\n",
    "  By combining multiple models it is said that, we smooth out any biases or quirks of individual folds and often get more robust predictions.\n",
    "* This ensemble method will help us get the most out of our data while still producing a single set of final predictions for submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483a67f7-6996-4d2f-9009-7979fb276831",
   "metadata": {},
   "source": [
    "We start by again loading our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0798ffdf-4d77-4061-bda1-9628da7ee37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "root_dir = \"../../\"\n",
    "base_save_folder_dir = '../saved/'\n",
    "dataset_folder = os.path.join(base_save_folder_dir, 'Dataset')\n",
    "\n",
    "with open(os.path.join(dataset_folder, 'dataset_train_cleaned.pkl'), 'rb') as f:\n",
    "    dataset_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d279dc8-b4c5-4e6d-acd3-dc5f2006cf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "      <th>narratives</th>\n",
       "      <th>subnarratives</th>\n",
       "      <th>narratives_encoded</th>\n",
       "      <th>subnarratives_encoded</th>\n",
       "      <th>aggregated_subnarratives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1161.txt</td>\n",
       "      <td>&lt;PARA&gt;в ближайшие два месяца сша будут стремит...</td>\n",
       "      <td>[URW: Blaming the war on others rather than th...</td>\n",
       "      <td>[The West are the aggressors, Other, The West ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1175.txt</td>\n",
       "      <td>&lt;PARA&gt;в ес испугались последствий популярности...</td>\n",
       "      <td>[URW: Discrediting the West, Diplomacy, URW: D...</td>\n",
       "      <td>[The West is weak, Other, The EU is divided]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1149.txt</td>\n",
       "      <td>&lt;PARA&gt;возможность признания аллы пугачевой ино...</td>\n",
       "      <td>[URW: Distrust towards Media]</td>\n",
       "      <td>[Western media is an instrument of propaganda]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1015.txt</td>\n",
       "      <td>&lt;PARA&gt;азаров рассказал о смене риторики киева ...</td>\n",
       "      <td>[URW: Discrediting Ukraine, URW: Discrediting ...</td>\n",
       "      <td>[Ukraine is a puppet of the West, Discrediting...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1001.txt</td>\n",
       "      <td>&lt;PARA&gt;в россиянах проснулась массовая любовь к...</td>\n",
       "      <td>[URW: Praise of Russia]</td>\n",
       "      <td>[Russia is a guarantor of peace and prosperity]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language       article_id  \\\n",
       "0       RU  RU-URW-1161.txt   \n",
       "1       RU  RU-URW-1175.txt   \n",
       "2       RU  RU-URW-1149.txt   \n",
       "3       RU  RU-URW-1015.txt   \n",
       "4       RU  RU-URW-1001.txt   \n",
       "\n",
       "                                             content  \\\n",
       "0  <PARA>в ближайшие два месяца сша будут стремит...   \n",
       "1  <PARA>в ес испугались последствий популярности...   \n",
       "2  <PARA>возможность признания аллы пугачевой ино...   \n",
       "3  <PARA>азаров рассказал о смене риторики киева ...   \n",
       "4  <PARA>в россиянах проснулась массовая любовь к...   \n",
       "\n",
       "                                          narratives  \\\n",
       "0  [URW: Blaming the war on others rather than th...   \n",
       "1  [URW: Discrediting the West, Diplomacy, URW: D...   \n",
       "2                      [URW: Distrust towards Media]   \n",
       "3  [URW: Discrediting Ukraine, URW: Discrediting ...   \n",
       "4                            [URW: Praise of Russia]   \n",
       "\n",
       "                                       subnarratives  \\\n",
       "0  [The West are the aggressors, Other, The West ...   \n",
       "1       [The West is weak, Other, The EU is divided]   \n",
       "2     [Western media is an instrument of propaganda]   \n",
       "3  [Ukraine is a puppet of the West, Discrediting...   \n",
       "4    [Russia is a guarantor of peace and prosperity]   \n",
       "\n",
       "                                  narratives_encoded  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                               subnarratives_encoded  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                            aggregated_subnarratives  \n",
       "0  [[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...  \n",
       "1  [[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...  \n",
       "2  [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...  \n",
       "3  [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...  \n",
       "4  [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6765b0-232d-4f50-bbf4-adf35b52dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "misc_folder = os.path.join(base_save_folder_dir, 'Misc')\n",
    "\n",
    "with open(os.path.join(misc_folder, 'narrative_to_subnarratives.pkl'), 'rb') as f:\n",
    "    narrative_to_subnarratives = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf092afa-741c-402d-8198-f0cf016afe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(misc_folder, 'narrative_to_subnarratives_map.pkl'), 'rb') as f:\n",
    "    narrative_to_sub_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf22a7b-911d-4ad7-a282-670ba92959c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(misc_folder, 'coarse_classes.pkl'), 'rb') as f:\n",
    "    coarse_classes = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(misc_folder, 'fine_classes.pkl'), 'rb') as f:\n",
    "    fine_classes = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(misc_folder, 'narrative_order.pkl'), 'rb') as f:\n",
    "    narrative_order = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76727fac-2b2a-4908-82f5-a1209c1bb3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1781, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9ce6eef-209f-433f-b993-bbe9ecac98d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'URW: Discrediting Ukraine': ['Discrediting Ukrainian government and officials and policies',\n",
       "  'Discrediting Ukrainian nation and society',\n",
       "  'Other',\n",
       "  'Ukraine is associated with nazism',\n",
       "  'Ukraine is a puppet of the West',\n",
       "  'Rewriting Ukraine’s history',\n",
       "  'Situation in Ukraine is hopeless',\n",
       "  'Discrediting Ukrainian military',\n",
       "  'Ukraine is a hub for criminal activities'],\n",
       " 'URW: Discrediting the West, Diplomacy': ['Diplomacy does/will not work',\n",
       "  'The EU is divided',\n",
       "  'West is tired of Ukraine',\n",
       "  'Other',\n",
       "  'The West does not care about Ukraine, only about its interests',\n",
       "  'The West is overreacting',\n",
       "  'The West is weak'],\n",
       " 'URW: Praise of Russia': ['Praise of Russian President Vladimir Putin',\n",
       "  'Russia has international support from a number of countries and people',\n",
       "  'Russia is a guarantor of peace and prosperity',\n",
       "  'Other',\n",
       "  'Russian invasion has strong national support',\n",
       "  'Praise of Russian military might'],\n",
       " 'URW: Russia is the Victim': ['Other',\n",
       "  'The West is russophobic',\n",
       "  'UA is anti-RU extremists',\n",
       "  'Russia actions in Ukraine are only self-defence'],\n",
       " 'URW: Distrust towards Media': ['Other',\n",
       "  'Ukrainian media cannot be trusted',\n",
       "  'Western media is an instrument of propaganda'],\n",
       " 'URW: Amplifying war-related fears': ['Russia will also attack other countries',\n",
       "  'Other',\n",
       "  'There is a real possibility that nuclear weapons will be employed',\n",
       "  'NATO should/will directly intervene',\n",
       "  'By continuing the war we risk WWIII'],\n",
       " 'URW: Blaming the war on others rather than the invader': ['Other',\n",
       "  'Ukraine is the aggressor',\n",
       "  'The West are the aggressors'],\n",
       " 'URW: Overpraising the West': ['Other',\n",
       "  'The West belongs in the right side of history',\n",
       "  'The West has the strongest international support',\n",
       "  'NATO will destroy Russia'],\n",
       " 'URW: Speculating war outcomes': ['Other',\n",
       "  'Russian army is collapsing',\n",
       "  'Russian army will lose all the occupied territories',\n",
       "  'Ukrainian army is collapsing'],\n",
       " 'URW: Hidden plots by secret schemes of powerful groups': ['Other'],\n",
       " 'Other': ['Other'],\n",
       " 'URW: Negative Consequences for the West': ['Other',\n",
       "  'Sanctions imposed by Western countries will backfire',\n",
       "  'The conflict will increase the Ukrainian refugee flows to Europe'],\n",
       " 'CC: Amplifying Climate Fears': ['Amplifying existing fears of global warming',\n",
       "  'Other',\n",
       "  'Earth will be uninhabitable soon',\n",
       "  'Doomsday scenarios for humans',\n",
       "  'Whatever we do it is already too late'],\n",
       " 'CC: Criticism of institutions and authorities': ['Other',\n",
       "  'Criticism of international entities',\n",
       "  'Criticism of the EU',\n",
       "  'Criticism of national governments',\n",
       "  'Criticism of political organizations and figures'],\n",
       " 'CC: Criticism of climate movement': ['Other',\n",
       "  'Climate movement is alarmist',\n",
       "  'Ad hominem attacks on key activists',\n",
       "  'Climate movement is corrupt'],\n",
       " 'CC: Downplaying climate change': ['Temperature increase does not have significant impact',\n",
       "  'Other',\n",
       "  'Human activities do not impact climate change',\n",
       "  'Sea levels are not rising',\n",
       "  'Climate cycles are natural',\n",
       "  'CO2 concentrations are too small to have an impact',\n",
       "  'Weather suggests the trend is global cooling',\n",
       "  'Ice is not melting',\n",
       "  'Humans and nature will adapt to the changes'],\n",
       " 'CC: Criticism of climate policies': ['Other',\n",
       "  'Climate policies are only for profit',\n",
       "  'Climate policies have negative impact on the economy',\n",
       "  'Climate policies are ineffective'],\n",
       " 'CC: Questioning the measurements and science': ['Data shows no temperature increase',\n",
       "  'Greenhouse effect/carbon dioxide do not drive climate change',\n",
       "  'Other',\n",
       "  'Methodologies/metrics used are unreliable/faulty',\n",
       "  'Scientific community is unreliable'],\n",
       " 'CC: Hidden plots by secret schemes of powerful groups': ['Other',\n",
       "  'Climate agenda has hidden motives',\n",
       "  'Blaming global elites'],\n",
       " 'CC: Climate change is beneficial': ['Other',\n",
       "  'CO2 is beneficial',\n",
       "  'Temperature increase is beneficial'],\n",
       " 'CC: Controversy about green technologies': ['Other',\n",
       "  'Renewable energy is costly',\n",
       "  'Renewable energy is unreliable',\n",
       "  'Renewable energy is dangerous'],\n",
       " 'CC: Green policies are geopolitical instruments': ['Other',\n",
       "  'Green activities are a form of neo-colonialism',\n",
       "  'Climate-related international relations are abusive/exploitative']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narrative_to_subnarratives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cfa15c7-687f-4871-8a3d-b872cd632124",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_folder = os.path.join(base_save_folder_dir, 'LabelEncoders')\n",
    "\n",
    "with open(os.path.join(label_encoder_folder, 'mlb_narratives.pkl'), 'rb') as f:\n",
    "    mlb_narratives = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(label_encoder_folder, 'mlb_subnarratives.pkl'), 'rb') as f:\n",
    "    mlb_subnarratives = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c77339ce-78a0-4344-92a0-8f36c514314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings_folder = os.path.join(base_save_folder_dir, 'Embeddings/embeddings_train_stella.npy')\n",
    "\n",
    "def load_embeddings(filename):\n",
    "    return np.load(filename)\n",
    "\n",
    "train_embeddings = load_embeddings(embeddings_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10ecc917-221b-416d-add9-38357edb6443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1781, 1024)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f6c8f89-b82a-42d6-bf57-1af05734720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dataset_folder, 'dataset_val_cleaned.pkl'), 'rb') as f:\n",
    "    dataset_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5aee4215-a420-4261-a249-e2127f3ea099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dc5b75f-faa3-44e1-afe9-7e4a54cc221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_folder = os.path.join(base_save_folder_dir, 'Embeddings/embeddings_dev_stella.npy')\n",
    "\n",
    "val_embeddings = load_embeddings(embeddings_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c4e333-9238-43e0-89a9-1397c55ac21a",
   "metadata": {},
   "source": [
    "We combine both train and val datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f4854f3-9ba0-426a-bee7-9bca8b73a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_combined = pd.concat([dataset_train, dataset_val], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82031f4a-1bcf-43e2-904a-79942ef74e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "prefer_cpu=True\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available() and not prefer_cpu\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "777afd4c-b9ca-44a7-a84a-2c315e746ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_embeddings_tensor = torch.tensor(train_embeddings, dtype=torch.float32).to(device)\n",
    "val_embeddings_tensor = torch.tensor(val_embeddings, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7f1fb0-7013-4184-a4a2-6ee21b9bc57c",
   "metadata": {},
   "source": [
    "We also do the same for the embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be890e76-ea7d-4ad4-af58-16be91b08e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_combined = torch.cat([train_embeddings_tensor, val_embeddings_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3571206-3413-4868-b07a-6bdca8cc003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def custom_shuffling(data, embeddings):\n",
    "    shuffled_indices = np.arange(len(data))\n",
    "    np.random.shuffle(shuffled_indices)\n",
    "    \n",
    "    data = data.iloc[shuffled_indices].reset_index(drop=True)\n",
    "    embeddings = embeddings[shuffled_indices]\n",
    "\n",
    "    return data, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "991d6642-28c8-4cee-86ea-7b1e55386f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, embeddings = custom_shuffling(dataset_combined, embeddings_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cdf2c20-f46e-4007-98ea-1ea2602888ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "      <th>narratives</th>\n",
       "      <th>subnarratives</th>\n",
       "      <th>narratives_encoded</th>\n",
       "      <th>subnarratives_encoded</th>\n",
       "      <th>aggregated_subnarratives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PT</td>\n",
       "      <td>PT_156.txt</td>\n",
       "      <td>&lt;PARA&gt;sudeste da europa regista um verão de ca...</td>\n",
       "      <td>[CC: Amplifying Climate Fears]</td>\n",
       "      <td>[Amplifying existing fears of global warming]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[1, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EN</td>\n",
       "      <td>EN_UA_DEV_213.txt</td>\n",
       "      <td>&lt;PARA&gt;US and NATO escalation of conflict with ...</td>\n",
       "      <td>[URW: Blaming the war on others rather than th...</td>\n",
       "      <td>[The West are the aggressors, Western media is...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EN</td>\n",
       "      <td>EN_CC_300005.txt</td>\n",
       "      <td>&lt;PARA&gt;NY’s electric school bus mandate won’t m...</td>\n",
       "      <td>[CC: Criticism of climate policies, CC: Critic...</td>\n",
       "      <td>[Climate policies are ineffective, Climate pol...</td>\n",
       "      <td>[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0], [0, 1, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BG</td>\n",
       "      <td>A7_URW_BG_2800.txt</td>\n",
       "      <td>&lt;PARA&gt;радев унищожително: самозваните ни евроа...</td>\n",
       "      <td>[URW: Amplifying war-related fears, URW: Ampli...</td>\n",
       "      <td>[There is a real possibility that nuclear weap...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HI</td>\n",
       "      <td>HI_274.txt</td>\n",
       "      <td>&lt;PARA&gt;रूस के उस गुप्त हथियार को लेकर रहस्य बरक...</td>\n",
       "      <td>[Other]</td>\n",
       "      <td>[Other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language          article_id  \\\n",
       "0       PT          PT_156.txt   \n",
       "1       EN   EN_UA_DEV_213.txt   \n",
       "2       EN    EN_CC_300005.txt   \n",
       "3       BG  A7_URW_BG_2800.txt   \n",
       "4       HI          HI_274.txt   \n",
       "\n",
       "                                             content  \\\n",
       "0  <PARA>sudeste da europa regista um verão de ca...   \n",
       "1  <PARA>US and NATO escalation of conflict with ...   \n",
       "2  <PARA>NY’s electric school bus mandate won’t m...   \n",
       "3  <PARA>радев унищожително: самозваните ни евроа...   \n",
       "4  <PARA>रूस के उस गुप्त हथियार को लेकर रहस्य बरक...   \n",
       "\n",
       "                                          narratives  \\\n",
       "0                     [CC: Amplifying Climate Fears]   \n",
       "1  [URW: Blaming the war on others rather than th...   \n",
       "2  [CC: Criticism of climate policies, CC: Critic...   \n",
       "3  [URW: Amplifying war-related fears, URW: Ampli...   \n",
       "4                                            [Other]   \n",
       "\n",
       "                                       subnarratives  \\\n",
       "0      [Amplifying existing fears of global warming]   \n",
       "1  [The West are the aggressors, Western media is...   \n",
       "2  [Climate policies are ineffective, Climate pol...   \n",
       "3  [There is a real possibility that nuclear weap...   \n",
       "4                                            [Other]   \n",
       "\n",
       "                                  narratives_encoded  \\\n",
       "0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "2  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "\n",
       "                               subnarratives_encoded  \\\n",
       "0  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, ...   \n",
       "3  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                            aggregated_subnarratives  \n",
       "0  [[1, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...  \n",
       "1  [[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...  \n",
       "2  [[0, 0, 0, 0, 0], [0, 0, 0], [0, 1, 0, 0], [0,...  \n",
       "3  [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...  \n",
       "4  [[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63265bcf-6a01-4dbc-98d4-3ad555b4a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub_heads = dataset['aggregated_subnarratives'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e40ce54-7b7f-438c-b69d-ad340c0e44f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "input_size = embeddings.shape[1]\n",
    "print(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ded6266-8004-45bf-8110-102378630944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiTaskClassifierMultiHead(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size=1024,\n",
    "        num_narratives=len(mlb_narratives.classes_),\n",
    "        narrative_to_sub_map=narrative_to_sub_map,\n",
    "        dropout_rate=0.4\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.shared_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size * 2),\n",
    "            nn.BatchNorm1d(hidden_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        self.narrative_head = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, num_narratives),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.subnarrative_heads = nn.ModuleDict()\n",
    "        for narr_idx, sub_indices in narrative_to_sub_map.items():\n",
    "            num_subs_for_this_narr = len(sub_indices)\n",
    "            self.subnarrative_heads[str(narr_idx)] = nn.Sequential(\n",
    "                nn.Linear(hidden_size * 2, num_subs_for_this_narr),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_out = self.shared_layer(x)\n",
    "        narr_probs = self.narrative_head(shared_out)\n",
    "\n",
    "        sub_probs_dict = {}\n",
    "        for narr_idx, head in self.subnarrative_heads.items():\n",
    "            sub_probs_dict[narr_idx] = head(shared_out)\n",
    "\n",
    "        return narr_probs, sub_probs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db5cc04c-8223-4956-a196-be29352c87d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_params = {\n",
    "    'lr': 0.001,\n",
    "    'hidden_size': 1024,\n",
    "    'dropout': 0.4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca024dba-3271-42d3-8699-4ab35a3f2741",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nar = dataset['narratives_encoded'].tolist()\n",
    "\n",
    "y_sub_nar = dataset['subnarratives_encoded'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f40bfd3f-4350-47e4-b327-8eab082eb158",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nar = torch.tensor(y_nar, dtype=torch.float32).to(device)\n",
    "y_sub_nar = torch.tensor(y_sub_nar, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4284e389-b29a-4aad-a339-5ac2b263d83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC: Amplifying Climate Fears',\n",
       " 'CC: Climate change is beneficial',\n",
       " 'CC: Controversy about green technologies',\n",
       " 'CC: Criticism of climate movement',\n",
       " 'CC: Criticism of climate policies']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "630377d4-c001-41aa-bed0-9352cb18dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = train_embeddings_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7eeb49a-a41e-450f-96f4-ace246e788d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC: Amplifying Climate Fears: Amplifying existing fears of global warming',\n",
       " 'CC: Amplifying Climate Fears: Doomsday scenarios for humans',\n",
       " 'CC: Amplifying Climate Fears: Earth will be uninhabitable soon',\n",
       " 'CC: Amplifying Climate Fears: Other',\n",
       " 'CC: Amplifying Climate Fears: Whatever we do it is already too late']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_classes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a67076b-b2ab-4711-899c-81db6b57fa78",
   "metadata": {},
   "source": [
    "We define the same evaluator we use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1e6d91c-39d0-406c-8aad-19ad26ab709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn import metrics\n",
    "\n",
    "class MultiHeadEvaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        classes_coarse=coarse_classes,\n",
    "        classes_fine=fine_classes,\n",
    "        narrative_to_sub_map=narrative_to_sub_map,\n",
    "        narrative_order=narrative_order,\n",
    "        narrative_classes=mlb_narratives.classes_,\n",
    "        subnarrative_classes=mlb_subnarratives.classes_,\n",
    "        device='cpu',\n",
    "        output_dir='../../../submissions',\n",
    "    ):\n",
    "        self.narrative_to_sub_map = narrative_to_sub_map\n",
    "        self.narrative_order = narrative_order\n",
    "        self.narrative_classes = list(narrative_classes)\n",
    "        self.subnarrative_classes = list(subnarrative_classes)\n",
    "        \n",
    "        self.classes_coarse = classes_coarse\n",
    "        self.classes_fine = classes_fine\n",
    "\n",
    "        self.device = device\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    def evaluate(\n",
    "        self,\n",
    "        model,\n",
    "        embeddings=val_embeddings_tensor,\n",
    "        dataset=dataset_val,\n",
    "        thresholds=None,\n",
    "        save=False,\n",
    "        std_weight=0.4,\n",
    "        lower_thres=0.1,\n",
    "        upper_thres=0.60\n",
    "    ):\n",
    "        if thresholds is None:\n",
    "            thresholds = np.arange(lower_thres, upper_thres, 0.05)    \n",
    "        embeddings = embeddings.to(self.device)\n",
    "    \n",
    "        best_results = {\n",
    "            'best_coarse_f1': -1,\n",
    "            'best_coarse_std': float('inf'),\n",
    "            'best_fine_f1': -1,\n",
    "            'best_fine_std': float('inf'),\n",
    "            'narr_threshold': 0,\n",
    "            'sub_threshold': 0,\n",
    "            'predictions': None,\n",
    "            'best_combined_score': -float('inf'),\n",
    "            'coarse_classification_report': None,\n",
    "            'fine_precision': None,\n",
    "            'fine_recall': None,\n",
    "            'samples_f1_fine': None,\n",
    "        }\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            narr_probs, sub_probs_dict = model(embeddings)\n",
    "            narr_probs = narr_probs.cpu().numpy()\n",
    "            sub_probs_dict = {k: v.cpu().numpy() for k, v in sub_probs_dict.items()}\n",
    "    \n",
    "        for narr_threshold in thresholds:\n",
    "            for sub_threshold in thresholds:\n",
    "                predictions = []\n",
    "                for sample_idx, row in dataset.iterrows():\n",
    "                    pred = self._make_prediction(\n",
    "                        row['article_id'],\n",
    "                        sample_idx,\n",
    "                        narr_probs,\n",
    "                        sub_probs_dict,\n",
    "                        narr_threshold,\n",
    "                        sub_threshold\n",
    "                    )\n",
    "                    predictions.append(pred)\n",
    "                \n",
    "                f1_coarse_mean, coarse_std, f1_fine_mean, fine_std, report_coarse, precision_fine, recall_fine, samples_f1_fine = self._compute_metrics_coarse_fine(predictions, dataset)\n",
    "                \n",
    "                combined_score = f1_fine_mean - (std_weight * coarse_std)\n",
    "                \n",
    "                if combined_score > best_results['best_combined_score']:\n",
    "                    best_results.update({\n",
    "                        'best_coarse_f1': f1_coarse_mean,\n",
    "                        'best_coarse_std': coarse_std,\n",
    "                        'best_fine_f1': f1_fine_mean,\n",
    "                        'best_fine_std': fine_std,\n",
    "                        'narr_threshold': narr_threshold,\n",
    "                        'sub_threshold': sub_threshold,\n",
    "                        'predictions': predictions,\n",
    "                        'best_combined_score': combined_score,\n",
    "                        'coarse_classification_report': report_coarse,\n",
    "                        'fine_precision': precision_fine,\n",
    "                        'fine_recall': recall_fine,\n",
    "                        'samples_f1_fine': samples_f1_fine,\n",
    "                    })\n",
    "    \n",
    "        print(\"\\nBest thresholds found:\")\n",
    "        print(f\"Narrative threshold: {best_results['narr_threshold']:.2f}\")\n",
    "        print(f\"Subnarrative threshold: {best_results['sub_threshold']:.2f}\")\n",
    "        print('\\nCompetition Values')\n",
    "        print(f\"Coarse-F1: {best_results['best_coarse_f1']:.3f}\")\n",
    "        print(f\"F1 st. dev. coarse: {best_results['best_coarse_std']:.3f}\")\n",
    "        print(f\"Fine-F1: {best_results['best_fine_f1']:.3f}\")\n",
    "        print(f\"F1 st. dev. fine: {best_results['best_fine_std']:.3f}\")\n",
    "        print(\"\\nCoarse Classification Report:\")\n",
    "        print(best_results['coarse_classification_report'])\n",
    "        print(\"\\nFine Metrics:\")\n",
    "        print(\"Precision: {:.3f}\".format(best_results['fine_precision']))\n",
    "        print(\"Recall: {:.3f}\".format(best_results['fine_recall']))\n",
    "        print(\"F1 Samples: {:.3f}\".format(best_results['samples_f1_fine']))\n",
    "\n",
    "        if save:\n",
    "            self._save_predictions(best_results, os.path.join(self.output_dir, 'submission.txt'))\n",
    "        \n",
    "        return best_results\n",
    "\n",
    "    def _make_prediction(self, article_id, sample_idx, narr_probs, sub_probs_dict, narr_threshold, sub_threshold):\n",
    "        other_idx = self.narrative_classes.index(\"Other\")\n",
    "        active_narratives = [\n",
    "            (n_idx, prob)\n",
    "            for n_idx, prob in enumerate(narr_probs[sample_idx])\n",
    "            if n_idx != other_idx and prob >= narr_threshold\n",
    "        ]\n",
    "        # Fallback, If no active narrartive, output \"Other\" for both\n",
    "        # narrative and subnarratives.\n",
    "        if not active_narratives:\n",
    "            return {\n",
    "                'article_id': article_id,\n",
    "                'narratives': [\"Other\"],\n",
    "                'pairs': [\"Other\"]\n",
    "            }\n",
    "        \n",
    "        narratives = []\n",
    "        pairs = []\n",
    "        seen_pairs = set()\n",
    "        \n",
    "        active_narratives.sort(key=lambda x: x[1], reverse=True)\n",
    "        for narr_idx, _ in active_narratives:\n",
    "            narr_name = self.narrative_classes[narr_idx]\n",
    "            \n",
    "            sub_probs = sub_probs_dict[str(narr_idx)][sample_idx]\n",
    "            # FInd active subnarratives based on the cur threshold\n",
    "            active_subnarratives = [\n",
    "                (local_idx, s_prob)\n",
    "                for local_idx, s_prob in enumerate(sub_probs)\n",
    "                if s_prob >= sub_threshold\n",
    "            ]\n",
    "            # If no active subnarrative, output the predicted Narrative, with Other\n",
    "            # as a pair.\n",
    "            active_subnarratives.sort(key=lambda x: x[1], reverse=True)\n",
    "            if not active_subnarratives:\n",
    "                pairs.append(f\"{narr_name}: Other\")\n",
    "            else:\n",
    "                for local_idx, _ in active_subnarratives:\n",
    "                    global_sub_idx = self.narrative_to_sub_map[narr_idx][local_idx]\n",
    "                    sub_name = self.subnarrative_classes[global_sub_idx]\n",
    "                    pair = f\"{narr_name}: {sub_name}\"\n",
    "                    if pair not in seen_pairs:\n",
    "                        pairs.append(pair)\n",
    "                        seen_pairs.add(pair)\n",
    "            narratives.append(narr_name)\n",
    "        \n",
    "        return {\n",
    "            'article_id': article_id,\n",
    "            'narratives': narratives,\n",
    "            'pairs': pairs\n",
    "        }\n",
    "\n",
    "    def _compute_metrics_coarse_fine(self, predictions, dataset):\n",
    "        \"\"\"\n",
    "        Evaluates the problem predictions with the gold.\n",
    "        Mimics the challenge evaluation function.\n",
    "        \"\"\"\n",
    "        gold_coarse_all = []\n",
    "        gold_fine_all = []\n",
    "        pred_coarse_all = []\n",
    "        pred_fine_all = []\n",
    "\n",
    "        for pred, (_, row) in zip(predictions, dataset.iterrows()):\n",
    "            gold_coarse = row['narratives']\n",
    "            gold_subnarratives = row['subnarratives']\n",
    "            \n",
    "            pred_coarse = pred['narratives']\n",
    "            pred_fine = []\n",
    "            for p in pred['pairs']:\n",
    "                if p == \"Other\":\n",
    "                    pred_fine.append(\"Other\")\n",
    "                else:\n",
    "                    pred_fine.append(p)\n",
    "\n",
    "            gold_fine = []\n",
    "            for gold_nar, gold_sub in zip(gold_coarse, gold_subnarratives):\n",
    "                if gold_nar == \"Other\":\n",
    "                    gold_fine.append(\"Other\")\n",
    "                else:\n",
    "                    gold_fine.append(f\"{gold_nar}: {gold_sub}\")\n",
    "            \n",
    "            gold_coarse_all.append(gold_coarse)\n",
    "            gold_fine_all.append(gold_fine)\n",
    "            pred_coarse_all.append(pred_coarse)\n",
    "            pred_fine_all.append(pred_fine)\n",
    "\n",
    "        f1_coarse_mean, coarse_std = self._evaluate_multi_label(gold_coarse_all, pred_coarse_all, self.classes_coarse)\n",
    "        f1_fine_mean, fine_std = self._evaluate_multi_label(gold_fine_all, pred_fine_all, self.classes_fine)\n",
    "        \n",
    "        gold_coarse_flat = []\n",
    "        pred_coarse_flat = []\n",
    "        for g_labels, p_labels in zip(gold_coarse_all, pred_coarse_all):\n",
    "            g_onehot = np.zeros(len(self.classes_coarse), dtype=int)\n",
    "            for lab in g_labels:\n",
    "                if lab in self.classes_coarse:\n",
    "                    g_onehot[self.classes_coarse.index(lab)] = 1\n",
    "            p_onehot = np.zeros(len(self.classes_coarse), dtype=int)\n",
    "            for lab in p_labels:\n",
    "                if lab in self.classes_coarse:\n",
    "                    p_onehot[self.classes_coarse.index(lab)] = 1\n",
    "            gold_coarse_flat.append(g_onehot)\n",
    "            pred_coarse_flat.append(p_onehot)\n",
    "        gold_coarse_flat = np.array(gold_coarse_flat)\n",
    "        pred_coarse_flat = np.array(pred_coarse_flat)\n",
    "        report_coarse = metrics.classification_report(\n",
    "            gold_coarse_flat, pred_coarse_flat, target_names=self.classes_coarse, zero_division=0\n",
    "        )\n",
    "        \n",
    "        gold_fine_flat = []\n",
    "        pred_fine_flat = []\n",
    "        for g_labels, p_labels in zip(gold_fine_all, pred_fine_all):\n",
    "            g_onehot = np.zeros(len(self.classes_fine), dtype=int)\n",
    "            for lab in g_labels:\n",
    "                if lab in self.classes_fine:\n",
    "                    g_onehot[self.classes_fine.index(lab)] = 1\n",
    "            p_onehot = np.zeros(len(self.classes_fine), dtype=int)\n",
    "            for lab in p_labels:\n",
    "                if lab in self.classes_fine:\n",
    "                    p_onehot[self.classes_fine.index(lab)] = 1\n",
    "            gold_fine_flat.append(g_onehot)\n",
    "            pred_fine_flat.append(p_onehot)\n",
    "        gold_fine_flat = np.array(gold_fine_flat)\n",
    "        pred_fine_flat = np.array(pred_fine_flat)\n",
    "        \n",
    "        precision_fine = metrics.precision_score(gold_fine_flat, pred_fine_flat, average='macro', zero_division=0)\n",
    "        recall_fine = metrics.recall_score(gold_fine_flat, pred_fine_flat, average='macro', zero_division=0)\n",
    "        samples_f1_fine = metrics.f1_score(\n",
    "            gold_fine_flat, \n",
    "            pred_fine_flat, \n",
    "            average='samples',\n",
    "            zero_division=0\n",
    "        )\n",
    "        \n",
    "        return f1_coarse_mean, coarse_std, f1_fine_mean, fine_std, report_coarse, precision_fine, recall_fine, samples_f1_fine\n",
    "\n",
    "    def _evaluate_multi_label(self, gold, predicted, class_list):\n",
    "        \"\"\"\n",
    "        Evaluates the predicted, with the gold and returns the mean and std f1 scores.\n",
    "        Mimics the challenge evaluation function.\n",
    "        \"\"\"\n",
    "        f1_scores = []\n",
    "        for g_labels, p_labels in zip(gold, predicted):\n",
    "            g_onehot = np.zeros(len(class_list), dtype=int)\n",
    "            for lab in g_labels:\n",
    "                if lab in class_list:\n",
    "                    g_onehot[class_list.index(lab)] = 1\n",
    "                    \n",
    "            p_onehot = np.zeros(len(class_list), dtype=int)\n",
    "            for lab in p_labels:\n",
    "                if lab in class_list:\n",
    "                    p_onehot[class_list.index(lab)] = 1\n",
    "\n",
    "            f1_doc = metrics.f1_score(g_onehot, p_onehot, zero_division=0)\n",
    "            f1_scores.append(f1_doc)\n",
    "        \n",
    "        return float(np.mean(f1_scores)), float(np.std(f1_scores))\n",
    "\n",
    "    def _save_predictions(self, best_results, filepath):\n",
    "        predictions = best_results['predictions']\n",
    "        if os.path.exists(filepath):\n",
    "            os.remove(filepath)\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            for pred in predictions:\n",
    "                line = (f\"{pred['article_id']}\\t\"\n",
    "                        f\"{';'.join(pred['narratives'])}\\t\"\n",
    "                        f\"{';'.join(pred['pairs'])}\\n\")\n",
    "                f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17623237-9ec8-41b0-9244-a46a8b9ed930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(y_train):\n",
    "    total_samples = y_train.shape[0]\n",
    "    class_weights = []\n",
    "    for label in range(y_train.shape[1]):\n",
    "        pos_count = y_train[:, label].sum().item()\n",
    "        neg_count = total_samples - pos_count\n",
    "        pos_weight = total_samples / (2 * pos_count) if pos_count > 0 else 0\n",
    "        neg_weight = total_samples / (2 * neg_count) if neg_count > 0 else 0\n",
    "        class_weights.append((pos_weight, neg_weight))\n",
    "    return class_weights\n",
    "\n",
    "class WeightedBCELoss(nn.Module):\n",
    "    def __init__(self, class_weights):\n",
    "        super().__init__()\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def forward(self, probs, targets):\n",
    "        bce_loss = 0\n",
    "        epsilon = 1e-7\n",
    "        for i, (pos_weight, neg_weight) in enumerate(self.class_weights):\n",
    "            prob = probs[:, i]\n",
    "            bce = -pos_weight * targets[:, i] * torch.log(prob + epsilon) - \\\n",
    "                  neg_weight * (1 - targets[:, i]) * torch.log(1 - prob + epsilon)\n",
    "            bce_loss += bce.mean()\n",
    "        return bce_loss / len(self.class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e052178-2256-4347-bc64-3ea1b3e5db97",
   "metadata": {},
   "source": [
    "We also define the same loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54e384f0-c67c-4f6b-9748-5761c280537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadLoss(nn.Module):\n",
    "    def __init__(self, narrative_criterion, sub_criterion_dict, \n",
    "                 condition_weight=0.3, sub_weight=0.3):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.narrative_criterion = narrative_criterion\n",
    "        self.sub_criterion_dict = sub_criterion_dict\n",
    "        self.condition_weight = condition_weight\n",
    "        self.sub_weight = sub_weight\n",
    "        \n",
    "    def forward(self, narr_probs, sub_probs_dict, y_narr, y_sub_heads):\n",
    "        narr_loss = self.narrative_criterion(narr_probs, y_narr)\n",
    "        sub_loss = 0.0\n",
    "        condition_loss = 0.0\n",
    "        \n",
    "        for narr_idx_str, sub_probs in sub_probs_dict.items():\n",
    "            narr_idx = int(narr_idx_str)\n",
    "            y_sub = [row[narr_idx] for row in y_sub_heads]\n",
    "            y_sub_tensor = torch.tensor(y_sub, dtype=torch.float32, device=sub_probs.device)\n",
    "            \n",
    "            sub_loss_func = self.sub_criterion_dict[narr_idx_str]\n",
    "            sub_loss += sub_loss_func(sub_probs, y_sub_tensor)\n",
    "\n",
    "            narr_pred = narr_probs[:, narr_idx].unsqueeze(1)\n",
    "            condition_term = torch.mean(\n",
    "                # Penalize high probs of sub, based on first level narr predictinos\n",
    "                torch.abs(sub_probs * (1 - narr_pred)) + \n",
    "                # If a narrative is true, then the subnarrative predictions should match their actual true values.\n",
    "                narr_pred * torch.abs(sub_probs - y_sub_tensor.unsqueeze(1))\n",
    "            )\n",
    "            condition_loss += condition_term\n",
    "            \n",
    "        sub_loss = sub_loss / len(sub_probs_dict)\n",
    "        condition_loss = condition_loss / len(sub_probs_dict)\n",
    "        \n",
    "        total_loss = (1 - self.sub_weight) * narr_loss + \\\n",
    "                    self.sub_weight * sub_loss + \\\n",
    "                    self.condition_weight * condition_loss\n",
    "        \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4301557f-da13-4af7-9212-c50e2d6bb2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_multihead(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    train_embeddings,\n",
    "    y_train_nar,\n",
    "    y_train_sub_heads,\n",
    "    val_embeddings,\n",
    "    y_val_nar,\n",
    "    y_val_sub_heads,\n",
    "    patience=10,\n",
    "    num_epochs=100,\n",
    "    scheduler=None,\n",
    "    min_delta=0.001,\n",
    "    show_progress=True\n",
    "):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience_counter = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_narr_probs, train_sub_probs_dict = model(train_embeddings)\n",
    "        train_loss = loss_fn(train_narr_probs, train_sub_probs_dict, y_train_nar, y_train_sub_heads)\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_narr_probs, val_sub_probs_dict = model(val_embeddings)\n",
    "            val_loss = loss_fn(val_narr_probs, val_sub_probs_dict, y_val_nar, y_val_sub_heads)\n",
    "            \n",
    "        if show_progress:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "                  f\"Training Loss: {train_loss.item():.4f}, \"\n",
    "                  f\"Validation Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "            current_lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "            print(f\"Current Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "        if val_loss.item() < best_val_loss - min_delta:\n",
    "            best_val_loss = val_loss.item()\n",
    "            patience_counter = 0\n",
    "            best_model = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Validation loss did not significantly improve for {patience_counter} epoch(s).\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    if best_model:\n",
    "        model.load_state_dict(best_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec801bb2-e5d7-4554-b40a-62b2dfa0e608",
   "metadata": {},
   "source": [
    "We first create a splitter, shuffle data and iterate each fold.\n",
    "- Each fold gives us a train and val idx in order for us to access the train and val in that fold.\n",
    "- We load our model, optimizer and class weights and then we train like usual.\n",
    "- After that, we validate our model on the validation embeddings for that fold.\n",
    "- Lastly, we save those models, their configs, and thresholds for later use during inference.\n",
    "- We finally averages the performance across folds so that we can get an estimate of how the model does on different splits of our complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85606afd-7e17-477c-8ba8-f2b76f5276b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "class CrossValEnsembleTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_class,\n",
    "        embeddings=embeddings,\n",
    "        dataset=dataset,\n",
    "        y_nar=y_nar,\n",
    "        y_sub_heads=y_sub_heads,\n",
    "        input_size=input_size,\n",
    "        hidden_size=1024,\n",
    "        dropout_rate=0.4,\n",
    "        lr=0.001,\n",
    "        n_splits=5,\n",
    "        patience=10,\n",
    "        num_epochs=100,\n",
    "    ):\n",
    "        self.model_class = model_class\n",
    "        self.embeddings = embeddings\n",
    "        self.dataset = dataset\n",
    "        self.y_nar = y_nar\n",
    "        self.y_sub_heads = y_sub_heads\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.lr = lr\n",
    "        self.n_splits = n_splits\n",
    "        self.patience = patience\n",
    "        self.num_epochs = num_epochs\n",
    "        \n",
    "        self.fold_models = []\n",
    "        self.fold_results = []\n",
    "\n",
    "    def fit(self, sub_weight=0.3, condition_weight=0.3):\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=random_state)\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(self.embeddings)):\n",
    "            print(f\"\\nTraining Fold {fold + 1}/{self.n_splits}\")\n",
    "            \n",
    "            # Split data based on indices\n",
    "            train_embeddings = self.embeddings[train_idx]\n",
    "            val_embeddings_fold = self.embeddings[val_idx]\n",
    "            \n",
    "            train_nar = self.y_nar[train_idx]\n",
    "            val_nar = self.y_nar[val_idx]\n",
    "            \n",
    "            train_sub = self.y_sub_heads[train_idx]\n",
    "            val_sub = self.y_sub_heads[val_idx]\n",
    "            \n",
    "            model = self.model_class(\n",
    "                input_size=self.input_size,\n",
    "                hidden_size=self.hidden_size,\n",
    "                dropout_rate=self.dropout_rate\n",
    "            )\n",
    "            \n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=self.lr)\n",
    "\n",
    "            # Compute class weights for narratives\n",
    "            class_weights_nar_fold = compute_class_weights(train_nar)\n",
    "            narrative_criterion_fold = WeightedBCELoss(class_weights_nar_fold)\n",
    "            \n",
    "            # Compute subnarrative class weights\n",
    "            sub_criterion_dict_fold = {}\n",
    "            for narr_idx_str in model.subnarrative_heads.keys():\n",
    "                narr_idx = int(narr_idx_str)\n",
    "                y_sub_fold = torch.tensor([row[narr_idx] for row in train_sub]).to(device)\n",
    "                class_weights_sub = compute_class_weights(y_sub_fold)\n",
    "                sub_criterion_dict_fold[narr_idx_str] = WeightedBCELoss(class_weights_sub)\n",
    "\n",
    "            loss_fn = MultiHeadLoss(\n",
    "                narrative_criterion=narrative_criterion_fold,\n",
    "                sub_criterion_dict=sub_criterion_dict_fold,\n",
    "                sub_weight=sub_weight,\n",
    "                condition_weight=condition_weight\n",
    "            )\n",
    "            \n",
    "            trained_model = train_with_multihead(\n",
    "                model=model,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn,\n",
    "                train_embeddings=train_embeddings,\n",
    "                y_train_nar=train_nar,\n",
    "                y_train_sub_heads=train_sub,\n",
    "                val_embeddings=val_embeddings_fold,\n",
    "                y_val_nar=val_nar,\n",
    "                y_val_sub_heads=val_sub,\n",
    "                patience=self.patience,\n",
    "                num_epochs=self.num_epochs,\n",
    "                show_progress=False\n",
    "            )\n",
    "            \n",
    "            evaluator = MultiHeadEvaluator()\n",
    "            fold_dataset = self.dataset.iloc[val_idx].reset_index(drop=True)\n",
    "            metrics = evaluator.evaluate(\n",
    "                trained_model, \n",
    "                val_embeddings_fold,\n",
    "                dataset=fold_dataset\n",
    "            )\n",
    "            \n",
    "            self.fold_models.append(trained_model.state_dict())\n",
    "            self.fold_results.append({\n",
    "                'fold': fold + 1,\n",
    "                'metrics': metrics,\n",
    "                'val_indices': val_idx\n",
    "            })\n",
    "            \n",
    "            print(f\"\\nFold {fold + 1} Results:\")\n",
    "            print(f\"Coarse-F1: {metrics['best_coarse_f1']:.3f}\")\n",
    "            print(f\"Fine-F1: {metrics['best_fine_f1']:.3f}\")\n",
    "            \n",
    "        self._display_cv_performance()\n",
    "        return self.fold_models, self.fold_results\n",
    "\n",
    "\n",
    "    def _display_cv_performance(self):\n",
    "        print(\"\\nCross-Validation Performance:\")\n",
    "        avg_coarse_f1 = np.mean([r['metrics']['best_coarse_f1'] for r in self.fold_results])\n",
    "        std_coarse_f1 = np.std([r['metrics']['best_coarse_f1'] for r in self.fold_results])\n",
    "        avg_fine_f1 = np.mean([r['metrics']['best_fine_f1'] for r in self.fold_results])\n",
    "        std_fine_f1 = np.std([r['metrics']['best_fine_f1'] for r in self.fold_results])\n",
    "        \n",
    "        print(f\"Average Coarse-F1: {avg_coarse_f1:.3f} ± {std_coarse_f1:.3f}\")\n",
    "        print(f\"Average Fine-F1:   {avg_fine_f1:.3f} ± {std_fine_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef28f2d0-f7e5-437b-af6e-1e36aeaac5fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Fold 1/5\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n",
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.55\n",
      "Subnarrative threshold: 0.50\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.576\n",
      "F1 st. dev. coarse: 0.387\n",
      "Fine-F1: 0.403\n",
      "F1 st. dev. fine: 0.352\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.83      0.94      0.88        66\n",
      "                      CC: Climate change is beneficial       0.00      0.00      0.00         5\n",
      "              CC: Controversy about green technologies       0.17      0.33      0.22         3\n",
      "                     CC: Criticism of climate movement       0.39      0.54      0.45        13\n",
      "                     CC: Criticism of climate policies       0.39      0.64      0.48        25\n",
      "         CC: Criticism of institutions and authorities       0.60      0.79      0.68        39\n",
      "                        CC: Downplaying climate change       0.45      0.50      0.48        10\n",
      "       CC: Green policies are geopolitical instruments       0.00      0.00      0.00         1\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.45      0.45      0.45        11\n",
      "          CC: Questioning the measurements and science       0.50      1.00      0.67         2\n",
      "                                                 Other       0.64      0.53      0.58        89\n",
      "                     URW: Amplifying war-related fears       0.61      0.66      0.64        41\n",
      "URW: Blaming the war on others rather than the invader       0.34      0.60      0.44        40\n",
      "                             URW: Discrediting Ukraine       0.68      0.60      0.64        83\n",
      "                 URW: Discrediting the West, Diplomacy       0.67      0.58      0.62        79\n",
      "                           URW: Distrust towards Media       0.25      0.09      0.13        11\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.50      0.33      0.40         3\n",
      "               URW: Negative Consequences for the West       0.35      0.30      0.32        20\n",
      "                            URW: Overpraising the West       0.38      0.33      0.35         9\n",
      "                                 URW: Praise of Russia       0.60      0.70      0.64        82\n",
      "                             URW: Russia is the Victim       0.35      0.58      0.44        31\n",
      "                         URW: Speculating war outcomes       0.23      0.30      0.26        27\n",
      "\n",
      "                                             micro avg       0.55      0.60      0.57       690\n",
      "                                             macro avg       0.43      0.49      0.44       690\n",
      "                                          weighted avg       0.56      0.60      0.58       690\n",
      "                                           samples avg       0.59      0.62      0.58       690\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.223\n",
      "Recall: 0.365\n",
      "F1 Samples: 0.403\n",
      "\n",
      "Fold 1 Results:\n",
      "Coarse-F1: 0.576\n",
      "Fine-F1: 0.403\n",
      "\n",
      "Training Fold 2/5\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n",
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.55\n",
      "Subnarrative threshold: 0.50\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.582\n",
      "F1 st. dev. coarse: 0.389\n",
      "Fine-F1: 0.404\n",
      "F1 st. dev. fine: 0.349\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.84      0.98      0.91        63\n",
      "                      CC: Climate change is beneficial       0.33      1.00      0.50         1\n",
      "              CC: Controversy about green technologies       0.75      0.55      0.63        11\n",
      "                     CC: Criticism of climate movement       0.41      0.58      0.48        12\n",
      "                     CC: Criticism of climate policies       0.47      0.70      0.56        20\n",
      "         CC: Criticism of institutions and authorities       0.56      0.82      0.67        33\n",
      "                        CC: Downplaying climate change       0.50      0.73      0.59        11\n",
      "       CC: Green policies are geopolitical instruments       0.50      0.33      0.40         3\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.53      0.82      0.64        11\n",
      "          CC: Questioning the measurements and science       0.80      0.80      0.80         5\n",
      "                                                 Other       0.46      0.48      0.47        65\n",
      "                     URW: Amplifying war-related fears       0.74      0.69      0.71        54\n",
      "URW: Blaming the war on others rather than the invader       0.27      0.34      0.30        38\n",
      "                             URW: Discrediting Ukraine       0.71      0.78      0.75        92\n",
      "                 URW: Discrediting the West, Diplomacy       0.60      0.59      0.60        71\n",
      "                           URW: Distrust towards Media       0.71      0.50      0.59        10\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.00      0.00      0.00         6\n",
      "               URW: Negative Consequences for the West       0.33      0.26      0.29        19\n",
      "                            URW: Overpraising the West       0.33      0.18      0.24        11\n",
      "                                 URW: Praise of Russia       0.55      0.73      0.63        75\n",
      "                             URW: Russia is the Victim       0.71      0.47      0.56        51\n",
      "                         URW: Speculating war outcomes       0.28      0.31      0.30        29\n",
      "\n",
      "                                             micro avg       0.57      0.63      0.60       691\n",
      "                                             macro avg       0.52      0.57      0.53       691\n",
      "                                          weighted avg       0.58      0.63      0.60       691\n",
      "                                           samples avg       0.59      0.64      0.58       691\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.261\n",
      "Recall: 0.367\n",
      "F1 Samples: 0.404\n",
      "\n",
      "Fold 2 Results:\n",
      "Coarse-F1: 0.582\n",
      "Fine-F1: 0.404\n",
      "\n",
      "Training Fold 3/5\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n",
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.50\n",
      "Subnarrative threshold: 0.45\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.598\n",
      "F1 st. dev. coarse: 0.361\n",
      "Fine-F1: 0.424\n",
      "F1 st. dev. fine: 0.338\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.82      0.94      0.88        53\n",
      "                      CC: Climate change is beneficial       0.50      1.00      0.67         1\n",
      "              CC: Controversy about green technologies       0.43      0.43      0.43         7\n",
      "                     CC: Criticism of climate movement       0.62      0.89      0.73        18\n",
      "                     CC: Criticism of climate policies       0.39      0.65      0.49        20\n",
      "         CC: Criticism of institutions and authorities       0.67      0.80      0.73        41\n",
      "                        CC: Downplaying climate change       0.36      0.50      0.42         8\n",
      "       CC: Green policies are geopolitical instruments       0.00      0.00      0.00         3\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.50      0.64      0.56        14\n",
      "          CC: Questioning the measurements and science       0.67      0.80      0.73         5\n",
      "                                                 Other       0.61      0.67      0.63        60\n",
      "                     URW: Amplifying war-related fears       0.55      0.72      0.62        47\n",
      "URW: Blaming the war on others rather than the invader       0.33      0.50      0.40        42\n",
      "                             URW: Discrediting Ukraine       0.60      0.79      0.68        97\n",
      "                 URW: Discrediting the West, Diplomacy       0.65      0.61      0.63        93\n",
      "                           URW: Distrust towards Media       0.50      0.31      0.38        13\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.75      0.33      0.46         9\n",
      "               URW: Negative Consequences for the West       0.40      0.48      0.43        21\n",
      "                            URW: Overpraising the West       0.25      0.20      0.22        10\n",
      "                                 URW: Praise of Russia       0.60      0.71      0.65        84\n",
      "                             URW: Russia is the Victim       0.36      0.40      0.38        45\n",
      "                         URW: Speculating war outcomes       0.33      0.47      0.38        32\n",
      "\n",
      "                                             micro avg       0.55      0.66      0.60       723\n",
      "                                             macro avg       0.49      0.58      0.52       723\n",
      "                                          weighted avg       0.56      0.66      0.60       723\n",
      "                                           samples avg       0.60      0.68      0.60       723\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.266\n",
      "Recall: 0.403\n",
      "F1 Samples: 0.424\n",
      "\n",
      "Fold 3 Results:\n",
      "Coarse-F1: 0.598\n",
      "Fine-F1: 0.424\n",
      "\n",
      "Training Fold 4/5\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n",
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.55\n",
      "Subnarrative threshold: 0.50\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.604\n",
      "F1 st. dev. coarse: 0.372\n",
      "Fine-F1: 0.450\n",
      "F1 st. dev. fine: 0.358\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.82      0.94      0.87        48\n",
      "                      CC: Climate change is beneficial       0.00      0.00      0.00         1\n",
      "              CC: Controversy about green technologies       0.09      0.25      0.13         4\n",
      "                     CC: Criticism of climate movement       0.62      0.71      0.67        14\n",
      "                     CC: Criticism of climate policies       0.50      0.68      0.58        22\n",
      "         CC: Criticism of institutions and authorities       0.60      0.84      0.70        32\n",
      "                        CC: Downplaying climate change       0.60      1.00      0.75         6\n",
      "       CC: Green policies are geopolitical instruments       0.50      0.50      0.50         2\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.50      0.56      0.53         9\n",
      "          CC: Questioning the measurements and science       1.00      0.50      0.67         6\n",
      "                                                 Other       0.59      0.71      0.64        68\n",
      "                     URW: Amplifying war-related fears       0.65      0.66      0.65        56\n",
      "URW: Blaming the war on others rather than the invader       0.41      0.47      0.44        45\n",
      "                             URW: Discrediting Ukraine       0.67      0.86      0.76        88\n",
      "                 URW: Discrediting the West, Diplomacy       0.65      0.64      0.64        83\n",
      "                           URW: Distrust towards Media       0.56      0.33      0.42        15\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.30      0.60      0.40         5\n",
      "               URW: Negative Consequences for the West       0.56      0.29      0.38        31\n",
      "                            URW: Overpraising the West       0.18      0.33      0.24         6\n",
      "                                 URW: Praise of Russia       0.63      0.57      0.60        86\n",
      "                             URW: Russia is the Victim       0.48      0.56      0.52        52\n",
      "                         URW: Speculating war outcomes       0.31      0.33      0.32        24\n",
      "\n",
      "                                             micro avg       0.58      0.64      0.61       703\n",
      "                                             macro avg       0.51      0.56      0.52       703\n",
      "                                          weighted avg       0.59      0.64      0.61       703\n",
      "                                           samples avg       0.61      0.66      0.60       703\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.298\n",
      "Recall: 0.406\n",
      "F1 Samples: 0.450\n",
      "\n",
      "Fold 4 Results:\n",
      "Coarse-F1: 0.604\n",
      "Fine-F1: 0.450\n",
      "\n",
      "Training Fold 5/5\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n",
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.55\n",
      "Subnarrative threshold: 0.55\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.590\n",
      "F1 st. dev. coarse: 0.370\n",
      "Fine-F1: 0.402\n",
      "F1 st. dev. fine: 0.353\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.81      0.96      0.88        50\n",
      "                      CC: Climate change is beneficial       0.00      0.00      0.00         5\n",
      "              CC: Controversy about green technologies       0.60      0.67      0.63         9\n",
      "                     CC: Criticism of climate movement       0.37      1.00      0.54        10\n",
      "                     CC: Criticism of climate policies       0.46      0.76      0.57        21\n",
      "         CC: Criticism of institutions and authorities       0.62      0.93      0.75        30\n",
      "                        CC: Downplaying climate change       0.60      0.75      0.67        16\n",
      "       CC: Green policies are geopolitical instruments       0.00      0.00      0.00         3\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.57      1.00      0.73         8\n",
      "          CC: Questioning the measurements and science       0.73      0.67      0.70        12\n",
      "                                                 Other       0.55      0.54      0.55        70\n",
      "                     URW: Amplifying war-related fears       0.82      0.69      0.75        54\n",
      "URW: Blaming the war on others rather than the invader       0.34      0.53      0.41        36\n",
      "                             URW: Discrediting Ukraine       0.61      0.78      0.68        98\n",
      "                 URW: Discrediting the West, Diplomacy       0.65      0.59      0.62        82\n",
      "                           URW: Distrust towards Media       0.33      0.12      0.18        16\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.40      0.40      0.40         5\n",
      "               URW: Negative Consequences for the West       0.35      0.35      0.35        17\n",
      "                            URW: Overpraising the West       0.14      0.08      0.11        12\n",
      "                                 URW: Praise of Russia       0.65      0.56      0.60        87\n",
      "                             URW: Russia is the Victim       0.49      0.41      0.44        54\n",
      "                         URW: Speculating war outcomes       0.29      0.43      0.34        23\n",
      "\n",
      "                                             micro avg       0.57      0.62      0.60       718\n",
      "                                             macro avg       0.47      0.56      0.50       718\n",
      "                                          weighted avg       0.58      0.62      0.59       718\n",
      "                                           samples avg       0.61      0.63      0.59       718\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.240\n",
      "Recall: 0.310\n",
      "F1 Samples: 0.402\n",
      "\n",
      "Fold 5 Results:\n",
      "Coarse-F1: 0.590\n",
      "Fine-F1: 0.402\n",
      "\n",
      "Cross-Validation Performance:\n",
      "Average Coarse-F1: 0.590 ± 0.010\n",
      "Average Fine-F1:   0.417 ± 0.019\n"
     ]
    }
   ],
   "source": [
    "simple_trainer = CrossValEnsembleTrainer(\n",
    "    model_class=MultiTaskClassifierMultiHead,\n",
    "    hidden_size=1024,\n",
    "    dropout_rate=0.4,\n",
    "    lr=0.001,\n",
    "    n_splits=5,\n",
    "    patience=10,\n",
    "    num_epochs=100,\n",
    ")\n",
    "ensemble_models, fold_results = simple_trainer.fit(sub_weight=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d752254e-edf2-41b5-9e72-b8837e844a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskClassifierMultiHeadConcat(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_narratives=len(mlb_narratives.classes_),\n",
    "        narrative_to_sub_map=narrative_to_sub_map,\n",
    "        dropout_rate=network_params['dropout']\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.shared_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size * 2),\n",
    "            nn.BatchNorm1d(hidden_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        self.narrative_head = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, num_narratives),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.subnarrative_heads = nn.ModuleDict()\n",
    "        for narr_idx, sub_indices in narrative_to_sub_map.items():\n",
    "            num_subs_for_this_narr = len(sub_indices)\n",
    "            self.subnarrative_heads[str(narr_idx)] = nn.Sequential(\n",
    "                nn.Linear(hidden_size * 2 + 1, num_subs_for_this_narr),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_out = self.shared_layer(x)\n",
    "\n",
    "        narr_probs = self.narrative_head(shared_out)\n",
    "\n",
    "        sub_probs_dict = {}\n",
    "        for narr_idx, head in self.subnarrative_heads.items():\n",
    "            conditioned_input = torch.cat((shared_out, narr_probs[:, int(narr_idx)].unsqueeze(1)), dim=1)\n",
    "            sub_probs_dict[narr_idx] = head(conditioned_input)\n",
    "\n",
    "        return narr_probs, sub_probs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ebf3f9d-de55-4332-a9d2-33816fe2d276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Fold 1/5\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n",
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.55\n",
      "Subnarrative threshold: 0.55\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.583\n",
      "F1 st. dev. coarse: 0.388\n",
      "Fine-F1: 0.410\n",
      "F1 st. dev. fine: 0.363\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.78      0.89      0.84        57\n",
      "                      CC: Climate change is beneficial       0.67      0.67      0.67         3\n",
      "              CC: Controversy about green technologies       0.50      0.33      0.40         9\n",
      "                     CC: Criticism of climate movement       0.50      0.77      0.61        13\n",
      "                     CC: Criticism of climate policies       0.54      0.63      0.58        30\n",
      "         CC: Criticism of institutions and authorities       0.75      0.78      0.76        50\n",
      "                        CC: Downplaying climate change       0.58      0.70      0.64        10\n",
      "       CC: Green policies are geopolitical instruments       1.00      0.33      0.50         3\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.38      0.62      0.48         8\n",
      "          CC: Questioning the measurements and science       0.62      0.83      0.71         6\n",
      "                                                 Other       0.53      0.60      0.56        70\n",
      "                     URW: Amplifying war-related fears       0.85      0.70      0.76        56\n",
      "URW: Blaming the war on others rather than the invader       0.41      0.53      0.46        34\n",
      "                             URW: Discrediting Ukraine       0.68      0.71      0.70        89\n",
      "                 URW: Discrediting the West, Diplomacy       0.78      0.52      0.62        81\n",
      "                           URW: Distrust towards Media       0.33      0.18      0.24        11\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.67      0.20      0.31        10\n",
      "               URW: Negative Consequences for the West       0.22      0.24      0.23        17\n",
      "                            URW: Overpraising the West       0.14      0.10      0.12        10\n",
      "                                 URW: Praise of Russia       0.64      0.60      0.62        87\n",
      "                             URW: Russia is the Victim       0.45      0.45      0.45        44\n",
      "                         URW: Speculating war outcomes       0.38      0.29      0.33        31\n",
      "\n",
      "                                             micro avg       0.61      0.60      0.60       729\n",
      "                                             macro avg       0.56      0.53      0.53       729\n",
      "                                          weighted avg       0.62      0.60      0.60       729\n",
      "                                           samples avg       0.61      0.61      0.58       729\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.295\n",
      "Recall: 0.323\n",
      "F1 Samples: 0.410\n",
      "\n",
      "Fold 1 Results:\n",
      "Coarse-F1: 0.583\n",
      "Fine-F1: 0.410\n",
      "\n",
      "Training Fold 2/5\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n",
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.55\n",
      "Subnarrative threshold: 0.50\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.602\n",
      "F1 st. dev. coarse: 0.369\n",
      "Fine-F1: 0.432\n",
      "F1 st. dev. fine: 0.348\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.72      1.00      0.84        42\n",
      "                      CC: Climate change is beneficial       1.00      0.50      0.67         2\n",
      "              CC: Controversy about green technologies       0.50      0.50      0.50         2\n",
      "                     CC: Criticism of climate movement       0.58      0.50      0.54        14\n",
      "                     CC: Criticism of climate policies       0.19      0.55      0.29        11\n",
      "         CC: Criticism of institutions and authorities       0.71      0.83      0.76        35\n",
      "                        CC: Downplaying climate change       0.83      0.38      0.53        13\n",
      "       CC: Green policies are geopolitical instruments       0.00      0.00      0.00         1\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.33      0.33      0.33         6\n",
      "          CC: Questioning the measurements and science       0.80      0.67      0.73         6\n",
      "                                                 Other       0.66      0.67      0.67        76\n",
      "                     URW: Amplifying war-related fears       0.75      0.59      0.66        56\n",
      "URW: Blaming the war on others rather than the invader       0.30      0.54      0.39        37\n",
      "                             URW: Discrediting Ukraine       0.62      0.82      0.71        97\n",
      "                 URW: Discrediting the West, Diplomacy       0.66      0.67      0.66        88\n",
      "                           URW: Distrust towards Media       0.50      0.33      0.40        12\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.00      0.00      0.00         7\n",
      "               URW: Negative Consequences for the West       0.47      0.32      0.38        25\n",
      "                            URW: Overpraising the West       0.00      0.00      0.00         8\n",
      "                                 URW: Praise of Russia       0.55      0.68      0.61        91\n",
      "                             URW: Russia is the Victim       0.37      0.57      0.45        46\n",
      "                         URW: Speculating war outcomes       0.31      0.48      0.38        25\n",
      "\n",
      "                                             micro avg       0.55      0.65      0.60       700\n",
      "                                             macro avg       0.49      0.50      0.48       700\n",
      "                                          weighted avg       0.57      0.65      0.60       700\n",
      "                                           samples avg       0.60      0.67      0.60       700\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.246\n",
      "Recall: 0.329\n",
      "F1 Samples: 0.432\n",
      "\n",
      "Fold 2 Results:\n",
      "Coarse-F1: 0.602\n",
      "Fine-F1: 0.432\n",
      "\n",
      "Training Fold 3/5\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n",
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.50\n",
      "Subnarrative threshold: 0.55\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.637\n",
      "F1 st. dev. coarse: 0.355\n",
      "Fine-F1: 0.451\n",
      "F1 st. dev. fine: 0.348\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.89      0.97      0.93        65\n",
      "                      CC: Climate change is beneficial       0.00      0.00      0.00         2\n",
      "              CC: Controversy about green technologies       0.78      0.58      0.67        12\n",
      "                     CC: Criticism of climate movement       0.35      1.00      0.52         8\n",
      "                     CC: Criticism of climate policies       0.65      0.68      0.67        25\n",
      "         CC: Criticism of institutions and authorities       0.64      0.83      0.72        36\n",
      "                        CC: Downplaying climate change       0.22      0.40      0.29         5\n",
      "       CC: Green policies are geopolitical instruments       0.00      0.00      0.00         3\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.38      0.50      0.43        10\n",
      "          CC: Questioning the measurements and science       0.75      1.00      0.86         3\n",
      "                                                 Other       0.72      0.60      0.66        65\n",
      "                     URW: Amplifying war-related fears       0.62      0.69      0.65        45\n",
      "URW: Blaming the war on others rather than the invader       0.35      0.51      0.41        45\n",
      "                             URW: Discrediting Ukraine       0.68      0.78      0.72        99\n",
      "                 URW: Discrediting the West, Diplomacy       0.63      0.60      0.62        87\n",
      "                           URW: Distrust towards Media       0.78      0.44      0.56        16\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.33      0.67      0.44         3\n",
      "               URW: Negative Consequences for the West       0.38      0.62      0.48        16\n",
      "                            URW: Overpraising the West       0.15      0.22      0.18         9\n",
      "                                 URW: Praise of Russia       0.61      0.74      0.67        84\n",
      "                             URW: Russia is the Victim       0.46      0.55      0.50        49\n",
      "                         URW: Speculating war outcomes       0.42      0.59      0.49        29\n",
      "\n",
      "                                             micro avg       0.59      0.68      0.63       716\n",
      "                                             macro avg       0.49      0.59      0.52       716\n",
      "                                          weighted avg       0.61      0.68      0.63       716\n",
      "                                           samples avg       0.64      0.70      0.64       716\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.270\n",
      "Recall: 0.328\n",
      "F1 Samples: 0.451\n",
      "\n",
      "Fold 3 Results:\n",
      "Coarse-F1: 0.637\n",
      "Fine-F1: 0.451\n",
      "\n",
      "Training Fold 4/5\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n",
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.55\n",
      "Subnarrative threshold: 0.50\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.589\n",
      "F1 st. dev. coarse: 0.387\n",
      "Fine-F1: 0.425\n",
      "F1 st. dev. fine: 0.368\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.82      0.97      0.89        60\n",
      "                      CC: Climate change is beneficial       0.00      0.00      0.00         5\n",
      "              CC: Controversy about green technologies       0.25      0.60      0.35         5\n",
      "                     CC: Criticism of climate movement       0.72      0.81      0.76        16\n",
      "                     CC: Criticism of climate policies       0.40      0.67      0.50        18\n",
      "         CC: Criticism of institutions and authorities       0.38      0.86      0.53        21\n",
      "                        CC: Downplaying climate change       0.64      0.54      0.58        13\n",
      "       CC: Green policies are geopolitical instruments       0.00      0.00      0.00         3\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.60      0.75      0.67        12\n",
      "          CC: Questioning the measurements and science       0.60      0.38      0.46         8\n",
      "                                                 Other       0.62      0.67      0.64        75\n",
      "                     URW: Amplifying war-related fears       0.73      0.71      0.72        52\n",
      "URW: Blaming the war on others rather than the invader       0.24      0.26      0.25        43\n",
      "                             URW: Discrediting Ukraine       0.63      0.74      0.68        84\n",
      "                 URW: Discrediting the West, Diplomacy       0.70      0.56      0.62        86\n",
      "                           URW: Distrust towards Media       0.67      0.27      0.38        15\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.00      0.00      0.00         4\n",
      "               URW: Negative Consequences for the West       0.43      0.12      0.18        26\n",
      "                            URW: Overpraising the West       0.00      0.00      0.00         4\n",
      "                                 URW: Praise of Russia       0.69      0.58      0.63        73\n",
      "                             URW: Russia is the Victim       0.39      0.30      0.34        47\n",
      "                         URW: Speculating war outcomes       0.23      0.39      0.29        18\n",
      "\n",
      "                                             micro avg       0.57      0.58      0.58       688\n",
      "                                             macro avg       0.44      0.46      0.43       688\n",
      "                                          weighted avg       0.58      0.58      0.57       688\n",
      "                                           samples avg       0.61      0.62      0.59       688\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.236\n",
      "Recall: 0.380\n",
      "F1 Samples: 0.425\n",
      "\n",
      "Fold 4 Results:\n",
      "Coarse-F1: 0.589\n",
      "Fine-F1: 0.425\n",
      "\n",
      "Training Fold 5/5\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n",
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.50\n",
      "Subnarrative threshold: 0.50\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.559\n",
      "F1 st. dev. coarse: 0.360\n",
      "Fine-F1: 0.390\n",
      "F1 st. dev. fine: 0.335\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.78      0.96      0.86        56\n",
      "                      CC: Climate change is beneficial       0.00      0.00      0.00         1\n",
      "              CC: Controversy about green technologies       0.43      0.50      0.46         6\n",
      "                     CC: Criticism of climate movement       0.40      0.75      0.52        16\n",
      "                     CC: Criticism of climate policies       0.43      0.67      0.52        24\n",
      "         CC: Criticism of institutions and authorities       0.48      0.94      0.63        33\n",
      "                        CC: Downplaying climate change       0.35      0.80      0.48        10\n",
      "       CC: Green policies are geopolitical instruments       0.00      0.00      0.00         2\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.59      0.59      0.59        17\n",
      "          CC: Questioning the measurements and science       0.50      0.57      0.53         7\n",
      "                                                 Other       0.62      0.45      0.53        66\n",
      "                     URW: Amplifying war-related fears       0.48      0.67      0.56        43\n",
      "URW: Blaming the war on others rather than the invader       0.35      0.62      0.44        42\n",
      "                             URW: Discrediting Ukraine       0.52      0.84      0.64        89\n",
      "                 URW: Discrediting the West, Diplomacy       0.49      0.67      0.57        66\n",
      "                           URW: Distrust towards Media       0.36      0.45      0.40        11\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.14      0.25      0.18         4\n",
      "               URW: Negative Consequences for the West       0.33      0.33      0.33        24\n",
      "                            URW: Overpraising the West       0.50      0.18      0.26        17\n",
      "                                 URW: Praise of Russia       0.50      0.85      0.63        79\n",
      "                             URW: Russia is the Victim       0.40      0.62      0.49        47\n",
      "                         URW: Speculating war outcomes       0.32      0.41      0.36        32\n",
      "\n",
      "                                             micro avg       0.48      0.68      0.56       692\n",
      "                                             macro avg       0.41      0.55      0.45       692\n",
      "                                          weighted avg       0.49      0.68      0.56       692\n",
      "                                           samples avg       0.52      0.67      0.56       692\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.229\n",
      "Recall: 0.377\n",
      "F1 Samples: 0.390\n",
      "\n",
      "Fold 5 Results:\n",
      "Coarse-F1: 0.559\n",
      "Fine-F1: 0.390\n",
      "\n",
      "Cross-Validation Performance:\n",
      "Average Coarse-F1: 0.594 ± 0.026\n",
      "Average Fine-F1:   0.422 ± 0.021\n"
     ]
    }
   ],
   "source": [
    "trainer_concat = CrossValEnsembleTrainer(\n",
    "    model_class=MultiTaskClassifierMultiHeadConcat,\n",
    "    hidden_size=2048,\n",
    "    dropout_rate=0.4,\n",
    "    lr=0.001,\n",
    "    n_splits=5,\n",
    "    patience=10,\n",
    "    num_epochs=100,\n",
    ")\n",
    "ensemble_models_concat, fold_results_concat = trainer_concat.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
