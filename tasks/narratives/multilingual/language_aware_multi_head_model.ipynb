{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "852c56be-3ebf-4f40-bf4e-53898a78ec63",
   "metadata": {},
   "source": [
    "# Semeval 2025 Task 10\n",
    "### Subtask 2: Narrative Classification\n",
    "\n",
    "Given a news article and a [two-level taxonomy of narrative labels](https://propaganda.math.unipd.it/semeval2025task10/NARRATIVE-TAXONOMIES.pdf) (where each narrative is subdivided into subnarratives) from a particular domain, assign to the article all the appropriate subnarrative labels. This is a multi-label multi-class document classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03220268-ecc3-4bf0-a8fb-cdf6413a32c7",
   "metadata": {},
   "source": [
    "## Loss Weighting by Language\n",
    "\n",
    "As of now,  we trained a model in 5 different languages just so that we can face the problem of having limited data. Our final submission is going to be in one of those languages. \n",
    "This is our current target right now, to make our model somewhat focus on a specified language.\n",
    "\n",
    "One way to account for that is to add an extra penalty in our current loss. We know the language of each training sample, so we can double or triple the loss for that sample, in a way to tell the model to pay more attention to it.\n",
    "\n",
    "This can help improve performance in a target language, especially when having limited data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f73c4c6-7246-4b25-b2c6-7a317f5d25da",
   "metadata": {},
   "source": [
    "We go ahead and do the boring stuff again by loading our pre-saved components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0c0bbce-4fbd-4523-9d4d-ef46b14fef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "root_dir = \"../../\"\n",
    "base_save_folder_dir = '../saved/'\n",
    "dataset_folder = os.path.join(base_save_folder_dir, 'Dataset')\n",
    "\n",
    "with open(os.path.join(dataset_folder, 'dataset_train_cleaned.pkl'), 'rb') as f:\n",
    "    dataset_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b419f7b3-706c-44e4-b9ee-20e72537b577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "      <th>narratives</th>\n",
       "      <th>subnarratives</th>\n",
       "      <th>narratives_encoded</th>\n",
       "      <th>subnarratives_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1161.txt</td>\n",
       "      <td>&lt;PARA&gt;в ближайшие два месяца сша будут стремит...</td>\n",
       "      <td>[URW: Blaming the war on others rather than th...</td>\n",
       "      <td>[The West are the aggressors, Other, The West ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1175.txt</td>\n",
       "      <td>&lt;PARA&gt;в ес испугались последствий популярности...</td>\n",
       "      <td>[URW: Discrediting the West, Diplomacy, URW: D...</td>\n",
       "      <td>[The West is weak, Other, The EU is divided]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1149.txt</td>\n",
       "      <td>&lt;PARA&gt;возможность признания аллы пугачевой ино...</td>\n",
       "      <td>[URW: Distrust towards Media]</td>\n",
       "      <td>[Western media is an instrument of propaganda]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1015.txt</td>\n",
       "      <td>&lt;PARA&gt;азаров рассказал о смене риторики киева ...</td>\n",
       "      <td>[URW: Discrediting Ukraine, URW: Discrediting ...</td>\n",
       "      <td>[Ukraine is a puppet of the West, Discrediting...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1001.txt</td>\n",
       "      <td>&lt;PARA&gt;в россиянах проснулась массовая любовь к...</td>\n",
       "      <td>[URW: Praise of Russia]</td>\n",
       "      <td>[Russia is a guarantor of peace and prosperity]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language       article_id  \\\n",
       "0       RU  RU-URW-1161.txt   \n",
       "1       RU  RU-URW-1175.txt   \n",
       "2       RU  RU-URW-1149.txt   \n",
       "3       RU  RU-URW-1015.txt   \n",
       "4       RU  RU-URW-1001.txt   \n",
       "\n",
       "                                             content  \\\n",
       "0  <PARA>в ближайшие два месяца сша будут стремит...   \n",
       "1  <PARA>в ес испугались последствий популярности...   \n",
       "2  <PARA>возможность признания аллы пугачевой ино...   \n",
       "3  <PARA>азаров рассказал о смене риторики киева ...   \n",
       "4  <PARA>в россиянах проснулась массовая любовь к...   \n",
       "\n",
       "                                          narratives  \\\n",
       "0  [URW: Blaming the war on others rather than th...   \n",
       "1  [URW: Discrediting the West, Diplomacy, URW: D...   \n",
       "2                      [URW: Distrust towards Media]   \n",
       "3  [URW: Discrediting Ukraine, URW: Discrediting ...   \n",
       "4                            [URW: Praise of Russia]   \n",
       "\n",
       "                                       subnarratives  \\\n",
       "0  [The West are the aggressors, Other, The West ...   \n",
       "1       [The West is weak, Other, The EU is divided]   \n",
       "2     [Western media is an instrument of propaganda]   \n",
       "3  [Ukraine is a puppet of the West, Discrediting...   \n",
       "4    [Russia is a guarantor of peace and prosperity]   \n",
       "\n",
       "                                  narratives_encoded  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                               subnarratives_encoded  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b611b9-f983-4724-9d7d-d46ff3688713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1781, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd076469-7d41-447d-8b2a-01ffc403b0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "BG    401\n",
       "PT    400\n",
       "EN    399\n",
       "HI    366\n",
       "RU    215\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91929ad6-26e8-4adb-b814-d2f7b5653a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "misc_folder = os.path.join(base_save_folder_dir, 'Misc')\n",
    "\n",
    "with open(os.path.join(misc_folder, 'narrative_to_subnarratives.pkl'), 'rb') as f:\n",
    "    narrative_to_subnarratives = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6bc9d85-cdc2-4520-9c2b-ac8dc9213849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'URW: Discrediting Ukraine': ['Rewriting Ukraine’s history',\n",
       "  'Ukraine is associated with nazism',\n",
       "  'Situation in Ukraine is hopeless',\n",
       "  'Discrediting Ukrainian nation and society',\n",
       "  'Discrediting Ukrainian military',\n",
       "  'Ukraine is a puppet of the West',\n",
       "  'Ukraine is a hub for criminal activities',\n",
       "  'Other',\n",
       "  'Discrediting Ukrainian government and officials and policies'],\n",
       " 'URW: Discrediting the West, Diplomacy': ['The EU is divided',\n",
       "  'West is tired of Ukraine',\n",
       "  'The West is weak',\n",
       "  'The West does not care about Ukraine, only about its interests',\n",
       "  'Other',\n",
       "  'The West is overreacting',\n",
       "  'Diplomacy does/will not work'],\n",
       " 'URW: Praise of Russia': ['Praise of Russian military might',\n",
       "  'Russian invasion has strong national support',\n",
       "  'Russia has international support from a number of countries and people',\n",
       "  'Praise of Russian President Vladimir Putin',\n",
       "  'Other',\n",
       "  'Russia is a guarantor of peace and prosperity'],\n",
       " 'URW: Russia is the Victim': ['Russia actions in Ukraine are only self-defence',\n",
       "  'The West is russophobic',\n",
       "  'UA is anti-RU extremists',\n",
       "  'Other'],\n",
       " 'URW: Distrust towards Media': ['Ukrainian media cannot be trusted',\n",
       "  'Other',\n",
       "  'Western media is an instrument of propaganda'],\n",
       " 'URW: Amplifying war-related fears': ['By continuing the war we risk WWIII',\n",
       "  'There is a real possibility that nuclear weapons will be employed',\n",
       "  'NATO should/will directly intervene',\n",
       "  'Other',\n",
       "  'Russia will also attack other countries'],\n",
       " 'URW: Blaming the war on others rather than the invader': ['Other',\n",
       "  'Ukraine is the aggressor',\n",
       "  'The West are the aggressors'],\n",
       " 'URW: Overpraising the West': ['The West has the strongest international support',\n",
       "  'The West belongs in the right side of history',\n",
       "  'Other',\n",
       "  'NATO will destroy Russia'],\n",
       " 'URW: Speculating war outcomes': ['Russian army will lose all the occupied territories',\n",
       "  'Russian army is collapsing',\n",
       "  'Other',\n",
       "  'Ukrainian army is collapsing'],\n",
       " 'URW: Hidden plots by secret schemes of powerful groups': ['Other'],\n",
       " 'Other': ['Other'],\n",
       " 'URW: Negative Consequences for the West': ['Sanctions imposed by Western countries will backfire',\n",
       "  'The conflict will increase the Ukrainian refugee flows to Europe',\n",
       "  'Other'],\n",
       " 'CC: Amplifying Climate Fears': ['Earth will be uninhabitable soon',\n",
       "  'Doomsday scenarios for humans',\n",
       "  'Whatever we do it is already too late',\n",
       "  'Other',\n",
       "  'Amplifying existing fears of global warming'],\n",
       " 'CC: Criticism of institutions and authorities': ['Criticism of national governments',\n",
       "  'Criticism of international entities',\n",
       "  'Criticism of the EU',\n",
       "  'Other',\n",
       "  'Criticism of political organizations and figures'],\n",
       " 'CC: Criticism of climate movement': ['Climate movement is corrupt',\n",
       "  'Climate movement is alarmist',\n",
       "  'Other',\n",
       "  'Ad hominem attacks on key activists'],\n",
       " 'CC: Downplaying climate change': ['Human activities do not impact climate change',\n",
       "  'Weather suggests the trend is global cooling',\n",
       "  'Temperature increase does not have significant impact',\n",
       "  'Ice is not melting',\n",
       "  'Climate cycles are natural',\n",
       "  'CO2 concentrations are too small to have an impact',\n",
       "  'Humans and nature will adapt to the changes',\n",
       "  'Other',\n",
       "  'Sea levels are not rising'],\n",
       " 'CC: Criticism of climate policies': ['Climate policies have negative impact on the economy',\n",
       "  'Climate policies are only for profit',\n",
       "  'Other',\n",
       "  'Climate policies are ineffective'],\n",
       " 'CC: Questioning the measurements and science': ['Scientific community is unreliable',\n",
       "  'Greenhouse effect/carbon dioxide do not drive climate change',\n",
       "  'Methodologies/metrics used are unreliable/faulty',\n",
       "  'Data shows no temperature increase',\n",
       "  'Other'],\n",
       " 'CC: Hidden plots by secret schemes of powerful groups': ['Climate agenda has hidden motives',\n",
       "  'Blaming global elites',\n",
       "  'Other'],\n",
       " 'CC: Climate change is beneficial': ['Temperature increase is beneficial',\n",
       "  'CO2 is beneficial',\n",
       "  'Other'],\n",
       " 'CC: Controversy about green technologies': ['Renewable energy is costly',\n",
       "  'Renewable energy is unreliable',\n",
       "  'Renewable energy is dangerous',\n",
       "  'Other'],\n",
       " 'CC: Green policies are geopolitical instruments': ['Green activities are a form of neo-colonialism',\n",
       "  'Climate-related international relations are abusive/exploitative',\n",
       "  'Other']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narrative_to_subnarratives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "024abfe7-45eb-49d5-82d7-5d19262c1b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_folder = os.path.join(base_save_folder_dir, 'LabelEncoders')\n",
    "\n",
    "with open(os.path.join(label_encoder_folder, 'mlb_narratives.pkl'), 'rb') as f:\n",
    "    mlb_narratives = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(label_encoder_folder, 'mlb_subnarratives.pkl'), 'rb') as f:\n",
    "    mlb_subnarratives = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ed1cc-3faf-4fbe-bc62-912ad4e29a46",
   "metadata": {},
   "source": [
    "We will be using `Stella` embeddings, as they have proved quite better than `KaLM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df5a3905-3ebe-4e0f-82de-b86ef2b1494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings_folder = os.path.join(base_save_folder_dir, 'Embeddings/embeddings_train_kalm.npy')\n",
    "\n",
    "def load_embeddings(filename):\n",
    "    return np.load(filename)\n",
    "\n",
    "train_embeddings = load_embeddings(embeddings_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a34d7b4f-af40-48e9-bed1-87c97b8a0a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dataset_folder, 'dataset_val_cleaned.pkl'), 'rb') as f:\n",
    "    dataset_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54f91fbc-c03c-41df-a9de-97e28e1f9ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_folder = os.path.join(base_save_folder_dir, 'Embeddings/embeddings_val_kalm.npy')\n",
    "\n",
    "val_embeddings = load_embeddings(embeddings_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "721ab153-b4d6-4dba-970d-66b1136f18c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset_and_embeddings(dataset, embeddings, condition_fn):\n",
    "    filtered_indices = dataset.index[dataset.apply(condition_fn, axis=1)].tolist()\n",
    "    \n",
    "    filtered_dataset = dataset.loc[filtered_indices]\n",
    "    filtered_embeddings = embeddings[filtered_indices]\n",
    "\n",
    "    return filtered_dataset, filtered_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8901a79f-c8ed-4dee-87f6-6042cb8f9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val, val_embeddings = filter_dataset_and_embeddings(\n",
    "    dataset_val,\n",
    "    val_embeddings, \n",
    "    lambda row: row[\"language\"] == \"EN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6145aee8-f5ec-4241-ab2f-b85513af4e95",
   "metadata": {},
   "source": [
    "Also, notice that we are getting validation data for English, since that is our target.\n",
    "\n",
    "However, we also have a some-what large amount of data hanging there, that we could take advantage in our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31f73db6-f69a-43fc-ba14-9079a72144ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val_non_en, val_embeddings_non_en = filter_dataset_and_embeddings(\n",
    "    dataset_val,\n",
    "    val_embeddings,\n",
    "    lambda row: row[\"language\"] != \"EN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cea1329-20c0-4c3e-ba13-1a8e02bf7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def custom_shuffling(data, embeddings, random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    shuffled_indices = np.arange(len(data))\n",
    "    np.random.shuffle(shuffled_indices)\n",
    "    \n",
    "    data = data.iloc[shuffled_indices].reset_index(drop=True)\n",
    "    embeddings = embeddings[shuffled_indices]\n",
    "\n",
    "    return data, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c03616b-db42-4988-b259-387063cb8762",
   "metadata": {},
   "source": [
    "For training, we concat the non-English validation data with the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e6ee9ad-b4c5-423c-96fa-c1495b25ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.concat([\n",
    "    dataset_train,  # All language training\n",
    "    dataset_val_non_en  # Adding non-English validation\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c83a32-1b53-45fa-ab24-69c381214fe9",
   "metadata": {},
   "source": [
    "We do the same for the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0720e35b-9efe-4a9e-a76e-15bfde4c888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = np.concatenate([\n",
    "    train_embeddings,\n",
    "    val_embeddings_non_en\n",
    "], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f9468f4-4223-4b51-896c-5d43b23d3bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, train_embeddings = custom_shuffling(dataset_train, train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e39118c-3fb5-4f06-8809-520391c012f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val, val_embeddings = custom_shuffling(dataset_val, val_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12b331f-972f-45fa-b3c5-9b6b895853a3",
   "metadata": {},
   "source": [
    "### 1.2 Remapping our subnarrative indices\n",
    "\n",
    "We know that our articls have many narratives, and each one maps to several subnarratives, creating a hierarchy.  \n",
    "The problem is, our `subnarratives_encoded` currently looks like a flat list of zeros:\n",
    "\n",
    "```\n",
    "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
    "```\n",
    "\n",
    "But we need it to reflect the hierarchy properly:\n",
    "\n",
    "So, we break it down into a list of lists—each inner list represents the true labels for a specific hierarchy:\n",
    "\n",
    "```\n",
    "[[0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0] , [0, 0, 0, ...\n",
    " ^ hierarchy 0       ^ hierarchy 1          ^ hierarchy 2 ...\n",
    "```\n",
    "\n",
    "This will help us significantly later when we need to know for a specific article, the true subnarrative labels for a specific hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "020b2582-5702-44ae-9731-3dd5cbbee0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "misc_folder = os.path.join(base_save_folder_dir, 'Misc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a09452c4-fbe0-42fe-9a5c-55cdd7d5ecde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{13: [39, 66, 50, 22, 21, 65, 64, 33, 20], 14: [53, 71, 60, 56, 33, 58, 19], 19: [35, 46, 41, 34, 33, 42], 20: [40, 59, 63, 33], 15: [69, 33, 72], 11: [3, 62, 31, 33, 43], 12: [33, 67, 54], 18: [57, 55, 33, 32], 21: [45, 44, 33, 68], 16: [33], 10: [33], 17: [47, 61, 33], 0: [24, 23, 73, 33, 1], 5: [15, 14, 17, 33, 16], 3: [9, 8, 33, 0], 6: [27, 70, 51, 29, 7, 4, 28, 33, 49], 4: [12, 11, 33, 10], 9: [48, 26, 30, 18, 33], 8: [6, 2, 33], 1: [52, 5, 33], 2: [36, 38, 37, 33], 7: [25, 13, 33]}\n"
     ]
    }
   ],
   "source": [
    "narrative_to_sub_map = {}\n",
    "narrative_classes = list(mlb_narratives.classes_)\n",
    "subnarrative_classes = list(mlb_subnarratives.classes_)\n",
    "\n",
    "for narrative, subnarratives in narrative_to_subnarratives.items():\n",
    "    narrative_idx = narrative_classes.index(narrative)\n",
    "    subnarrative_indices = [subnarrative_classes.index(sub) for sub in subnarratives]\n",
    "    narrative_to_sub_map[narrative_idx] = subnarrative_indices\n",
    "\n",
    "print(narrative_to_sub_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadb2c4e-18fd-4988-8ef2-d09ac65028bc",
   "metadata": {},
   "source": [
    "Now, we remap the `subnarratives_encoded` list to reflect the correct hierarchy for each article.  \n",
    "* For each narrative, we grab its corresponding subnarrative indices from `narrative_to_sub_map` and assign the sublabels to the appropriate hierarchy column.  \n",
    "\n",
    "This will give us a new set of columns where each one contains the true subnarrative labels for that narrative hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95e7e28e-57d4-4c5d-89af-547d71c91879",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy_new_column_name = \"narrative_hierarchy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35a8ac8e-83dc-426d-b950-836d29b9ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_subnarratives(row, narrative_to_sub_map):\n",
    "    \"\"\"Takes in a row and encodes the current subnarrative list to the associated hierarchy based on the narr-subnar map\"\"\"\n",
    "    for narr_idx, sub_indices in narrative_to_sub_map.items():\n",
    "        sub_labels = [row['subnarratives_encoded'][sub_idx] for sub_idx in sub_indices]\n",
    "        col_name = f\"{hierarchy_new_column_name}_{narr_idx}\"\n",
    "        row[col_name] = sub_labels\n",
    "    return row\n",
    "\n",
    "dataset_train_cpy = dataset_train.apply(remap_subnarratives, axis=1, args=(narrative_to_sub_map,)).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3297861-7291-4c6e-8b81-4a3296bb7dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val_cpy = dataset_val.apply(remap_subnarratives, axis=1, args=(narrative_to_sub_map,)).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb885857-6165-404e-932d-3b36450915c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "      <th>narratives</th>\n",
       "      <th>subnarratives</th>\n",
       "      <th>narratives_encoded</th>\n",
       "      <th>subnarratives_encoded</th>\n",
       "      <th>narrative_hierarchy_13</th>\n",
       "      <th>narrative_hierarchy_14</th>\n",
       "      <th>narrative_hierarchy_19</th>\n",
       "      <th>...</th>\n",
       "      <th>narrative_hierarchy_0</th>\n",
       "      <th>narrative_hierarchy_5</th>\n",
       "      <th>narrative_hierarchy_3</th>\n",
       "      <th>narrative_hierarchy_6</th>\n",
       "      <th>narrative_hierarchy_4</th>\n",
       "      <th>narrative_hierarchy_9</th>\n",
       "      <th>narrative_hierarchy_8</th>\n",
       "      <th>narrative_hierarchy_1</th>\n",
       "      <th>narrative_hierarchy_2</th>\n",
       "      <th>narrative_hierarchy_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EN</td>\n",
       "      <td>EN_UA_DEV_100029.txt</td>\n",
       "      <td>&lt;PARA&gt;general Milley: russian military stocks ...</td>\n",
       "      <td>[URW: Speculating war outcomes]</td>\n",
       "      <td>[Russian army is collapsing]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EN</td>\n",
       "      <td>EN_CC_200050.txt</td>\n",
       "      <td>&lt;PARA&gt;link to major banks bend the knee to cli...</td>\n",
       "      <td>[Other]</td>\n",
       "      <td>[Other]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EN</td>\n",
       "      <td>EN_UA_DEV_100026.txt</td>\n",
       "      <td>&lt;PARA&gt;how green fanaticism and the sanctions r...</td>\n",
       "      <td>[URW: Negative Consequences for the West]</td>\n",
       "      <td>[Sanctions imposed by Western countries will b...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EN</td>\n",
       "      <td>EN_CC_200077.txt</td>\n",
       "      <td>&lt;PARA&gt;obey the green: blue states depriving ru...</td>\n",
       "      <td>[CC: Criticism of institutions and authorities...</td>\n",
       "      <td>[Criticism of political organizations and figu...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[1, 0, 0, 1, 1]</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 1, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EN</td>\n",
       "      <td>EN_UA_DEV_100013.txt</td>\n",
       "      <td>&lt;PARA&gt;former commander-in-chief of Ukrainian A...</td>\n",
       "      <td>[URW: Discrediting Ukraine, URW: Blaming the w...</td>\n",
       "      <td>[Discrediting Ukrainian government and officia...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 1, 0, 0, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  language            article_id  \\\n",
       "0       EN  EN_UA_DEV_100029.txt   \n",
       "1       EN      EN_CC_200050.txt   \n",
       "2       EN  EN_UA_DEV_100026.txt   \n",
       "3       EN      EN_CC_200077.txt   \n",
       "4       EN  EN_UA_DEV_100013.txt   \n",
       "\n",
       "                                             content  \\\n",
       "0  <PARA>general Milley: russian military stocks ...   \n",
       "1  <PARA>link to major banks bend the knee to cli...   \n",
       "2  <PARA>how green fanaticism and the sanctions r...   \n",
       "3  <PARA>obey the green: blue states depriving ru...   \n",
       "4  <PARA>former commander-in-chief of Ukrainian A...   \n",
       "\n",
       "                                          narratives  \\\n",
       "0                    [URW: Speculating war outcomes]   \n",
       "1                                            [Other]   \n",
       "2          [URW: Negative Consequences for the West]   \n",
       "3  [CC: Criticism of institutions and authorities...   \n",
       "4  [URW: Discrediting Ukraine, URW: Blaming the w...   \n",
       "\n",
       "                                       subnarratives  \\\n",
       "0                       [Russian army is collapsing]   \n",
       "1                                            [Other]   \n",
       "2  [Sanctions imposed by Western countries will b...   \n",
       "3  [Criticism of political organizations and figu...   \n",
       "4  [Discrediting Ukrainian government and officia...   \n",
       "\n",
       "                                  narratives_encoded  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "\n",
       "                               subnarratives_encoded  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "        narrative_hierarchy_13 narrative_hierarchy_14 narrative_hierarchy_19  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0]     [0, 0, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 1, 0]  [0, 0, 0, 0, 1, 0, 0]     [0, 0, 0, 0, 1, 0]   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0]  [0, 0, 0, 0, 0, 0, 0]     [0, 0, 0, 0, 0, 0]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 1, 0]  [0, 0, 0, 0, 1, 0, 0]     [0, 0, 0, 0, 1, 0]   \n",
       "4  [0, 1, 0, 0, 1, 0, 0, 1, 1]  [0, 0, 0, 0, 1, 0, 0]     [0, 0, 0, 0, 1, 0]   \n",
       "\n",
       "   ... narrative_hierarchy_0 narrative_hierarchy_5 narrative_hierarchy_3  \\\n",
       "0  ...       [0, 0, 0, 0, 0]       [0, 0, 0, 0, 0]          [0, 0, 0, 0]   \n",
       "1  ...       [0, 0, 0, 1, 0]       [0, 0, 0, 1, 0]          [0, 0, 1, 0]   \n",
       "2  ...       [0, 0, 0, 0, 0]       [0, 0, 0, 0, 0]          [0, 0, 0, 0]   \n",
       "3  ...       [0, 0, 0, 1, 0]       [1, 0, 0, 1, 1]          [0, 0, 1, 0]   \n",
       "4  ...       [0, 0, 0, 1, 0]       [0, 0, 0, 1, 0]          [0, 0, 1, 0]   \n",
       "\n",
       "         narrative_hierarchy_6 narrative_hierarchy_4 narrative_hierarchy_9  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0]          [0, 0, 0, 0]       [0, 0, 0, 0, 0]   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 1, 0]          [0, 0, 1, 0]       [0, 0, 0, 0, 1]   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0]          [0, 0, 0, 0]       [0, 0, 0, 0, 0]   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 1, 0]          [0, 1, 1, 0]       [0, 0, 0, 0, 1]   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 1, 0]          [0, 0, 1, 0]       [0, 0, 0, 0, 1]   \n",
       "\n",
       "  narrative_hierarchy_8 narrative_hierarchy_1 narrative_hierarchy_2  \\\n",
       "0             [0, 0, 0]             [0, 0, 0]          [0, 0, 0, 0]   \n",
       "1             [0, 0, 1]             [0, 0, 1]          [0, 0, 0, 1]   \n",
       "2             [0, 0, 0]             [0, 0, 0]          [0, 0, 0, 0]   \n",
       "3             [0, 0, 1]             [0, 0, 1]          [0, 0, 0, 1]   \n",
       "4             [0, 0, 1]             [0, 0, 1]          [0, 0, 0, 1]   \n",
       "\n",
       "  narrative_hierarchy_7  \n",
       "0             [0, 0, 0]  \n",
       "1             [0, 0, 1]  \n",
       "2             [0, 0, 0]  \n",
       "3             [0, 1, 1]  \n",
       "4             [0, 0, 1]  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val_cpy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3a87262-98d7-4402-ace3-6709026e4b27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of narrative_hierarchy_13:\n",
      "0    [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "1    [1, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "2    [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "3    [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "4    [0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
      "Name: narrative_hierarchy_13, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_14:\n",
      "0    [0, 0, 0, 0, 1, 0, 0]\n",
      "1    [0, 0, 0, 0, 1, 0, 0]\n",
      "2    [0, 0, 0, 0, 1, 0, 0]\n",
      "3    [0, 0, 0, 0, 0, 0, 0]\n",
      "4    [0, 0, 0, 0, 0, 0, 0]\n",
      "Name: narrative_hierarchy_14, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_19:\n",
      "0    [0, 0, 0, 0, 1, 0]\n",
      "1    [0, 0, 0, 0, 1, 0]\n",
      "2    [0, 0, 0, 0, 1, 0]\n",
      "3    [0, 0, 1, 0, 0, 0]\n",
      "4    [0, 0, 0, 0, 0, 0]\n",
      "Name: narrative_hierarchy_19, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_20:\n",
      "0    [0, 0, 0, 1]\n",
      "1    [0, 0, 0, 1]\n",
      "2    [0, 0, 0, 1]\n",
      "3    [0, 0, 0, 0]\n",
      "4    [0, 0, 0, 0]\n",
      "Name: narrative_hierarchy_20, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_15:\n",
      "0    [0, 1, 0]\n",
      "1    [0, 1, 0]\n",
      "2    [0, 1, 0]\n",
      "3    [0, 0, 0]\n",
      "4    [0, 0, 0]\n",
      "Name: narrative_hierarchy_15, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_11:\n",
      "0    [0, 0, 0, 1, 0]\n",
      "1    [1, 1, 0, 1, 0]\n",
      "2    [0, 0, 0, 1, 0]\n",
      "3    [0, 0, 0, 0, 0]\n",
      "4    [0, 0, 0, 0, 0]\n",
      "Name: narrative_hierarchy_11, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_12:\n",
      "0    [1, 0, 0]\n",
      "1    [1, 0, 1]\n",
      "2    [1, 0, 0]\n",
      "3    [0, 0, 0]\n",
      "4    [0, 0, 0]\n",
      "Name: narrative_hierarchy_12, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_18:\n",
      "0    [0, 0, 1, 0]\n",
      "1    [0, 0, 1, 0]\n",
      "2    [0, 0, 1, 0]\n",
      "3    [0, 0, 0, 0]\n",
      "4    [0, 0, 0, 0]\n",
      "Name: narrative_hierarchy_18, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_21:\n",
      "0    [0, 0, 1, 0]\n",
      "1    [0, 0, 1, 0]\n",
      "2    [0, 0, 1, 0]\n",
      "3    [0, 0, 0, 0]\n",
      "4    [0, 0, 0, 1]\n",
      "Name: narrative_hierarchy_21, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_16:\n",
      "0    [1]\n",
      "1    [1]\n",
      "2    [1]\n",
      "3    [0]\n",
      "4    [0]\n",
      "Name: narrative_hierarchy_16, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_10:\n",
      "0    [1]\n",
      "1    [1]\n",
      "2    [1]\n",
      "3    [0]\n",
      "4    [0]\n",
      "Name: narrative_hierarchy_10, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_17:\n",
      "0    [0, 0, 1]\n",
      "1    [0, 0, 1]\n",
      "2    [0, 0, 1]\n",
      "3    [0, 0, 0]\n",
      "4    [0, 0, 0]\n",
      "Name: narrative_hierarchy_17, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_0:\n",
      "0    [0, 0, 0, 1, 0]\n",
      "1    [0, 0, 0, 1, 0]\n",
      "2    [0, 0, 0, 1, 0]\n",
      "3    [0, 0, 0, 0, 0]\n",
      "4    [0, 0, 0, 0, 0]\n",
      "Name: narrative_hierarchy_0, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_5:\n",
      "0    [0, 0, 0, 1, 0]\n",
      "1    [0, 0, 0, 1, 0]\n",
      "2    [0, 0, 0, 1, 0]\n",
      "3    [0, 0, 0, 0, 0]\n",
      "4    [0, 0, 0, 0, 0]\n",
      "Name: narrative_hierarchy_5, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_3:\n",
      "0    [0, 0, 1, 0]\n",
      "1    [0, 0, 1, 0]\n",
      "2    [0, 0, 1, 0]\n",
      "3    [0, 0, 0, 0]\n",
      "4    [0, 0, 0, 0]\n",
      "Name: narrative_hierarchy_3, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_6:\n",
      "0    [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "1    [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "2    [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "3    [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "4    [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Name: narrative_hierarchy_6, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_4:\n",
      "0    [0, 0, 1, 0]\n",
      "1    [0, 0, 1, 0]\n",
      "2    [0, 0, 1, 0]\n",
      "3    [0, 0, 0, 0]\n",
      "4    [0, 0, 0, 0]\n",
      "Name: narrative_hierarchy_4, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_9:\n",
      "0    [0, 0, 0, 0, 1]\n",
      "1    [0, 0, 0, 0, 1]\n",
      "2    [0, 0, 0, 0, 1]\n",
      "3    [0, 0, 0, 0, 0]\n",
      "4    [0, 0, 0, 0, 0]\n",
      "Name: narrative_hierarchy_9, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_8:\n",
      "0    [0, 0, 1]\n",
      "1    [0, 0, 1]\n",
      "2    [0, 0, 1]\n",
      "3    [0, 0, 0]\n",
      "4    [0, 0, 0]\n",
      "Name: narrative_hierarchy_8, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_1:\n",
      "0    [0, 0, 1]\n",
      "1    [0, 0, 1]\n",
      "2    [0, 0, 1]\n",
      "3    [0, 0, 0]\n",
      "4    [0, 0, 0]\n",
      "Name: narrative_hierarchy_1, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_2:\n",
      "0    [0, 0, 0, 1]\n",
      "1    [0, 0, 0, 1]\n",
      "2    [0, 0, 0, 1]\n",
      "3    [0, 0, 0, 0]\n",
      "4    [0, 0, 0, 0]\n",
      "Name: narrative_hierarchy_2, dtype: object\n",
      "\n",
      "\n",
      "Sample of narrative_hierarchy_7:\n",
      "0    [0, 0, 1]\n",
      "1    [0, 0, 1]\n",
      "2    [0, 0, 1]\n",
      "3    [0, 0, 0]\n",
      "4    [0, 0, 0]\n",
      "Name: narrative_hierarchy_7, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for narr_idx, sub_indices in narrative_to_sub_map.items():\n",
    "    dataset_hierarchy_col_name = f\"{hierarchy_new_column_name}_{narr_idx}\"\n",
    "    res = dataset_train_cpy[dataset_hierarchy_col_name]\n",
    "    print(f\"Sample of {dataset_hierarchy_col_name}:\")\n",
    "    print(res.head()) \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f98f1d4-13c4-40c6-8926-cf87c94f9e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narrative_order = sorted(narrative_to_sub_map.keys())\n",
    "narrative_order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a224f72d-78c3-4e9e-8071-971d6985b49f",
   "metadata": {},
   "source": [
    "Now we want to make sure that the true subnarratives for hierarchy 0 are in position 0 of the aggregated list, hierarchy 1 in position 1, and so on.  \n",
    "This ensures the subnarratives are ordered correctly in the final, aggregated list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2c1d08f-b4b5-4450-a04e-08d3ec63bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_subnarratives(row, narrative_order, narrative_to_sub_map):\n",
    "    \"\"\"Takes in a row, and aggregates all hierarchy columns to 1 list.\n",
    "    The encoded list will be a list of lists, starting from the first hierarchy\"\"\"\n",
    "    aggregated = []\n",
    "    for narr_idx in narrative_order:\n",
    "        column_name = f\"narrative_hierarchy_{narr_idx}\"\n",
    "        sub_labels = row[column_name]\n",
    "        aggregated.append(sub_labels)\n",
    "    return aggregated\n",
    "\n",
    "dataset_train['aggregated_subnarratives'] = dataset_train_cpy.apply(\n",
    "    aggregate_subnarratives,\n",
    "    axis=1,\n",
    "    args=(narrative_order, narrative_to_sub_map)\n",
    ")\n",
    "\n",
    "dataset_val['aggregated_subnarratives'] = dataset_val_cpy.apply(\n",
    "    aggregate_subnarratives,\n",
    "    axis=1,\n",
    "    args=(narrative_order, narrative_to_sub_map)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f01c2957-097c-4fa4-a9d5-238a7486df20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [[0, 0, 0, 1, 0], [0, 0, 1], [0, 0, 0, 1], [0,...\n",
       "1       [[0, 0, 0, 1, 0], [0, 0, 1], [0, 0, 0, 1], [0,...\n",
       "2       [[0, 0, 0, 1, 0], [0, 0, 1], [0, 0, 0, 1], [0,...\n",
       "3       [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...\n",
       "4       [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...\n",
       "                              ...                        \n",
       "1776    [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...\n",
       "1777    [[0, 0, 0, 1, 0], [0, 0, 1], [0, 0, 0, 1], [0,...\n",
       "1778    [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...\n",
       "1779    [[0, 0, 0, 1, 0], [0, 0, 1], [0, 0, 0, 1], [0,...\n",
       "1780    [[0, 0, 0, 1, 0], [0, 0, 1], [0, 0, 0, 1], [0,...\n",
       "Name: aggregated_subnarratives, Length: 1781, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train['aggregated_subnarratives']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb9a13a1-917f-47ca-b979-d21b3b7bf855",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sub_heads = dataset_train['aggregated_subnarratives'].to_numpy()\n",
    "y_val_sub_heads = dataset_val['aggregated_subnarratives'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e69f8235-7d2f-475e-9876-5166a3ced91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_embeddings_tensor = torch.tensor(train_embeddings, dtype=torch.float32)\n",
    "val_embeddings_tensor = torch.tensor(val_embeddings, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "410f575d-85e8-4d53-ba94-6b7e48b8a556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896\n"
     ]
    }
   ],
   "source": [
    "input_size = train_embeddings_tensor.shape[1]\n",
    "print(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63fa1546-578e-49a2-ac03-2b06c1d2fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_params = {\n",
    "    'lr': 0.001,\n",
    "    'hidden_size': 1024,\n",
    "    'dropout': 0.4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7664898e-69c8-4f74-99f3-9fabf247a671",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_nar = dataset_train['narratives_encoded'].tolist()\n",
    "y_val_nar = dataset_val['narratives_encoded'].tolist()\n",
    "\n",
    "y_train_sub_nar = dataset_train['subnarratives_encoded'].tolist()\n",
    "y_val_sub_nar = dataset_val['subnarratives_encoded'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74494f26-ae72-4a72-9ec9-bfab3d9b67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_nar = torch.tensor(y_train_nar, dtype=torch.float32)\n",
    "y_train_sub_nar = torch.tensor(y_train_sub_nar, dtype=torch.float32)\n",
    "\n",
    "y_val_nar = torch.tensor(y_val_nar, dtype=torch.float32)\n",
    "y_val_sub_nar = torch.tensor(y_val_sub_nar, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46fcaf5e-dee1-488d-8c79-f7c2f3d618bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_tensor = torch.tensor(train_embeddings, dtype=torch.float32)\n",
    "val_embeddings_tensor = torch.tensor(val_embeddings, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89bc1f13-5799-400f-b126-5cfe6fdc4375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def compute_class_weights(y_train):\n",
    "    total_samples = y_train.shape[0]\n",
    "    class_weights = []\n",
    "    for label in range(y_train.shape[1]):\n",
    "        pos_count = y_train[:, label].sum().item()\n",
    "        neg_count = total_samples - pos_count\n",
    "        pos_weight = total_samples / (2 * pos_count) if pos_count > 0 else 0\n",
    "        neg_weight = total_samples / (2 * neg_count) if neg_count > 0 else 0\n",
    "        class_weights.append((pos_weight, neg_weight))\n",
    "    return class_weights\n",
    "\n",
    "class WeightedBCELoss(nn.Module):\n",
    "    def __init__(self, class_weights):\n",
    "        super().__init__()\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def forward(self, probs, targets):\n",
    "        bce_loss = 0\n",
    "        epsilon = 1e-7\n",
    "        for i, (pos_weight, neg_weight) in enumerate(self.class_weights):\n",
    "            prob = probs[:, i]\n",
    "            bce = -pos_weight * targets[:, i] * torch.log(prob + epsilon) - \\\n",
    "                  neg_weight * (1 - targets[:, i]) * torch.log(1 - prob + epsilon)\n",
    "            bce_loss += bce.mean()\n",
    "        return bce_loss / len(self.class_weights)\n",
    "\n",
    "class_weights_sub_nar = compute_class_weights(y_val_sub_nar)\n",
    "class_weights_nar = compute_class_weights(y_val_nar)\n",
    "narrative_criterion = WeightedBCELoss(class_weights_nar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc839d6b-f588-436a-b5f0-464093ce986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_criterion_dict = {}\n",
    "\n",
    "for narr_idx, sub_indices in narrative_to_sub_map.items():\n",
    "    local_weights = [ class_weights_sub_nar[sub_i] for sub_i in sub_indices ]\n",
    "\n",
    "    sub_criterion = WeightedBCELoss(local_weights)\n",
    "    sub_criterion_dict[str(narr_idx)] = sub_criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494c44cc-cfb6-4c8f-80fe-df360cf0a659",
   "metadata": {},
   "source": [
    "We will also select the MultiHeadConcat Model, since this is the one appearing to do the best for our Fine-F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e92f161-370b-409e-bea0-4dc59a28d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskClassifierMultiHeadConcat(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_narratives=len(mlb_narratives.classes_),\n",
    "        narrative_to_sub_map=narrative_to_sub_map,\n",
    "        dropout_rate=network_params['dropout']\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.shared_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size * 2),\n",
    "            nn.BatchNorm1d(hidden_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        self.narrative_head = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, num_narratives),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.subnarrative_heads = nn.ModuleDict()\n",
    "        for narr_idx, sub_indices in narrative_to_sub_map.items():\n",
    "            num_subs_for_this_narr = len(sub_indices)\n",
    "            self.subnarrative_heads[str(narr_idx)] = nn.Sequential(\n",
    "                nn.Linear(hidden_size * 2 + 1, num_subs_for_this_narr),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_out = self.shared_layer(x)\n",
    "\n",
    "        narr_probs = self.narrative_head(shared_out)\n",
    "\n",
    "        sub_probs_dict = {}\n",
    "        for narr_idx, head in self.subnarrative_heads.items():\n",
    "            conditioned_input = torch.cat((shared_out, narr_probs[:, int(narr_idx)].unsqueeze(1)), dim=1)\n",
    "            sub_probs_dict[narr_idx] = head(conditioned_input)\n",
    "\n",
    "        return narr_probs, sub_probs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50b83196-b7fc-46ce-9e90-3cad23e1bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiTaskClassifierMultiHeadConcat(\n",
    "    input_size=input_size,\n",
    "    hidden_size=2048\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615aed4d-898f-43e7-a100-e8e6198c9add",
   "metadata": {},
   "source": [
    "We add the extra penalty for english samples\n",
    "\n",
    "* In the forwarding step, we check if the sample is an english one, and if it is we apply the extra weight upon the loss to essentially tell them model to pay more attention to those samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db85e674-51d2-4c47-9983-41410a48e2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageAwareMultiHeadLoss(nn.Module):\n",
    "    def __init__(self, narrative_criterion, sub_criterion_dict, \n",
    "                 condition_weight=0.8, sub_weight=0.5,\n",
    "                 english_weight=3.0):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.narrative_criterion = narrative_criterion\n",
    "        self.sub_criterion_dict = sub_criterion_dict\n",
    "        self.condition_weight = condition_weight\n",
    "        self.sub_weight = sub_weight\n",
    "        self.english_weight = english_weight\n",
    "\n",
    "    def forward(self, narr_probs, sub_probs_dict, y_narr, y_sub_heads, is_english):\n",
    "        is_english = is_english.to(narr_probs.device)\n",
    "        sample_weights = torch.where(is_english == 1, self.english_weight, 1.0)\n",
    "        \n",
    "        narr_loss = self.narrative_criterion(narr_probs, y_narr)\n",
    "        narr_loss = (narr_loss * sample_weights.unsqueeze(1)).mean()\n",
    "\n",
    "        sub_loss = 0.0\n",
    "        condition_loss = 0.0\n",
    "\n",
    "        for narr_idx_str, sub_probs in sub_probs_dict.items():\n",
    "            narr_idx = int(narr_idx_str)\n",
    "            y_sub = [row[narr_idx] for row in y_sub_heads]\n",
    "            y_sub_tensor = torch.tensor(y_sub, dtype=torch.float32, device=sub_probs.device)\n",
    "            sub_loss_func = self.sub_criterion_dict[narr_idx_str]\n",
    "            sub_batch_loss = sub_loss_func(sub_probs, y_sub_tensor)\n",
    "            sub_loss += (sub_batch_loss * sample_weights).mean()\n",
    "\n",
    "            narr_pred = narr_probs[:, narr_idx].unsqueeze(1)\n",
    "            condition_term = torch.abs(sub_probs * (1 - narr_pred)) + \\\n",
    "                             narr_pred * torch.abs(sub_probs - y_sub_tensor.unsqueeze(1))\n",
    "            condition_term = (condition_term * sample_weights.unsqueeze(1)).mean()\n",
    "            condition_loss += condition_term\n",
    "\n",
    "        sub_loss = sub_loss / len(sub_probs_dict)\n",
    "        condition_loss = condition_loss / len(sub_probs_dict)\n",
    "        total_loss = (1 - self.sub_weight) * narr_loss + self.sub_weight * sub_loss + \\\n",
    "                     self.condition_weight * condition_loss\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "818232af-9ada-48e2-bffc-a8c0b170c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_english_train = torch.tensor([1 if lang == 'EN' else 0 for lang in dataset_train['language']], \n",
    "                              dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dcdeba57-1029-407e-8f6c-f8f245e8bb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0.,  ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_english_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdb1e2a9-7369-449b-9195-1c30ef431fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_aware_loss = LanguageAwareMultiHeadLoss(\n",
    "    narrative_criterion=narrative_criterion,\n",
    "    sub_criterion_dict=sub_criterion_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f8b9c35-d86e-4a69-8bc1-616c9f9406dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_multihead(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn=language_aware_loss,\n",
    "    train_embeddings=train_embeddings_tensor,\n",
    "    y_train_nar=y_train_nar,\n",
    "    y_train_sub_heads=y_train_sub_heads,\n",
    "    val_embeddings=val_embeddings_tensor,\n",
    "    y_val_nar=y_val_nar,\n",
    "    y_val_sub_heads=y_val_sub_heads,\n",
    "    is_english_train=is_english_train, \n",
    "    patience=5,\n",
    "    num_epochs=100,\n",
    "    scheduler=None,\n",
    "    min_delta=0.001\n",
    "):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_narr_probs, train_sub_probs_dict = model(train_embeddings)\n",
    "\n",
    "        train_loss = loss_fn(\n",
    "            train_narr_probs, \n",
    "            train_sub_probs_dict, \n",
    "            y_train_nar, \n",
    "            y_train_sub_heads,\n",
    "            is_english_train\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_narr_probs, val_sub_probs_dict = model(val_embeddings)\n",
    "            is_english_val = torch.ones(len(val_embeddings), device=val_embeddings.device)\n",
    "            val_loss = loss_fn(\n",
    "                val_narr_probs, \n",
    "                val_sub_probs_dict, \n",
    "                y_val_nar, \n",
    "                y_val_sub_heads,\n",
    "                is_english_val\n",
    "            )\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "              f\"Training Loss: {train_loss.item():.4f}, \"\n",
    "              f\"Validation Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "            current_lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "            print(f\"Current Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "        if val_loss.item() < best_val_loss - min_delta:\n",
    "            best_val_loss = val_loss.item()\n",
    "            patience_counter = 0\n",
    "            best_model = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Validation loss did not significantly improve for {patience_counter} epoch(s).\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    if best_model:\n",
    "        model.load_state_dict(best_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f52b84b-04bf-411b-9835-59e027f833e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "def initialize_and_train_model(\n",
    "    model,\n",
    "    num_epochs=100,\n",
    "    lr=0.001,\n",
    "    patience=10,\n",
    "    use_scheduler=True,\n",
    "    scheduler_patience=3,\n",
    "    loss_fn=language_aware_loss,\n",
    "    num_subnarratives=len(mlb_subnarratives.classes_),\n",
    "    device='cpu'\n",
    "):\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    scheduler = None\n",
    "    if use_scheduler:\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=scheduler_patience)\n",
    "\n",
    "    trained_model = train_with_multihead(\n",
    "                                    model=model,\n",
    "                                    optimizer=optimizer,\n",
    "                                    scheduler=scheduler,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    patience=patience\n",
    "                                )\n",
    "    return trained_model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87eff7a5-59f7-4d8e-9d82-5adae872b486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 1.4956, Validation Loss: 3.0042\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 2/100, Training Loss: 0.9631, Validation Loss: 2.9521\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 3/100, Training Loss: 0.8044, Validation Loss: 2.9174\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 4/100, Training Loss: 0.7298, Validation Loss: 2.8871\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 5/100, Training Loss: 0.6824, Validation Loss: 2.8554\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 6/100, Training Loss: 0.6517, Validation Loss: 2.8209\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 7/100, Training Loss: 0.6227, Validation Loss: 2.7838\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 8/100, Training Loss: 0.5989, Validation Loss: 2.7436\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 9/100, Training Loss: 0.5794, Validation Loss: 2.7013\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 10/100, Training Loss: 0.5616, Validation Loss: 2.6592\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 11/100, Training Loss: 0.5492, Validation Loss: 2.6178\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 12/100, Training Loss: 0.5349, Validation Loss: 2.5775\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 13/100, Training Loss: 0.5223, Validation Loss: 2.5364\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 14/100, Training Loss: 0.5131, Validation Loss: 2.4942\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 15/100, Training Loss: 0.5019, Validation Loss: 2.4510\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 16/100, Training Loss: 0.4929, Validation Loss: 2.4066\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 17/100, Training Loss: 0.4844, Validation Loss: 2.3612\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 18/100, Training Loss: 0.4725, Validation Loss: 2.3156\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 19/100, Training Loss: 0.4634, Validation Loss: 2.2714\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 20/100, Training Loss: 0.4569, Validation Loss: 2.2299\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 21/100, Training Loss: 0.4499, Validation Loss: 2.1918\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 22/100, Training Loss: 0.4435, Validation Loss: 2.1576\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 23/100, Training Loss: 0.4347, Validation Loss: 2.1264\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 24/100, Training Loss: 0.4277, Validation Loss: 2.0972\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 25/100, Training Loss: 0.4199, Validation Loss: 2.0695\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 26/100, Training Loss: 0.4125, Validation Loss: 2.0437\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 27/100, Training Loss: 0.4063, Validation Loss: 2.0197\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 28/100, Training Loss: 0.3994, Validation Loss: 1.9978\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 29/100, Training Loss: 0.3935, Validation Loss: 1.9775\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 30/100, Training Loss: 0.3870, Validation Loss: 1.9585\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 31/100, Training Loss: 0.3810, Validation Loss: 1.9434\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 32/100, Training Loss: 0.3757, Validation Loss: 1.9324\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 33/100, Training Loss: 0.3688, Validation Loss: 1.9248\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 34/100, Training Loss: 0.3636, Validation Loss: 1.9173\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 35/100, Training Loss: 0.3578, Validation Loss: 1.9119\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 36/100, Training Loss: 0.3521, Validation Loss: 1.9119\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 37/100, Training Loss: 0.3477, Validation Loss: 1.9163\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 38/100, Training Loss: 0.3425, Validation Loss: 1.9262\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 39/100, Training Loss: 0.3373, Validation Loss: 1.9371\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Epoch 40/100, Training Loss: 0.3316, Validation Loss: 1.9394\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "trained_model, optimizer, scheduler = initialize_and_train_model(\n",
    "    model,\n",
    "    patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0221d707-9320-4c0f-b25e-98e109cb9364",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_classes = sorted(narrative_to_subnarratives.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "550fa66e-d415-461d-9377-df45a0cbdf2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC: Amplifying Climate Fears',\n",
       " 'CC: Climate change is beneficial',\n",
       " 'CC: Controversy about green technologies',\n",
       " 'CC: Criticism of climate movement',\n",
       " 'CC: Criticism of climate policies',\n",
       " 'CC: Criticism of institutions and authorities',\n",
       " 'CC: Downplaying climate change',\n",
       " 'CC: Green policies are geopolitical instruments',\n",
       " 'CC: Hidden plots by secret schemes of powerful groups',\n",
       " 'CC: Questioning the measurements and science',\n",
       " 'Other',\n",
       " 'URW: Amplifying war-related fears',\n",
       " 'URW: Blaming the war on others rather than the invader',\n",
       " 'URW: Discrediting Ukraine',\n",
       " 'URW: Discrediting the West, Diplomacy',\n",
       " 'URW: Distrust towards Media',\n",
       " 'URW: Hidden plots by secret schemes of powerful groups',\n",
       " 'URW: Negative Consequences for the West',\n",
       " 'URW: Overpraising the West',\n",
       " 'URW: Praise of Russia',\n",
       " 'URW: Russia is the Victim',\n",
       " 'URW: Speculating war outcomes']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "713c2c13-cbd4-4c5b-8008-922dd00bc9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_label_set = set()\n",
    "\n",
    "for narrative, subnarratives in narrative_to_subnarratives.items():\n",
    "    if narrative == \"Other\":\n",
    "        fine_label_set.add(\"Other\")\n",
    "    else:\n",
    "        for sub in subnarratives:\n",
    "            if sub == \"Other\":\n",
    "                fine_label_set.add(f\"{narrative}: Other\")\n",
    "            else:\n",
    "                fine_label_set.add(f\"{narrative}: {sub}\")\n",
    "\n",
    "fine_classes = sorted(fine_label_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "435caf0b-cbbe-4130-8782-28a408d3c9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC: Amplifying Climate Fears: Amplifying existing fears of global warming',\n",
       " 'CC: Amplifying Climate Fears: Doomsday scenarios for humans',\n",
       " 'CC: Amplifying Climate Fears: Earth will be uninhabitable soon',\n",
       " 'CC: Amplifying Climate Fears: Other',\n",
       " 'CC: Amplifying Climate Fears: Whatever we do it is already too late',\n",
       " 'CC: Climate change is beneficial: CO2 is beneficial',\n",
       " 'CC: Climate change is beneficial: Other',\n",
       " 'CC: Climate change is beneficial: Temperature increase is beneficial',\n",
       " 'CC: Controversy about green technologies: Other',\n",
       " 'CC: Controversy about green technologies: Renewable energy is costly',\n",
       " 'CC: Controversy about green technologies: Renewable energy is dangerous',\n",
       " 'CC: Controversy about green technologies: Renewable energy is unreliable',\n",
       " 'CC: Criticism of climate movement: Ad hominem attacks on key activists',\n",
       " 'CC: Criticism of climate movement: Climate movement is alarmist',\n",
       " 'CC: Criticism of climate movement: Climate movement is corrupt']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_classes[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "087519a2-98bb-425b-b836-8b093854684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List\n",
    "from sklearn import metrics\n",
    "\n",
    "class MultiHeadEvaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        classes_coarse=coarse_classes,\n",
    "        classes_fine=fine_classes,\n",
    "        narrative_to_sub_map=narrative_to_sub_map,\n",
    "        narrative_order=narrative_order,\n",
    "        narrative_classes=mlb_narratives.classes_,\n",
    "        subnarrative_classes=mlb_subnarratives.classes_,\n",
    "        device='cpu',\n",
    "        output_dir='../../../submissions',\n",
    "    ):\n",
    "        self.narrative_to_sub_map = narrative_to_sub_map\n",
    "        self.narrative_order = narrative_order\n",
    "        self.narrative_classes = list(narrative_classes)\n",
    "        self.subnarrative_classes = list(subnarrative_classes)\n",
    "        \n",
    "        self.classes_coarse = classes_coarse\n",
    "        self.classes_fine = classes_fine\n",
    "\n",
    "        self.device = device\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    def evaluate(\n",
    "        self,\n",
    "        model,\n",
    "        embeddings=val_embeddings_tensor,\n",
    "        dataset=dataset_val,\n",
    "        thresholds=None,\n",
    "        save=False,\n",
    "        std_weight=0.6,\n",
    "        lower_thres=0.1,\n",
    "        upper_thres=0.55\n",
    "    ):\n",
    "        if thresholds is None:\n",
    "            thresholds = np.arange(lower_thres, upper_thres, 0.05)    \n",
    "        embeddings = embeddings.to(self.device)\n",
    "    \n",
    "        best_results = {\n",
    "            'best_coarse_f1': -1,\n",
    "            'best_coarse_std': float('inf'),\n",
    "            'best_fine_f1': -1,\n",
    "            'best_fine_std': float('inf'),\n",
    "            'narr_threshold': 0,\n",
    "            'sub_threshold': 0,\n",
    "            'predictions': None,\n",
    "            'best_combined_score': -float('inf')\n",
    "        }\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            narr_probs, sub_probs_dict = model(embeddings)\n",
    "            narr_probs = narr_probs.cpu().numpy()\n",
    "            sub_probs_dict = {k: v.cpu().numpy() for k, v in sub_probs_dict.items()}\n",
    "    \n",
    "        for narr_threshold in thresholds:\n",
    "            for sub_threshold in thresholds:\n",
    "                predictions = []\n",
    "                for sample_idx, row in dataset.iterrows():\n",
    "                    pred = self._make_prediction(\n",
    "                        row['article_id'],\n",
    "                        sample_idx,\n",
    "                        narr_probs,\n",
    "                        sub_probs_dict,\n",
    "                        narr_threshold,\n",
    "                        sub_threshold\n",
    "                    )\n",
    "                    predictions.append(pred)\n",
    "                \n",
    "                f1_coarse_mean, coarse_std, f1_fine_mean, fine_std = self._compute_metrics_coarse_fine(\n",
    "                    predictions,\n",
    "                    dataset\n",
    "                )\n",
    "                \n",
    "                combined_score = f1_fine_mean - (std_weight * coarse_std)\n",
    "                \n",
    "                if combined_score > best_results['best_combined_score']:\n",
    "                    best_results.update({\n",
    "                        'best_coarse_f1': f1_coarse_mean,\n",
    "                        'best_coarse_std': coarse_std,\n",
    "                        'best_fine_f1': f1_fine_mean,\n",
    "                        'best_fine_std': fine_std,\n",
    "                        'narr_threshold': narr_threshold,\n",
    "                        'sub_threshold': sub_threshold,\n",
    "                        'predictions': predictions,\n",
    "                        'best_combined_score': combined_score\n",
    "                    })\n",
    "    \n",
    "        print(\"\\nBest thresholds found:\")\n",
    "        print(f\"Narrative threshold: {best_results['narr_threshold']:.2f}\")\n",
    "        print(f\"Subnarrative threshold: {best_results['sub_threshold']:.2f}\")\n",
    "        print('\\n')\n",
    "        print(f\"Coarse-F1: {best_results['best_coarse_f1']:.3f}\")\n",
    "        print(f\"F1 st. dev. coarse: {best_results['best_coarse_std']:.3f}\")\n",
    "        print(f\"Fine-F1: {best_results['best_fine_f1']:.3f} \")\n",
    "        print(f\"F1 st. dev. fine: {best_results['best_fine_std']:.3f}\")\n",
    "\n",
    "        if save:\n",
    "            self._save_predictions(best_results, os.path.join(self.output_dir, 'submission.txt'))\n",
    "        \n",
    "        return best_results\n",
    "\n",
    "    def _make_prediction(self, article_id, sample_idx, narr_probs, sub_probs_dict, narr_threshold, sub_threshold):\n",
    "        other_idx = self.narrative_classes.index(\"Other\")\n",
    "        # Find all narratives >= narr_threshold \n",
    "        # (except 'Other', this is going to be used as a fallback)\n",
    "        active_narratives = [\n",
    "            (n_idx, prob)\n",
    "            for n_idx, prob in enumerate(narr_probs[sample_idx])\n",
    "            if n_idx != other_idx and prob >= narr_threshold\n",
    "        ]\n",
    "        \n",
    "        if not active_narratives:\n",
    "            return {\n",
    "                'article_id': article_id,\n",
    "                'narratives': [\"Other\"],\n",
    "                'pairs': [\"Other\"]\n",
    "            }\n",
    "        \n",
    "        narratives = []\n",
    "        pairs = []\n",
    "        seen_pairs = set()\n",
    "        \n",
    "        active_narratives.sort(key=lambda x: x[1], reverse=True)\n",
    "        for narr_idx, narr_prob in active_narratives:\n",
    "            narr_name = self.narrative_classes[narr_idx]\n",
    "            \n",
    "            sub_probs = sub_probs_dict[str(narr_idx)][sample_idx]\n",
    "            active_subnarratives = [\n",
    "                (local_idx, s_prob)\n",
    "                for local_idx, s_prob in enumerate(sub_probs)\n",
    "                if s_prob >= sub_threshold\n",
    "            ]\n",
    "            active_subnarratives.sort(key=lambda x: x[1], reverse=True)\n",
    "            # Fallback, when no subnarrative active, we put other.\n",
    "            if not active_subnarratives:\n",
    "                pairs.append(f\"{narr_name}: Other\")\n",
    "            else:\n",
    "                for local_idx, _ in active_subnarratives:\n",
    "                    global_sub_idx = self.narrative_to_sub_map[narr_idx][local_idx]\n",
    "                    sub_name = self.subnarrative_classes[global_sub_idx]\n",
    "                    pair = f\"{narr_name}: {sub_name}\"\n",
    "                    if pair not in seen_pairs:\n",
    "                        pairs.append(pair)\n",
    "                        seen_pairs.add(pair)\n",
    "\n",
    "            narratives.append(narr_name)\n",
    "        \n",
    "        return {\n",
    "            'article_id': article_id,\n",
    "            'narratives': narratives,\n",
    "            'pairs': pairs\n",
    "        }\n",
    "\n",
    "    def _compute_metrics_coarse_fine(self, predictions, dataset):\n",
    "        \"\"\"\n",
    "        Mimics the official scorere used by the challenge.\n",
    "        \"\"\"\n",
    "        gold_coarse_all = []\n",
    "        gold_fine_all = []\n",
    "        pred_coarse_all = []\n",
    "        pred_fine_all = []\n",
    "\n",
    "        for pred, (_, row) in zip(predictions, dataset.iterrows()):\n",
    "            gold_coarse = row['narratives']\n",
    "            gold_subnarratives = row['subnarratives']\n",
    "            \n",
    "            pred_coarse = pred['narratives']\n",
    "            pred_fine = []\n",
    "            for p in pred['pairs']:\n",
    "                # If previously we predicted a \"Other\",\n",
    "                # we output \"Other Other\" as the narrative and subnarrative.\n",
    "                if p == \"Other\":\n",
    "                    pred_fine.append(\"Other\")\n",
    "                else:\n",
    "                    # Takes the whole nar : sub pair.\n",
    "                    pred_fine.append(p)\n",
    "\n",
    "            gold_fine = []\n",
    "            for gold_nar, gold_sub in zip(gold_coarse, gold_subnarratives):\n",
    "                # We do the same for truths.\n",
    "                if gold_nar == \"Other\":\n",
    "                    gold_fine.append(\"Other\")\n",
    "                else:\n",
    "                    gold_fine.append(f\"{gold_nar}: {gold_sub}\")\n",
    "            \n",
    "            gold_coarse_all.append(gold_coarse)\n",
    "            gold_fine_all.append(gold_fine)\n",
    "            pred_coarse_all.append(pred_coarse)\n",
    "            pred_fine_all.append(pred_fine)\n",
    "\n",
    "        f1_coarse_mean, coarse_std = self._evaluate_multi_label(gold_coarse_all, pred_coarse_all, self.classes_coarse)\n",
    "        f1_fine_mean, fine_std = self._evaluate_multi_label(gold_fine_all, pred_fine_all, self.classes_fine)\n",
    "\n",
    "        return f1_coarse_mean, coarse_std, f1_fine_mean, fine_std\n",
    "\n",
    "    def _evaluate_multi_label(self, gold, predicted, class_list):\n",
    "        \"\"\"\n",
    "        Mimics the official f1-score calculation used by the challenge.\n",
    "        \"\"\"\n",
    "        f1_scores = []\n",
    "        for g_labels, p_labels in zip(gold, predicted):\n",
    "            g_onehot = np.zeros(len(class_list), dtype=int)\n",
    "            for lab in g_labels:\n",
    "                if lab in class_list:\n",
    "                    g_onehot[class_list.index(lab)] = 1\n",
    "                    \n",
    "            p_onehot = np.zeros(len(class_list), dtype=int)\n",
    "            for lab in p_labels:\n",
    "                if lab in class_list:\n",
    "                    p_onehot[class_list.index(lab)] = 1\n",
    "\n",
    "            f1_doc = metrics.f1_score(g_onehot, p_onehot, zero_division=0)\n",
    "            f1_scores.append(f1_doc)\n",
    "        \n",
    "        return float(np.mean(f1_scores)), float(np.std(f1_scores))\n",
    "\n",
    "    def _save_predictions(self, best_results, filepath):\n",
    "        predictions = best_results['predictions']\n",
    "        if os.path.exists(filepath):\n",
    "            os.remove(filepath)\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            for pred in predictions:\n",
    "                line = (f\"{pred['article_id']}\\t\"\n",
    "                        f\"{';'.join(pred['narratives'])}\\t\"\n",
    "                        f\"{';'.join(pred['pairs'])}\\n\")\n",
    "                f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ebe71798-314a-40ce-8724-506db53bcaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MultiHeadEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d1c49c5-eaf8-47ec-874a-e056b1a22de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.45\n",
      "Subnarrative threshold: 0.35\n",
      "\n",
      "\n",
      "Coarse-F1: 0.463\n",
      "F1 st. dev. coarse: 0.382\n",
      "Fine-F1: 0.318 \n",
      "F1 st. dev. fine: 0.323\n"
     ]
    }
   ],
   "source": [
    "_ = evaluator.evaluate(\n",
    "    model=trained_model,\n",
    "    save=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
