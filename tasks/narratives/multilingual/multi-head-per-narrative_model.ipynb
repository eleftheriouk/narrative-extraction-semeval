{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b0d8ce9-d6d9-4e03-82e8-36fe1c5a343a",
   "metadata": {},
   "source": [
    "# Semeval 2025 Task 10\n",
    "### Subtask 2: Narrative Classification\n",
    "\n",
    "Given a news article and a [two-level taxonomy of narrative labels](https://propaganda.math.unipd.it/semeval2025task10/NARRATIVE-TAXONOMIES.pdf) (where each narrative is subdivided into subnarratives) from a particular domain, assign to the article all the appropriate subnarrative labels. This is a multi-label multi-class document classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaa2ebd-27af-46e1-aa7c-d2549cfc988a",
   "metadata": {},
   "source": [
    "## Multi-head per narrative model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc67788-7872-4608-ba0e-01fd263958cf",
   "metadata": {},
   "source": [
    "### 1.1 Loading pre-saved variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030d05fc-7c36-43ed-a942-bd6c8daf585d",
   "metadata": {},
   "source": [
    "We start by loading our pre-saved variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe27a15d-ab42-4768-a155-a65353545112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "root_dir = \"../../\"\n",
    "base_save_folder_dir = '../saved/'\n",
    "dataset_folder = os.path.join(base_save_folder_dir, 'Dataset')\n",
    "\n",
    "with open(os.path.join(dataset_folder, 'dataset_train_cleaned.pkl'), 'rb') as f:\n",
    "    dataset_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d58b84c-f126-4f5f-9f4c-883bd5b2741d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "      <th>narratives</th>\n",
       "      <th>subnarratives</th>\n",
       "      <th>narratives_encoded</th>\n",
       "      <th>subnarratives_encoded</th>\n",
       "      <th>aggregated_subnarratives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1161.txt</td>\n",
       "      <td>&lt;PARA&gt;в ближайшие два месяца сша будут стремит...</td>\n",
       "      <td>[URW: Blaming the war on others rather than th...</td>\n",
       "      <td>[The West are the aggressors, Other, The West ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1175.txt</td>\n",
       "      <td>&lt;PARA&gt;в ес испугались последствий популярности...</td>\n",
       "      <td>[URW: Discrediting the West, Diplomacy, URW: D...</td>\n",
       "      <td>[The West is weak, Other, The EU is divided]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1149.txt</td>\n",
       "      <td>&lt;PARA&gt;возможность признания аллы пугачевой ино...</td>\n",
       "      <td>[URW: Distrust towards Media]</td>\n",
       "      <td>[Western media is an instrument of propaganda]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1015.txt</td>\n",
       "      <td>&lt;PARA&gt;азаров рассказал о смене риторики киева ...</td>\n",
       "      <td>[URW: Discrediting Ukraine, URW: Discrediting ...</td>\n",
       "      <td>[Ukraine is a puppet of the West, Discrediting...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1001.txt</td>\n",
       "      <td>&lt;PARA&gt;в россиянах проснулась массовая любовь к...</td>\n",
       "      <td>[URW: Praise of Russia]</td>\n",
       "      <td>[Russia is a guarantor of peace and prosperity]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language       article_id  \\\n",
       "0       RU  RU-URW-1161.txt   \n",
       "1       RU  RU-URW-1175.txt   \n",
       "2       RU  RU-URW-1149.txt   \n",
       "3       RU  RU-URW-1015.txt   \n",
       "4       RU  RU-URW-1001.txt   \n",
       "\n",
       "                                             content  \\\n",
       "0  <PARA>в ближайшие два месяца сша будут стремит...   \n",
       "1  <PARA>в ес испугались последствий популярности...   \n",
       "2  <PARA>возможность признания аллы пугачевой ино...   \n",
       "3  <PARA>азаров рассказал о смене риторики киева ...   \n",
       "4  <PARA>в россиянах проснулась массовая любовь к...   \n",
       "\n",
       "                                          narratives  \\\n",
       "0  [URW: Blaming the war on others rather than th...   \n",
       "1  [URW: Discrediting the West, Diplomacy, URW: D...   \n",
       "2                      [URW: Distrust towards Media]   \n",
       "3  [URW: Discrediting Ukraine, URW: Discrediting ...   \n",
       "4                            [URW: Praise of Russia]   \n",
       "\n",
       "                                       subnarratives  \\\n",
       "0  [The West are the aggressors, Other, The West ...   \n",
       "1       [The West is weak, Other, The EU is divided]   \n",
       "2     [Western media is an instrument of propaganda]   \n",
       "3  [Ukraine is a puppet of the West, Discrediting...   \n",
       "4    [Russia is a guarantor of peace and prosperity]   \n",
       "\n",
       "                                  narratives_encoded  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                               subnarratives_encoded  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                            aggregated_subnarratives  \n",
       "0  [[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...  \n",
       "1  [[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...  \n",
       "2  [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...  \n",
       "3  [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...  \n",
       "4  [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e056632b-56d7-47ae-929b-cdda00d86a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "misc_folder = os.path.join(base_save_folder_dir, 'Misc')\n",
    "\n",
    "with open(os.path.join(misc_folder, 'narrative_to_subnarratives.pkl'), 'rb') as f:\n",
    "    narrative_to_subnarratives = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75b99343-2136-4f7f-a74f-218213d92ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(misc_folder, 'narrative_to_subnarratives_map.pkl'), 'rb') as f:\n",
    "    narrative_to_sub_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38b02083-0a1a-42d6-9378-5c41acac894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(misc_folder, 'coarse_classes.pkl'), 'rb') as f:\n",
    "    coarse_classes = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(misc_folder, 'fine_classes.pkl'), 'rb') as f:\n",
    "    fine_classes = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(misc_folder, 'narrative_order.pkl'), 'rb') as f:\n",
    "    narrative_order = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d2aae0-9952-4364-b1cc-8fadef6bd8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1781, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aae755a-3967-4790-8405-51b2a99594bd",
   "metadata": {},
   "source": [
    "We'll also need the actual hierarchy of narratives to subnarratives for our new model.  \n",
    "\n",
    "* Each narrative is also mapped to `Other`—this happens because if no subnarrative matches, we assign it to `Other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11550c30-6e80-4c4e-b262-ecec4d942892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'URW: Discrediting Ukraine': ['Discrediting Ukrainian government and officials and policies',\n",
       "  'Discrediting Ukrainian nation and society',\n",
       "  'Other',\n",
       "  'Ukraine is associated with nazism',\n",
       "  'Ukraine is a puppet of the West',\n",
       "  'Rewriting Ukraine’s history',\n",
       "  'Situation in Ukraine is hopeless',\n",
       "  'Discrediting Ukrainian military',\n",
       "  'Ukraine is a hub for criminal activities'],\n",
       " 'URW: Discrediting the West, Diplomacy': ['Diplomacy does/will not work',\n",
       "  'The EU is divided',\n",
       "  'West is tired of Ukraine',\n",
       "  'Other',\n",
       "  'The West does not care about Ukraine, only about its interests',\n",
       "  'The West is overreacting',\n",
       "  'The West is weak'],\n",
       " 'URW: Praise of Russia': ['Praise of Russian President Vladimir Putin',\n",
       "  'Russia has international support from a number of countries and people',\n",
       "  'Russia is a guarantor of peace and prosperity',\n",
       "  'Other',\n",
       "  'Russian invasion has strong national support',\n",
       "  'Praise of Russian military might'],\n",
       " 'URW: Russia is the Victim': ['Other',\n",
       "  'The West is russophobic',\n",
       "  'UA is anti-RU extremists',\n",
       "  'Russia actions in Ukraine are only self-defence'],\n",
       " 'URW: Distrust towards Media': ['Other',\n",
       "  'Ukrainian media cannot be trusted',\n",
       "  'Western media is an instrument of propaganda'],\n",
       " 'URW: Amplifying war-related fears': ['Russia will also attack other countries',\n",
       "  'Other',\n",
       "  'There is a real possibility that nuclear weapons will be employed',\n",
       "  'NATO should/will directly intervene',\n",
       "  'By continuing the war we risk WWIII'],\n",
       " 'URW: Blaming the war on others rather than the invader': ['Other',\n",
       "  'Ukraine is the aggressor',\n",
       "  'The West are the aggressors'],\n",
       " 'URW: Overpraising the West': ['Other',\n",
       "  'The West belongs in the right side of history',\n",
       "  'The West has the strongest international support',\n",
       "  'NATO will destroy Russia'],\n",
       " 'URW: Speculating war outcomes': ['Other',\n",
       "  'Russian army is collapsing',\n",
       "  'Russian army will lose all the occupied territories',\n",
       "  'Ukrainian army is collapsing'],\n",
       " 'URW: Hidden plots by secret schemes of powerful groups': ['Other'],\n",
       " 'Other': ['Other'],\n",
       " 'URW: Negative Consequences for the West': ['Other',\n",
       "  'Sanctions imposed by Western countries will backfire',\n",
       "  'The conflict will increase the Ukrainian refugee flows to Europe'],\n",
       " 'CC: Amplifying Climate Fears': ['Amplifying existing fears of global warming',\n",
       "  'Other',\n",
       "  'Earth will be uninhabitable soon',\n",
       "  'Doomsday scenarios for humans',\n",
       "  'Whatever we do it is already too late'],\n",
       " 'CC: Criticism of institutions and authorities': ['Other',\n",
       "  'Criticism of international entities',\n",
       "  'Criticism of the EU',\n",
       "  'Criticism of national governments',\n",
       "  'Criticism of political organizations and figures'],\n",
       " 'CC: Criticism of climate movement': ['Other',\n",
       "  'Climate movement is alarmist',\n",
       "  'Ad hominem attacks on key activists',\n",
       "  'Climate movement is corrupt'],\n",
       " 'CC: Downplaying climate change': ['Temperature increase does not have significant impact',\n",
       "  'Other',\n",
       "  'Human activities do not impact climate change',\n",
       "  'Sea levels are not rising',\n",
       "  'Climate cycles are natural',\n",
       "  'CO2 concentrations are too small to have an impact',\n",
       "  'Weather suggests the trend is global cooling',\n",
       "  'Ice is not melting',\n",
       "  'Humans and nature will adapt to the changes'],\n",
       " 'CC: Criticism of climate policies': ['Other',\n",
       "  'Climate policies are only for profit',\n",
       "  'Climate policies have negative impact on the economy',\n",
       "  'Climate policies are ineffective'],\n",
       " 'CC: Questioning the measurements and science': ['Data shows no temperature increase',\n",
       "  'Greenhouse effect/carbon dioxide do not drive climate change',\n",
       "  'Other',\n",
       "  'Methodologies/metrics used are unreliable/faulty',\n",
       "  'Scientific community is unreliable'],\n",
       " 'CC: Hidden plots by secret schemes of powerful groups': ['Other',\n",
       "  'Climate agenda has hidden motives',\n",
       "  'Blaming global elites'],\n",
       " 'CC: Climate change is beneficial': ['Other',\n",
       "  'CO2 is beneficial',\n",
       "  'Temperature increase is beneficial'],\n",
       " 'CC: Controversy about green technologies': ['Other',\n",
       "  'Renewable energy is costly',\n",
       "  'Renewable energy is unreliable',\n",
       "  'Renewable energy is dangerous'],\n",
       " 'CC: Green policies are geopolitical instruments': ['Other',\n",
       "  'Green activities are a form of neo-colonialism',\n",
       "  'Climate-related international relations are abusive/exploitative']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narrative_to_subnarratives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6912756b-47f2-4a11-b782-71f86ee25137",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_folder = os.path.join(base_save_folder_dir, 'LabelEncoders')\n",
    "\n",
    "with open(os.path.join(label_encoder_folder, 'mlb_narratives.pkl'), 'rb') as f:\n",
    "    mlb_narratives = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(label_encoder_folder, 'mlb_subnarratives.pkl'), 'rb') as f:\n",
    "    mlb_subnarratives = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45abdb04-673c-4fcd-8282-e1ec57a4b090",
   "metadata": {},
   "source": [
    "Finally, we get our embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "082080ec-bfbf-4db2-8363-2b06413a3ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings_folder = os.path.join(base_save_folder_dir, 'Embeddings/embeddings_train_qwen.npy')\n",
    "\n",
    "def load_embeddings(filename):\n",
    "    return np.load(filename)\n",
    "\n",
    "train_embeddings = load_embeddings(embeddings_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14c48702-e977-485c-8722-904b3719c86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1781, 1536)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e6c7197-a076-4ddc-addd-3e29a9f6b978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "      <th>narratives</th>\n",
       "      <th>subnarratives</th>\n",
       "      <th>narratives_encoded</th>\n",
       "      <th>subnarratives_encoded</th>\n",
       "      <th>aggregated_subnarratives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1161.txt</td>\n",
       "      <td>&lt;PARA&gt;в ближайшие два месяца сша будут стремит...</td>\n",
       "      <td>[URW: Blaming the war on others rather than th...</td>\n",
       "      <td>[The West are the aggressors, Other, The West ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1175.txt</td>\n",
       "      <td>&lt;PARA&gt;в ес испугались последствий популярности...</td>\n",
       "      <td>[URW: Discrediting the West, Diplomacy, URW: D...</td>\n",
       "      <td>[The West is weak, Other, The EU is divided]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1149.txt</td>\n",
       "      <td>&lt;PARA&gt;возможность признания аллы пугачевой ино...</td>\n",
       "      <td>[URW: Distrust towards Media]</td>\n",
       "      <td>[Western media is an instrument of propaganda]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1015.txt</td>\n",
       "      <td>&lt;PARA&gt;азаров рассказал о смене риторики киева ...</td>\n",
       "      <td>[URW: Discrediting Ukraine, URW: Discrediting ...</td>\n",
       "      <td>[Ukraine is a puppet of the West, Discrediting...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1001.txt</td>\n",
       "      <td>&lt;PARA&gt;в россиянах проснулась массовая любовь к...</td>\n",
       "      <td>[URW: Praise of Russia]</td>\n",
       "      <td>[Russia is a guarantor of peace and prosperity]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language       article_id  \\\n",
       "0       RU  RU-URW-1161.txt   \n",
       "1       RU  RU-URW-1175.txt   \n",
       "2       RU  RU-URW-1149.txt   \n",
       "3       RU  RU-URW-1015.txt   \n",
       "4       RU  RU-URW-1001.txt   \n",
       "\n",
       "                                             content  \\\n",
       "0  <PARA>в ближайшие два месяца сша будут стремит...   \n",
       "1  <PARA>в ес испугались последствий популярности...   \n",
       "2  <PARA>возможность признания аллы пугачевой ино...   \n",
       "3  <PARA>азаров рассказал о смене риторики киева ...   \n",
       "4  <PARA>в россиянах проснулась массовая любовь к...   \n",
       "\n",
       "                                          narratives  \\\n",
       "0  [URW: Blaming the war on others rather than th...   \n",
       "1  [URW: Discrediting the West, Diplomacy, URW: D...   \n",
       "2                      [URW: Distrust towards Media]   \n",
       "3  [URW: Discrediting Ukraine, URW: Discrediting ...   \n",
       "4                            [URW: Praise of Russia]   \n",
       "\n",
       "                                       subnarratives  \\\n",
       "0  [The West are the aggressors, Other, The West ...   \n",
       "1       [The West is weak, Other, The EU is divided]   \n",
       "2     [Western media is an instrument of propaganda]   \n",
       "3  [Ukraine is a puppet of the West, Discrediting...   \n",
       "4    [Russia is a guarantor of peace and prosperity]   \n",
       "\n",
       "                                  narratives_encoded  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                               subnarratives_encoded  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                            aggregated_subnarratives  \n",
       "0  [[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...  \n",
       "1  [[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...  \n",
       "2  [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...  \n",
       "3  [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...  \n",
       "4  [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b72fdc13-086a-4e20-9053-8078dbf87a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1781, 1536)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e062f4ea-aed6-4ec0-bdeb-aed875f92caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1781, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efe32714-ba24-447c-9bb1-04455e70e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dataset_folder, 'dataset_val_cleaned.pkl'), 'rb') as f:\n",
    "    dataset_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f3f5144-8c6a-4919-ada6-d9a477d7ff02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efe05792-a8f2-4976-bf42-3f5bb2ea3c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "      <th>narratives</th>\n",
       "      <th>subnarratives</th>\n",
       "      <th>narratives_encoded</th>\n",
       "      <th>subnarratives_encoded</th>\n",
       "      <th>aggregated_subnarratives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1014.txt</td>\n",
       "      <td>&lt;PARA&gt;алаудинов: российские силы растянули и р...</td>\n",
       "      <td>[URW: Praise of Russia]</td>\n",
       "      <td>[Praise of Russian military might]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1174.txt</td>\n",
       "      <td>&lt;PARA&gt;других сценариев нет. никаких переговоро...</td>\n",
       "      <td>[URW: Speculating war outcomes, URW: Discredit...</td>\n",
       "      <td>[Ukrainian army is collapsing, Discrediting Uk...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1166.txt</td>\n",
       "      <td>&lt;PARA&gt;попытка запада изолировать путина провал...</td>\n",
       "      <td>[URW: Praise of Russia, URW: Distrust towards ...</td>\n",
       "      <td>[Praise of Russian President Vladimir Putin, W...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1170.txt</td>\n",
       "      <td>&lt;PARA&gt;часть территории украины войдет в состав...</td>\n",
       "      <td>[URW: Discrediting Ukraine, URW: Speculating w...</td>\n",
       "      <td>[Discrediting Ukrainian government and officia...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RU</td>\n",
       "      <td>RU-URW-1004.txt</td>\n",
       "      <td>&lt;PARA&gt;зеленскому не очень понравилась идея о в...</td>\n",
       "      <td>[URW: Discrediting Ukraine, URW: Discrediting ...</td>\n",
       "      <td>[Discrediting Ukrainian government and officia...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language       article_id  \\\n",
       "0       RU  RU-URW-1014.txt   \n",
       "1       RU  RU-URW-1174.txt   \n",
       "2       RU  RU-URW-1166.txt   \n",
       "3       RU  RU-URW-1170.txt   \n",
       "4       RU  RU-URW-1004.txt   \n",
       "\n",
       "                                             content  \\\n",
       "0  <PARA>алаудинов: российские силы растянули и р...   \n",
       "1  <PARA>других сценариев нет. никаких переговоро...   \n",
       "2  <PARA>попытка запада изолировать путина провал...   \n",
       "3  <PARA>часть территории украины войдет в состав...   \n",
       "4  <PARA>зеленскому не очень понравилась идея о в...   \n",
       "\n",
       "                                          narratives  \\\n",
       "0                            [URW: Praise of Russia]   \n",
       "1  [URW: Speculating war outcomes, URW: Discredit...   \n",
       "2  [URW: Praise of Russia, URW: Distrust towards ...   \n",
       "3  [URW: Discrediting Ukraine, URW: Speculating w...   \n",
       "4  [URW: Discrediting Ukraine, URW: Discrediting ...   \n",
       "\n",
       "                                       subnarratives  \\\n",
       "0                 [Praise of Russian military might]   \n",
       "1  [Ukrainian army is collapsing, Discrediting Uk...   \n",
       "2  [Praise of Russian President Vladimir Putin, W...   \n",
       "3  [Discrediting Ukrainian government and officia...   \n",
       "4  [Discrediting Ukrainian government and officia...   \n",
       "\n",
       "                                  narratives_encoded  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, ...   \n",
       "\n",
       "                               subnarratives_encoded  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                            aggregated_subnarratives  \n",
       "0  [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...  \n",
       "1  [[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...  \n",
       "2  [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...  \n",
       "3  [[0, 1, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [1,...  \n",
       "4  [[0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0,...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edd234bd-0c1e-4dc2-8a94-fb2066d8d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_folder = os.path.join(base_save_folder_dir, 'Embeddings/embeddings_dev_qwen.npy')\n",
    "\n",
    "val_embeddings = load_embeddings(embeddings_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b283641-df9f-4605-af40-77f2483ecec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 1536)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaeece6-9c98-4b88-8464-0c44744ebffe",
   "metadata": {},
   "source": [
    "We will use this function to filter out specific rows based on a condition for both dataset and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c31fe348-2a01-49e7-bdde-57f766b03b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset_and_embeddings(dataset, embeddings, condition_fn):\n",
    "    filtered_indices = dataset.index[dataset.apply(condition_fn, axis=1)].tolist()\n",
    "    \n",
    "    filtered_dataset = dataset.loc[filtered_indices]\n",
    "    filtered_embeddings = embeddings[filtered_indices]\n",
    "\n",
    "    return filtered_dataset, filtered_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c445f249-6c66-4322-ae13-3bb509443075",
   "metadata": {},
   "source": [
    "More specifically here we only take the English validation data, since that is our focus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6677c80-d227-4770-864a-91ca479b46e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val, val_embeddings = filter_dataset_and_embeddings(\n",
    "        dataset_val, val_embeddings, lambda row: row[\"language\"] == \"EN\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d5e87a2-92ee-4a22-bb77-32dee467ee91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e427692-3fde-4edf-ad0e-35ea899b2ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 1536)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eeba09fb-dad2-4b26-9353-a40305aa0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e631c3fd-7ea3-44b2-a155-3a8af387513c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Setting random state\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "if random_state:\n",
    "    print('[WARNING] Setting random state')\n",
    "    torch.manual_seed(random_state)\n",
    "    np.random.seed(random_state) \n",
    "    random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c4ff2cd-76a5-4dae-b048-121422879c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_shuffling(data, embeddings):\n",
    "    shuffled_indices = np.arange(len(data))\n",
    "    np.random.shuffle(shuffled_indices)\n",
    "    \n",
    "    data = data.iloc[shuffled_indices].reset_index(drop=True)\n",
    "    embeddings = embeddings[shuffled_indices]\n",
    "\n",
    "    return data, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd17cc21-7e28-4043-b8f5-9bf89e2635f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, train_embeddings = custom_shuffling(dataset_train, train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ded2cbe8-fe43-40ac-8b97-ec0fe066dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val, val_embeddings = custom_shuffling(dataset_val, val_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a2641ae-1d2a-4ae5-be70-44f26d1ba3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "misc_folder = os.path.join(base_save_folder_dir, 'Misc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1968bf35-e93b-465e-b0a2-742953b808bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sub_heads = dataset_train['aggregated_subnarratives'].to_numpy()\n",
    "y_val_sub_heads = dataset_val['aggregated_subnarratives'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7227d2dd-e2f4-4190-aafa-9aa6b8fff6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "prefer_cpu=True\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available() and not prefer_cpu\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d41dde1e-10e6-46c9-a26e-78e4df738bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_embeddings_tensor = torch.tensor(train_embeddings, dtype=torch.float32).to(device)\n",
    "val_embeddings_tensor = torch.tensor(val_embeddings, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ff6872b-c06e-4450-b232-7d812eff12e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "input_size = train_embeddings_tensor.shape[1]\n",
    "print(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6475290-7dfc-4a1e-b58e-b92183ac93a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PT', 'HI', 'BG', 'EN', 'RU'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train['language'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44113e27-e31c-436b-8bde-519c2dd616ab",
   "metadata": {},
   "source": [
    "Base Classifier class to visualize our models using onnx:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "659a787c-8665-4295-a03a-2638598f1d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BaseClassifier(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.input_shape = (1, input_size)\n",
    "        self.model_name = \"base_model\"\n",
    "        self._visualize=False\n",
    "        \n",
    "    def visualize(self, filepath=None, dummy_input=None):\n",
    "        if not self._visualize:\n",
    "            print('Skipping visualization')\n",
    "            return\n",
    "        if filepath is None:\n",
    "            filepath = f'./visualizations/{self.model_name}.onnx'\n",
    "        \n",
    "        torch.onnx.export(\n",
    "            self,\n",
    "            dummy_input,\n",
    "            filepath,\n",
    "            export_params=True,\n",
    "            opset_version=11,\n",
    "            do_constant_folding=True,\n",
    "            input_names=['input'],\n",
    "            output_names=['narrative_output', 'subnarrative_outputs'],\n",
    "        )\n",
    "        \n",
    "        print(f\"Model exported to {filepath}\")\n",
    "        print(\"You can visualize this using Netron: https://netron.app/\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError(\n",
    "            \"Forward method must be implemented by subclasses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc9bf33-7994-4ed3-b508-93cc3d536582",
   "metadata": {},
   "source": [
    "Now we have a model with a shared layer that captures the general features of the article.  \n",
    "* The BatchNorm + ReLU combo seems to significantly improve performance by stabilizing training and speeding up convergence.\n",
    "* Also, it seems like the model overfits very quickly when becoming overly complex.\n",
    "  \n",
    "We make predictions for the top-level narratives, followed by separate subnarrative predictions for each narrative.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c3acef3-fa00-4d9e-bec9-0f9cacd9fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiTaskClassifierMultiHead(BaseClassifier):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size=1024,\n",
    "        num_narratives=len(mlb_narratives.classes_),\n",
    "        narrative_to_sub_map=narrative_to_sub_map,\n",
    "        dropout_rate=0.4,\n",
    "        model_name=\"MultiTaskClassifierMultiHead\" \n",
    "    ):\n",
    "        super().__init__(input_size)\n",
    "        self.model_name = model_name \n",
    "        \n",
    "        self.shared_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size * 2),\n",
    "            nn.BatchNorm1d(hidden_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        self.narrative_head = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, num_narratives),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.subnarrative_heads = nn.ModuleDict()\n",
    "        for narr_idx, sub_indices in narrative_to_sub_map.items():\n",
    "            num_subs_for_this_narr = len(sub_indices)\n",
    "            self.subnarrative_heads[str(narr_idx)] = nn.Sequential(\n",
    "                nn.Linear(hidden_size * 2, num_subs_for_this_narr),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_out = self.shared_layer(x)\n",
    "        narr_probs = self.narrative_head(shared_out)\n",
    "\n",
    "        sub_probs_dict = {}\n",
    "        for narr_idx, head in self.subnarrative_heads.items():\n",
    "            sub_probs_dict[narr_idx] = head(shared_out)\n",
    "\n",
    "        return narr_probs, sub_probs_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20f442d8-dc42-471e-b7b5-6374fb7948be",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_params = {\n",
    "    'lr': 0.001,\n",
    "    'hidden_size': 1024,\n",
    "    'dropout': 0.4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71b02d39-8af6-4cae-bde3-b82a663fbdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multi_head = MultiTaskClassifierMultiHead(\n",
    "    input_size=input_size,\n",
    "    hidden_size=1024,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae2c7c9f-e40e-4594-85ec-116e77958ff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiTaskClassifierMultiHead(\n",
      "  (shared_layer): Sequential(\n",
      "    (0): Linear(in_features=1536, out_features=2048, bias=True)\n",
      "    (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "  )\n",
      "  (narrative_head): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=22, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (subnarrative_heads): ModuleDict(\n",
      "    (13): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=9, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (14): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=7, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (19): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=6, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (20): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=4, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (15): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=3, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (11): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=5, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (12): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=3, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (18): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=4, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (21): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=4, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (16): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=1, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (10): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=1, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (17): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=3, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=5, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=5, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=4, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=9, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=4, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (9): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=5, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (8): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=3, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=3, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=4, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=3, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_multi_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ee84bbc-0176-4b32-b53f-02204b63c601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.17.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from onnx) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from onnx) (5.29.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aada979a-6dc4-46e2-b54c-07caeb95cfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping visualization\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, model_multi_head.input_size).to(device)\n",
    "model_multi_head.visualize(dummy_input=dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bfde290-d982-49fa-a89a-b48bb81a1f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_nar = dataset_train['narratives_encoded'].tolist()\n",
    "y_val_nar = dataset_val['narratives_encoded'].tolist()\n",
    "\n",
    "y_train_sub_nar = dataset_train['subnarratives_encoded'].tolist()\n",
    "y_val_sub_nar = dataset_val['subnarratives_encoded'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd3c347-5e6a-4c3a-835d-e1f2cb9a2440",
   "metadata": {},
   "source": [
    "We move everything to a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18b1217b-9e4b-4fcc-8cb1-4274f4bdd343",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_nar = torch.tensor(y_train_nar, dtype=torch.float32).to(device)\n",
    "y_train_sub_nar = torch.tensor(y_train_sub_nar, dtype=torch.float32).to(device)\n",
    "\n",
    "y_val_nar = torch.tensor(y_val_nar, dtype=torch.float32).to(device)\n",
    "y_val_sub_nar = torch.tensor(y_val_sub_nar, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1b730da-7939-4cdd-b725-a95d84624222",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings_tensor = torch.tensor(train_embeddings, dtype=torch.float32).to(device)\n",
    "val_embeddings_tensor = torch.tensor(val_embeddings, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeef867-9a58-4f41-b770-4dc50151a4be",
   "metadata": {},
   "source": [
    "We calculate class weights to handle label imbalance in the training data. \n",
    "* This way, rare labels are given higher importance to ensure the model learns them effectively.\n",
    "* The custom ```WeightedBCELoss``` applies these weights during training to balance the impact of common and rare labels, preventing the model from focusing only on frequent ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a10fe2bc-989e-40f5-9779-14d70ec69245",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_class_weights(y_train):\n",
    "    total_samples = y_train.shape[0]\n",
    "    class_weights = []\n",
    "    for label in range(y_train.shape[1]):\n",
    "        pos_count = y_train[:, label].sum().item()\n",
    "        neg_count = total_samples - pos_count\n",
    "        pos_weight = total_samples / (2 * pos_count) if pos_count > 0 else 0\n",
    "        neg_weight = total_samples / (2 * neg_count) if neg_count > 0 else 0\n",
    "        class_weights.append((pos_weight, neg_weight))\n",
    "    return class_weights\n",
    "\n",
    "class WeightedBCELoss(nn.Module):\n",
    "    def __init__(self, class_weights):\n",
    "        super().__init__()\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def forward(self, probs, targets):\n",
    "        bce_loss = 0\n",
    "        epsilon = 1e-7\n",
    "        for i, (pos_weight, neg_weight) in enumerate(self.class_weights):\n",
    "            prob = probs[:, i]\n",
    "            bce = -pos_weight * targets[:, i] * torch.log(prob + epsilon) - \\\n",
    "                  neg_weight * (1 - targets[:, i]) * torch.log(1 - prob + epsilon)\n",
    "            bce_loss += bce.mean()\n",
    "        return bce_loss / len(self.class_weights)\n",
    "\n",
    "class_weights_sub_nar = compute_class_weights(y_train_sub_nar)\n",
    "class_weights_nar = compute_class_weights(y_train_nar)\n",
    "narrative_criterion = WeightedBCELoss(class_weights_nar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc3da05-7d9a-4486-a4c3-2f899e1af47f",
   "metadata": {},
   "source": [
    "We create a separate loss function for each hierarchy of subnarratives to handle their specific class imbalance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b8e8505-b560-4307-85a3-7ef738cfb94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_criterion_dict = {}\n",
    "\n",
    "for narr_idx, sub_indices in narrative_to_sub_map.items():\n",
    "    local_weights = [ class_weights_sub_nar[sub_i] for sub_i in sub_indices ]\n",
    "\n",
    "    sub_criterion = WeightedBCELoss(local_weights)\n",
    "    sub_criterion_dict[str(narr_idx)] = sub_criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453f1ac5-fd61-441a-81db-f2b960b07427",
   "metadata": {},
   "source": [
    "We define a loss class to handle the multi-task loss calculation.\n",
    "\n",
    "* In the forward method, we first calculate the loss for the top-level narratives using the narrative criterion.\n",
    "We then loop through each subnarrative head and compute the loss for each one similarly.\n",
    "\n",
    "\n",
    "* We introduce a conditioning term that penalizes inconsistencies between narrative and subnarrative predictions. The conditioning term is there to match our hierarchical problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4cb3d662-fb28-402a-818e-5774dfb88e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a25509a-1532-4bf2-93b3-4651d9527af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if log:\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(\"./logs/loss_logs.log\")\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67dd421f-0d07-492d-b472-165199fcb43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadLoss(nn.Module):\n",
    "    def __init__(self, narrative_criterion, sub_criterion_dict, \n",
    "                 condition_weight=0.3, sub_weight=0.3):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.narrative_criterion = narrative_criterion\n",
    "        self.sub_criterion_dict = sub_criterion_dict\n",
    "        self.condition_weight = condition_weight\n",
    "        self.sub_weight = sub_weight\n",
    "        logging.info(\"MultiHeadLoss Start\")\n",
    "        \n",
    "    def forward(self, narr_probs, sub_probs_dict, y_narr, y_sub_heads):\n",
    "        narr_loss = self.narrative_criterion(narr_probs, y_narr)\n",
    "        sub_loss = 0.0\n",
    "        condition_loss = 0.0\n",
    "        \n",
    "        for narr_idx_str, sub_probs in sub_probs_dict.items():\n",
    "            narr_idx = int(narr_idx_str)\n",
    "            y_sub = [row[narr_idx] for row in y_sub_heads]\n",
    "            y_sub_tensor = torch.tensor(y_sub, dtype=torch.float32, device=sub_probs.device)\n",
    "            \n",
    "            sub_loss_func = self.sub_criterion_dict[narr_idx_str]\n",
    "            sub_loss += sub_loss_func(sub_probs, y_sub_tensor)\n",
    "\n",
    "            narr_pred = narr_probs[:, narr_idx].unsqueeze(1)\n",
    "            condition_term = torch.mean(\n",
    "                # Penalize high probs of sub, based on first level narr predictinos\n",
    "                torch.abs(sub_probs * (1 - narr_pred)) + \n",
    "                # If a narrative is true, then the subnarrative predictions should match their actual true values.\n",
    "                narr_pred * torch.abs(sub_probs - y_sub_tensor.unsqueeze(1))\n",
    "            )\n",
    "            condition_loss += condition_term\n",
    "            \n",
    "        sub_loss = sub_loss / len(sub_probs_dict)\n",
    "        condition_loss = condition_loss / len(sub_probs_dict)\n",
    "        \n",
    "        weighted_narr_loss = (1 - self.sub_weight) * narr_loss\n",
    "        weighted_sub_loss = self.sub_weight * sub_loss\n",
    "        weighted_condition_loss = self.condition_weight * condition_loss\n",
    "        total_loss =  (weighted_narr_loss + \n",
    "                       weighted_sub_loss + \n",
    "                       weighted_condition_loss)\n",
    "\n",
    "        logging.info(f'{weighted_narr_loss.item()},' +\n",
    "                     f'{weighted_sub_loss.item()},' +\n",
    "                     f'{weighted_condition_loss.item()}')\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d158d987-3f15-4949-ace4-ef3f64481b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_head_loss_fn = MultiHeadLoss(narrative_criterion, sub_criterion_dict).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1cd8bb5-2850-447f-a899-e11001466723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_weight_norms(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            norm = param.norm(2).item()\n",
    "            print(f\"Layer: {name} | Weight Norm: {norm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d07790-5568-40ce-bdc9-38f0282b0598",
   "metadata": {},
   "source": [
    "We define the function for training our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f7c1e38-c06b-4285-9d46-0c338ce8c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_multihead(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn=multi_head_loss_fn,\n",
    "    train_embeddings=train_embeddings_tensor,\n",
    "    y_train_nar=y_train_nar,\n",
    "    y_train_sub_heads=y_train_sub_heads,\n",
    "    val_embeddings=val_embeddings_tensor,\n",
    "    y_val_nar=y_val_nar,\n",
    "    y_val_sub_heads=y_val_sub_heads,\n",
    "    patience=10,\n",
    "    num_epochs=100,\n",
    "    scheduler=None,\n",
    "    min_delta=0.001\n",
    "):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience_counter = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_narr_probs, train_sub_probs_dict = model(train_embeddings)\n",
    "        train_loss = loss_fn(train_narr_probs, train_sub_probs_dict, y_train_nar, y_train_sub_heads)\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_narr_probs, val_sub_probs_dict = model(val_embeddings)\n",
    "            val_loss = loss_fn(val_narr_probs, val_sub_probs_dict, y_val_nar, y_val_sub_heads)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "              f\"Training Loss: {train_loss.item():.4f}, \"\n",
    "              f\"Validation Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "            current_lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "            print(f\"Current Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "        if val_loss.item() < best_val_loss - min_delta:\n",
    "            best_val_loss = val_loss.item()\n",
    "            patience_counter = 0\n",
    "            best_model = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Validation loss did not significantly improve for {patience_counter} epoch(s).\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    if best_model:\n",
    "        model.load_state_dict(best_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ec5cf11-220e-48db-be7f-d3ce7aa5e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_multi_head = torch.optim.AdamW(model_multi_head.parameters(),\n",
    "                                         lr=network_params['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a450be-6a3b-4100-9177-bcc2ff8dfda7",
   "metadata": {},
   "source": [
    "We will also initialize a scheduler to adjust the learning rate dynamically during training based on how the model is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7119e042-d647-4491-9e70-f8815ee0134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_multi_head, \n",
    "                                                       mode='min', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d39c97-888c-4246-a7a0-f6f67599ec1c",
   "metadata": {},
   "source": [
    "Notice that the simple model doesn't have any kind of relationship between narrative and subnarrative, we will stronger the weight for subnarratives as that is where we should focus more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a457cd29-7b55-448a-92aa-a9950fdbba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_head_loss_fn_simple = MultiHeadLoss(\n",
    "    narrative_criterion,\n",
    "    sub_criterion_dict,\n",
    "    condition_weight=0.3,\n",
    "    sub_weight=0.5\n",
    "    # narrative weight = 0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a501a7b4-6d0c-4c3f-bf4b-33015a1b73bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.8751, Validation Loss: 1.2574\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 2/100, Training Loss: 0.6744, Validation Loss: 1.2510\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 3/100, Training Loss: 0.5871, Validation Loss: 1.2522\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 4/100, Training Loss: 0.5196, Validation Loss: 1.2560\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 5/100, Training Loss: 0.4799, Validation Loss: 1.2581\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 6/100, Training Loss: 0.4529, Validation Loss: 1.2548\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Epoch 7/100, Training Loss: 0.4288, Validation Loss: 1.2485\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 8/100, Training Loss: 0.4184, Validation Loss: 1.2406\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 9/100, Training Loss: 0.4050, Validation Loss: 1.2320\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 10/100, Training Loss: 0.3947, Validation Loss: 1.2237\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 11/100, Training Loss: 0.3849, Validation Loss: 1.2164\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 12/100, Training Loss: 0.3770, Validation Loss: 1.2104\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 13/100, Training Loss: 0.3697, Validation Loss: 1.2056\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 14/100, Training Loss: 0.3626, Validation Loss: 1.2018\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 15/100, Training Loss: 0.3543, Validation Loss: 1.1990\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 16/100, Training Loss: 0.3492, Validation Loss: 1.1964\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 17/100, Training Loss: 0.3401, Validation Loss: 1.1939\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 18/100, Training Loss: 0.3354, Validation Loss: 1.1906\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 19/100, Training Loss: 0.3303, Validation Loss: 1.1863\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 20/100, Training Loss: 0.3231, Validation Loss: 1.1811\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 21/100, Training Loss: 0.3175, Validation Loss: 1.1757\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 22/100, Training Loss: 0.3129, Validation Loss: 1.1707\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 23/100, Training Loss: 0.3058, Validation Loss: 1.1666\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 24/100, Training Loss: 0.3010, Validation Loss: 1.1637\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 25/100, Training Loss: 0.2956, Validation Loss: 1.1626\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 26/100, Training Loss: 0.2916, Validation Loss: 1.1617\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 27/100, Training Loss: 0.2855, Validation Loss: 1.1615\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 28/100, Training Loss: 0.2817, Validation Loss: 1.1615\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 29/100, Training Loss: 0.2771, Validation Loss: 1.1612\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 30/100, Training Loss: 0.2720, Validation Loss: 1.1588\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 31/100, Training Loss: 0.2676, Validation Loss: 1.1550\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 32/100, Training Loss: 0.2628, Validation Loss: 1.1495\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 33/100, Training Loss: 0.2586, Validation Loss: 1.1444\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 34/100, Training Loss: 0.2541, Validation Loss: 1.1402\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 35/100, Training Loss: 0.2502, Validation Loss: 1.1367\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 36/100, Training Loss: 0.2453, Validation Loss: 1.1349\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 37/100, Training Loss: 0.2414, Validation Loss: 1.1371\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 38/100, Training Loss: 0.2376, Validation Loss: 1.1400\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 39/100, Training Loss: 0.2335, Validation Loss: 1.1447\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 40/100, Training Loss: 0.2291, Validation Loss: 1.1515\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Epoch 41/100, Training Loss: 0.2255, Validation Loss: 1.1506\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Epoch 42/100, Training Loss: 0.2236, Validation Loss: 1.1494\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Epoch 43/100, Training Loss: 0.2207, Validation Loss: 1.1485\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Epoch 44/100, Training Loss: 0.2188, Validation Loss: 1.1484\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Epoch 45/100, Training Loss: 0.2174, Validation Loss: 1.1467\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Epoch 46/100, Training Loss: 0.2150, Validation Loss: 1.1451\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "trained_multi_head_simple = train_with_multihead(\n",
    "    model=model_multi_head,\n",
    "    optimizer=optimizer_multi_head,\n",
    "    loss_fn=multi_head_loss_fn_simple,\n",
    "    patience=10,\n",
    "    scheduler=scheduler\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b75d48c-c3ad-4c3b-a546-287d3d8682fc",
   "metadata": {},
   "source": [
    "The coarse, or narrative classes, to be used in the evaluation function look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b342d65c-dad0-4c1a-8df0-7da453161948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC: Amplifying Climate Fears',\n",
       " 'CC: Climate change is beneficial',\n",
       " 'CC: Controversy about green technologies',\n",
       " 'CC: Criticism of climate movement',\n",
       " 'CC: Criticism of climate policies',\n",
       " 'CC: Criticism of institutions and authorities',\n",
       " 'CC: Downplaying climate change',\n",
       " 'CC: Green policies are geopolitical instruments',\n",
       " 'CC: Hidden plots by secret schemes of powerful groups',\n",
       " 'CC: Questioning the measurements and science',\n",
       " 'Other',\n",
       " 'URW: Amplifying war-related fears',\n",
       " 'URW: Blaming the war on others rather than the invader',\n",
       " 'URW: Discrediting Ukraine',\n",
       " 'URW: Discrediting the West, Diplomacy',\n",
       " 'URW: Distrust towards Media',\n",
       " 'URW: Hidden plots by secret schemes of powerful groups',\n",
       " 'URW: Negative Consequences for the West',\n",
       " 'URW: Overpraising the West',\n",
       " 'URW: Praise of Russia',\n",
       " 'URW: Russia is the Victim',\n",
       " 'URW: Speculating war outcomes']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240aa8d4-6880-48f9-9f6b-5ef90ddf392b",
   "metadata": {},
   "source": [
    "The fine, includes every single pair of a `narrative: subnarrative` from all hierarchies.\n",
    "- In case `Other` is labeled for an article as a narrative, we leave the fine as just `Other` (that is what we should do)\n",
    "- Also, for instances where the subnarrative is truly `Other` we match it with it's narrative parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57baea4d-8621-403d-8835-cef4e9279651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC: Amplifying Climate Fears: Amplifying existing fears of global warming',\n",
       " 'CC: Amplifying Climate Fears: Doomsday scenarios for humans',\n",
       " 'CC: Amplifying Climate Fears: Earth will be uninhabitable soon',\n",
       " 'CC: Amplifying Climate Fears: Other',\n",
       " 'CC: Amplifying Climate Fears: Whatever we do it is already too late',\n",
       " 'CC: Climate change is beneficial: CO2 is beneficial',\n",
       " 'CC: Climate change is beneficial: Other',\n",
       " 'CC: Climate change is beneficial: Temperature increase is beneficial',\n",
       " 'CC: Controversy about green technologies: Other',\n",
       " 'CC: Controversy about green technologies: Renewable energy is costly',\n",
       " 'CC: Controversy about green technologies: Renewable energy is dangerous',\n",
       " 'CC: Controversy about green technologies: Renewable energy is unreliable',\n",
       " 'CC: Criticism of climate movement: Ad hominem attacks on key activists',\n",
       " 'CC: Criticism of climate movement: Climate movement is alarmist',\n",
       " 'CC: Criticism of climate movement: Climate movement is corrupt']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_classes[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573c538-25c4-4f94-bd25-5326c9224da2",
   "metadata": {},
   "source": [
    "For the evaluator, we start by iterating over a range of thresholds, for both narratives and subnarratives.\n",
    "\n",
    "* First, we get the predictions of our model for the narratives and subnarratives.\n",
    "  - For each sample, we make a prediction, with the current thresholds.\n",
    "  - The predictions are evaluated, with the exact scorer that is used by the challenge.\n",
    "  - The metrics that we are aiming for, based on the evaluation rules of the challenge that claims:\n",
    " ```\n",
    "    The official evaluation measure will be averaged (over test documents) samples F1 computed for entire narrative_x:subnarrative_x labels. That is, we will first compute an F1 score per test document by comparing the predicted to the gold narrative_x:subnarrative_x labels of the document, and we will then average over the test documents. Both the narrative_x and the subnarrative_x part of each predicted narrative_x:subnarrative_x label will have to be correct for the predicted label to be considered correct.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1f5838d9-f9eb-46f4-8cbf-baadb18482ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn import metrics\n",
    "\n",
    "class MultiHeadEvaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        classes_coarse=coarse_classes,\n",
    "        classes_fine=fine_classes,\n",
    "        narrative_to_sub_map=narrative_to_sub_map,\n",
    "        narrative_order=narrative_order,\n",
    "        narrative_classes=mlb_narratives.classes_,\n",
    "        subnarrative_classes=mlb_subnarratives.classes_,\n",
    "        device='cpu',\n",
    "        output_dir='../../../submissions',\n",
    "    ):\n",
    "        self.narrative_to_sub_map = narrative_to_sub_map\n",
    "        self.narrative_order = narrative_order\n",
    "        self.narrative_classes = list(narrative_classes)\n",
    "        self.subnarrative_classes = list(subnarrative_classes)\n",
    "        \n",
    "        self.classes_coarse = classes_coarse\n",
    "        self.classes_fine = classes_fine\n",
    "\n",
    "        self.device = device\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    def evaluate(\n",
    "        self,\n",
    "        model,\n",
    "        embeddings=val_embeddings_tensor,\n",
    "        dataset=dataset_val,\n",
    "        thresholds=None,\n",
    "        save=False,\n",
    "        std_weight=0.4,\n",
    "        lower_thres=0.1,\n",
    "        upper_thres=0.60\n",
    "    ):\n",
    "        if thresholds is None:\n",
    "            thresholds = np.arange(lower_thres, upper_thres, 0.05)    \n",
    "        embeddings = embeddings.to(self.device)\n",
    "    \n",
    "        best_results = {\n",
    "            'best_coarse_f1': -1,\n",
    "            'best_coarse_std': float('inf'),\n",
    "            'best_fine_f1': -1,\n",
    "            'best_fine_std': float('inf'),\n",
    "            'narr_threshold': 0,\n",
    "            'sub_threshold': 0,\n",
    "            'predictions': None,\n",
    "            'best_combined_score': -float('inf'),\n",
    "            'coarse_classification_report': None,\n",
    "            'fine_precision': None,\n",
    "            'fine_recall': None,\n",
    "            'samples_f1_fine': None,\n",
    "        }\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            narr_probs, sub_probs_dict = model(embeddings)\n",
    "            narr_probs = narr_probs.cpu().numpy()\n",
    "            sub_probs_dict = {k: v.cpu().numpy() for k, v in sub_probs_dict.items()}\n",
    "    \n",
    "        for narr_threshold in thresholds:\n",
    "            for sub_threshold in thresholds:\n",
    "                predictions = []\n",
    "                for sample_idx, row in dataset.iterrows():\n",
    "                    pred = self._make_prediction(\n",
    "                        row['article_id'],\n",
    "                        sample_idx,\n",
    "                        narr_probs,\n",
    "                        sub_probs_dict,\n",
    "                        narr_threshold,\n",
    "                        sub_threshold\n",
    "                    )\n",
    "                    predictions.append(pred)\n",
    "                \n",
    "                f1_coarse_mean, coarse_std, f1_fine_mean, fine_std, report_coarse, precision_fine, recall_fine, samples_f1_fine = self._compute_metrics_coarse_fine(predictions, dataset)\n",
    "                \n",
    "                combined_score = f1_fine_mean - (std_weight * coarse_std)\n",
    "                \n",
    "                if combined_score > best_results['best_combined_score']:\n",
    "                    best_results.update({\n",
    "                        'best_coarse_f1': f1_coarse_mean,\n",
    "                        'best_coarse_std': coarse_std,\n",
    "                        'best_fine_f1': f1_fine_mean,\n",
    "                        'best_fine_std': fine_std,\n",
    "                        'narr_threshold': narr_threshold,\n",
    "                        'sub_threshold': sub_threshold,\n",
    "                        'predictions': predictions,\n",
    "                        'best_combined_score': combined_score,\n",
    "                        'coarse_classification_report': report_coarse,\n",
    "                        'fine_precision': precision_fine,\n",
    "                        'fine_recall': recall_fine,\n",
    "                        'samples_f1_fine': samples_f1_fine,\n",
    "                    })\n",
    "    \n",
    "        print(\"\\nBest thresholds found:\")\n",
    "        print(f\"Narrative threshold: {best_results['narr_threshold']:.2f}\")\n",
    "        print(f\"Subnarrative threshold: {best_results['sub_threshold']:.2f}\")\n",
    "        print('\\nCompetition Values')\n",
    "        print(f\"Coarse-F1: {best_results['best_coarse_f1']:.3f}\")\n",
    "        print(f\"F1 st. dev. coarse: {best_results['best_coarse_std']:.3f}\")\n",
    "        print(f\"Fine-F1: {best_results['best_fine_f1']:.3f}\")\n",
    "        print(f\"F1 st. dev. fine: {best_results['best_fine_std']:.3f}\")\n",
    "        print(\"\\nCoarse Classification Report:\")\n",
    "        print(best_results['coarse_classification_report'])\n",
    "        print(\"\\nFine Metrics:\")\n",
    "        print(\"Precision: {:.3f}\".format(best_results['fine_precision']))\n",
    "        print(\"Recall: {:.3f}\".format(best_results['fine_recall']))\n",
    "        print(\"F1 Samples: {:.3f}\".format(best_results['samples_f1_fine']))\n",
    "\n",
    "        if save:\n",
    "            self._save_predictions(best_results, os.path.join(self.output_dir, 'submission.txt'))\n",
    "        \n",
    "        return best_results\n",
    "\n",
    "    def _make_prediction(self, article_id, sample_idx, narr_probs, sub_probs_dict, narr_threshold, sub_threshold):\n",
    "        other_idx = self.narrative_classes.index(\"Other\")\n",
    "        active_narratives = [\n",
    "            (n_idx, prob)\n",
    "            for n_idx, prob in enumerate(narr_probs[sample_idx])\n",
    "            if n_idx != other_idx and prob >= narr_threshold\n",
    "        ]\n",
    "        # Fallback, If no active narrartive, output \"Other\" for both\n",
    "        # narrative and subnarratives.\n",
    "        if not active_narratives:\n",
    "            return {\n",
    "                'article_id': article_id,\n",
    "                'narratives': [\"Other\"],\n",
    "                'pairs': [\"Other\"]\n",
    "            }\n",
    "        \n",
    "        narratives = []\n",
    "        pairs = []\n",
    "        seen_pairs = set()\n",
    "        \n",
    "        active_narratives.sort(key=lambda x: x[1], reverse=True)\n",
    "        for narr_idx, _ in active_narratives:\n",
    "            narr_name = self.narrative_classes[narr_idx]\n",
    "            \n",
    "            sub_probs = sub_probs_dict[str(narr_idx)][sample_idx]\n",
    "            # FInd active subnarratives based on the cur threshold\n",
    "            active_subnarratives = [\n",
    "                (local_idx, s_prob)\n",
    "                for local_idx, s_prob in enumerate(sub_probs)\n",
    "                if s_prob >= sub_threshold\n",
    "            ]\n",
    "            # If no active subnarrative, output the predicted Narrative, with Other\n",
    "            # as a pair.\n",
    "            active_subnarratives.sort(key=lambda x: x[1], reverse=True)\n",
    "            if not active_subnarratives:\n",
    "                pairs.append(f\"{narr_name}: Other\")\n",
    "            else:\n",
    "                for local_idx, _ in active_subnarratives:\n",
    "                    global_sub_idx = self.narrative_to_sub_map[narr_idx][local_idx]\n",
    "                    sub_name = self.subnarrative_classes[global_sub_idx]\n",
    "                    pair = f\"{narr_name}: {sub_name}\"\n",
    "                    if pair not in seen_pairs:\n",
    "                        pairs.append(pair)\n",
    "                        seen_pairs.add(pair)\n",
    "            narratives.append(narr_name)\n",
    "        \n",
    "        return {\n",
    "            'article_id': article_id,\n",
    "            'narratives': narratives,\n",
    "            'pairs': pairs\n",
    "        }\n",
    "\n",
    "    def _compute_metrics_coarse_fine(self, predictions, dataset):\n",
    "        \"\"\"\n",
    "        Evaluates the problem predictions with the gold.\n",
    "        Mimics the challenge evaluation function.\n",
    "        \"\"\"\n",
    "        gold_coarse_all = []\n",
    "        gold_fine_all = []\n",
    "        pred_coarse_all = []\n",
    "        pred_fine_all = []\n",
    "\n",
    "        for pred, (_, row) in zip(predictions, dataset.iterrows()):\n",
    "            gold_coarse = row['narratives']\n",
    "            gold_subnarratives = row['subnarratives']\n",
    "            \n",
    "            pred_coarse = pred['narratives']\n",
    "            pred_fine = []\n",
    "            for p in pred['pairs']:\n",
    "                if p == \"Other\":\n",
    "                    pred_fine.append(\"Other\")\n",
    "                else:\n",
    "                    pred_fine.append(p)\n",
    "\n",
    "            gold_fine = []\n",
    "            for gold_nar, gold_sub in zip(gold_coarse, gold_subnarratives):\n",
    "                if gold_nar == \"Other\":\n",
    "                    gold_fine.append(\"Other\")\n",
    "                else:\n",
    "                    gold_fine.append(f\"{gold_nar}: {gold_sub}\")\n",
    "            \n",
    "            gold_coarse_all.append(gold_coarse)\n",
    "            gold_fine_all.append(gold_fine)\n",
    "            pred_coarse_all.append(pred_coarse)\n",
    "            pred_fine_all.append(pred_fine)\n",
    "\n",
    "        f1_coarse_mean, coarse_std = self._evaluate_multi_label(gold_coarse_all, pred_coarse_all, self.classes_coarse)\n",
    "        f1_fine_mean, fine_std = self._evaluate_multi_label(gold_fine_all, pred_fine_all, self.classes_fine)\n",
    "        \n",
    "        gold_coarse_flat = []\n",
    "        pred_coarse_flat = []\n",
    "        for g_labels, p_labels in zip(gold_coarse_all, pred_coarse_all):\n",
    "            g_onehot = np.zeros(len(self.classes_coarse), dtype=int)\n",
    "            for lab in g_labels:\n",
    "                if lab in self.classes_coarse:\n",
    "                    g_onehot[self.classes_coarse.index(lab)] = 1\n",
    "            p_onehot = np.zeros(len(self.classes_coarse), dtype=int)\n",
    "            for lab in p_labels:\n",
    "                if lab in self.classes_coarse:\n",
    "                    p_onehot[self.classes_coarse.index(lab)] = 1\n",
    "            gold_coarse_flat.append(g_onehot)\n",
    "            pred_coarse_flat.append(p_onehot)\n",
    "        gold_coarse_flat = np.array(gold_coarse_flat)\n",
    "        pred_coarse_flat = np.array(pred_coarse_flat)\n",
    "        report_coarse = metrics.classification_report(\n",
    "            gold_coarse_flat, pred_coarse_flat, target_names=self.classes_coarse, zero_division=0\n",
    "        )\n",
    "        \n",
    "        gold_fine_flat = []\n",
    "        pred_fine_flat = []\n",
    "        for g_labels, p_labels in zip(gold_fine_all, pred_fine_all):\n",
    "            g_onehot = np.zeros(len(self.classes_fine), dtype=int)\n",
    "            for lab in g_labels:\n",
    "                if lab in self.classes_fine:\n",
    "                    g_onehot[self.classes_fine.index(lab)] = 1\n",
    "            p_onehot = np.zeros(len(self.classes_fine), dtype=int)\n",
    "            for lab in p_labels:\n",
    "                if lab in self.classes_fine:\n",
    "                    p_onehot[self.classes_fine.index(lab)] = 1\n",
    "            gold_fine_flat.append(g_onehot)\n",
    "            pred_fine_flat.append(p_onehot)\n",
    "        gold_fine_flat = np.array(gold_fine_flat)\n",
    "        pred_fine_flat = np.array(pred_fine_flat)\n",
    "        \n",
    "        precision_fine = metrics.precision_score(gold_fine_flat, pred_fine_flat, average='macro', zero_division=0)\n",
    "        recall_fine = metrics.recall_score(gold_fine_flat, pred_fine_flat, average='macro', zero_division=0)\n",
    "        samples_f1_fine = metrics.f1_score(\n",
    "            gold_fine_flat, \n",
    "            pred_fine_flat, \n",
    "            average='samples',\n",
    "            zero_division=0\n",
    "        )\n",
    "        \n",
    "        return f1_coarse_mean, coarse_std, f1_fine_mean, fine_std, report_coarse, precision_fine, recall_fine, samples_f1_fine\n",
    "\n",
    "    def _evaluate_multi_label(self, gold, predicted, class_list):\n",
    "        \"\"\"\n",
    "        Evaluates the predicted, with the gold and returns the mean and std f1 scores.\n",
    "        Mimics the challenge evaluation function.\n",
    "        \"\"\"\n",
    "        f1_scores = []\n",
    "        for g_labels, p_labels in zip(gold, predicted):\n",
    "            g_onehot = np.zeros(len(class_list), dtype=int)\n",
    "            for lab in g_labels:\n",
    "                if lab in class_list:\n",
    "                    g_onehot[class_list.index(lab)] = 1\n",
    "                    \n",
    "            p_onehot = np.zeros(len(class_list), dtype=int)\n",
    "            for lab in p_labels:\n",
    "                if lab in class_list:\n",
    "                    p_onehot[class_list.index(lab)] = 1\n",
    "\n",
    "            f1_doc = metrics.f1_score(g_onehot, p_onehot, zero_division=0)\n",
    "            f1_scores.append(f1_doc)\n",
    "        \n",
    "        return float(np.mean(f1_scores)), float(np.std(f1_scores))\n",
    "\n",
    "    def _save_predictions(self, best_results, filepath):\n",
    "        predictions = best_results['predictions']\n",
    "        if os.path.exists(filepath):\n",
    "            os.remove(filepath)\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            for pred in predictions:\n",
    "                line = (f\"{pred['article_id']}\\t\"\n",
    "                        f\"{';'.join(pred['narratives'])}\\t\"\n",
    "                        f\"{';'.join(pred['pairs'])}\\n\")\n",
    "                f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bdde4245-e025-4853-8281-70ae844ea3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MultiHeadEvaluator(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4fb002-ee50-4677-8813-bbf3099f3e7c",
   "metadata": {},
   "source": [
    "Our model does a decent job correctly predicting the fine-grained roles, about 43% of the time.\n",
    "* The somewhat high standard deviation suggests some inconsistent performance across articles.\n",
    "    - We aim for a balanced prediction, between the F1 and the std score.\n",
    "\n",
    "Our model also does a decent job when it comes to predicting exact pairs of `narrative: subnarratives`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8491b49d-185e-4ef0-b330-09842c828a50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.55\n",
      "Subnarrative threshold: 0.45\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.431\n",
      "F1 st. dev. coarse: 0.359\n",
      "Fine-F1: 0.272\n",
      "F1 st. dev. fine: 0.285\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.00      0.00      0.00         0\n",
      "                      CC: Climate change is beneficial       0.00      0.00      0.00         1\n",
      "              CC: Controversy about green technologies       0.33      0.50      0.40         2\n",
      "                     CC: Criticism of climate movement       0.57      1.00      0.73         8\n",
      "                     CC: Criticism of climate policies       0.20      0.67      0.31         3\n",
      "         CC: Criticism of institutions and authorities       0.42      1.00      0.59         8\n",
      "                        CC: Downplaying climate change       0.00      0.00      0.00         2\n",
      "       CC: Green policies are geopolitical instruments       0.00      0.00      0.00         3\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.33      0.75      0.46         4\n",
      "          CC: Questioning the measurements and science       1.00      0.75      0.86         4\n",
      "                                                 Other       0.60      0.27      0.38        11\n",
      "                     URW: Amplifying war-related fears       0.50      0.67      0.57         3\n",
      "URW: Blaming the war on others rather than the invader       0.60      0.50      0.55         6\n",
      "                             URW: Discrediting Ukraine       0.80      0.57      0.67         7\n",
      "                 URW: Discrediting the West, Diplomacy       0.88      0.78      0.82         9\n",
      "                           URW: Distrust towards Media       0.00      0.00      0.00         4\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.00      0.00      0.00         0\n",
      "               URW: Negative Consequences for the West       0.00      0.00      0.00         1\n",
      "                            URW: Overpraising the West       0.00      0.00      0.00         1\n",
      "                                 URW: Praise of Russia       0.00      0.00      0.00         2\n",
      "                             URW: Russia is the Victim       0.00      0.00      0.00         2\n",
      "                         URW: Speculating war outcomes       0.33      0.25      0.29         4\n",
      "\n",
      "                                             micro avg       0.46      0.53      0.49        85\n",
      "                                             macro avg       0.30      0.35      0.30        85\n",
      "                                          weighted avg       0.48      0.53      0.47        85\n",
      "                                           samples avg       0.44      0.49      0.43        85\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.106\n",
      "Recall: 0.245\n",
      "F1 Samples: 0.272\n"
     ]
    }
   ],
   "source": [
    "results = evaluator.evaluate(\n",
    "    model=trained_multi_head_simple,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50daf14-7af8-4001-8530-a56385f46c8f",
   "metadata": {},
   "source": [
    "### Providing the already predicted narrative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd803a-e9c3-4e42-b3ef-b3001952784b",
   "metadata": {},
   "source": [
    "The results we got from the base, multi-head model, are encouraging. But, despite of the loss, our model by itself isn't providing any extra info when it comes to the phase of predicting subnarratives.\n",
    "\n",
    "Let h(x) be the shared layer output for the embedding x:\n",
    "\n",
    "        shared_out = self.shared_layer(x)\n",
    "\n",
    "We compute the probability P(narr_i | x) for each narrative:\n",
    "\n",
    "        narr_probs = self.narrative_head(shared_out)\n",
    "\n",
    "Previously, we used the following formula for the subnarrative probability P(subnarr_j | x):\n",
    "\n",
    "        P(subnarr_j | x) = σ(h(x))\n",
    "\n",
    "It makes sense to try:\n",
    "\n",
    "        P(subnarr_j | x) = σ(concat(h(x), P(narr_i | x)))\n",
    "\n",
    "\n",
    "Where narr_i is the narrative associated with subnarrative subnarr_j in the hierarchy.\n",
    "\n",
    "Essentially:\n",
    "\n",
    "* If the probability of the narrative is high, the subnarrative head will be more likely to predict the relevant subnarratives.\n",
    "* If the probability is low, the model will ignore the corresponding subnarratives.\n",
    "* At the same time, the shared output of the shared layer will help determine which subnarrative is most appropriate for the given document (and we can potentially use other techniques like attention to further improve the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00f17fed-9a17-4949-ae38-26b6aad935b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskClassifierMultiHeadConcat(BaseClassifier):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_narratives=len(mlb_narratives.classes_),\n",
    "        narrative_to_sub_map=narrative_to_sub_map,\n",
    "        dropout_rate=network_params['dropout'],\n",
    "        model_name=\"MultiTaskClassifierMultiHeadConcat\"\n",
    "    ):\n",
    "        super().__init__(input_size)\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        self.shared_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size * 2),\n",
    "            nn.BatchNorm1d(hidden_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        self.narrative_head = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, num_narratives),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.subnarrative_heads = nn.ModuleDict()\n",
    "        for narr_idx, sub_indices in narrative_to_sub_map.items():\n",
    "            num_subs_for_this_narr = len(sub_indices)\n",
    "            # Here each head expects an additional 1-dimension input (the narrative probability for that head)\n",
    "            self.subnarrative_heads[str(narr_idx)] = nn.Sequential(\n",
    "                nn.Linear(hidden_size * 2 + 1, num_subs_for_this_narr),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_out = self.shared_layer(x)\n",
    "\n",
    "        narr_probs = self.narrative_head(shared_out)\n",
    "\n",
    "        sub_probs_dict = {}\n",
    "        for narr_idx, head in self.subnarrative_heads.items():\n",
    "            # Add a new dimension: get the probability for the narrative corresponding to narr_idx\n",
    "            # Then concatenate it with shared layer's output.\n",
    "            conditioned_input = torch.cat((shared_out, narr_probs[:, int(narr_idx)].unsqueeze(1)), dim=1)\n",
    "            sub_probs_dict[narr_idx] = head(conditioned_input)\n",
    "\n",
    "        return narr_probs, sub_probs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d263ff-d5ec-47b3-9fc4-841851aba8fb",
   "metadata": {},
   "source": [
    "We make a util function to initialize and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "08a1fe75-e8f8-4e34-b4ad-48db7a0f9b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "def initialize_and_train_model(\n",
    "    model,\n",
    "    num_epochs=100,\n",
    "    lr=0.001,\n",
    "    patience=10,\n",
    "    use_scheduler=True,\n",
    "    scheduler_patience=3,\n",
    "    loss_fn=multi_head_loss_fn,\n",
    "    num_subnarratives=len(mlb_subnarratives.classes_),\n",
    "    device='cpu'\n",
    "):\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    scheduler = None\n",
    "    if use_scheduler:\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=scheduler_patience)\n",
    "\n",
    "    trained_model = train_with_multihead(\n",
    "                                    model=model,\n",
    "                                    optimizer=optimizer,\n",
    "                                    scheduler=scheduler,\n",
    "                                    loss_fn=loss_fn,\n",
    "                                    patience=patience\n",
    "                                )\n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc5cb2ce-2cf7-4d50-b444-004198d25653",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multi_head_concat= MultiTaskClassifierMultiHeadConcat(\n",
    "    input_size=input_size,\n",
    "    hidden_size=2048,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "755381ee-0c10-48a1-8751-8a653bec71fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping visualization\n"
     ]
    }
   ],
   "source": [
    "model_multi_head_concat.visualize(dummy_input=dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1adaf93e-7919-4cc4-ade8-201bbea84fca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiTaskClassifierMultiHeadConcat(\n",
      "  (shared_layer): Sequential(\n",
      "    (0): Linear(in_features=1536, out_features=4096, bias=True)\n",
      "    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "  )\n",
      "  (narrative_head): Sequential(\n",
      "    (0): Linear(in_features=4096, out_features=22, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (subnarrative_heads): ModuleDict(\n",
      "    (13): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=9, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (14): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=7, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (19): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=6, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (20): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=4, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (15): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=3, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (11): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=5, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (12): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=3, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (18): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=4, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (21): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=4, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (16): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=1, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (10): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=1, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (17): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=3, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=5, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=5, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=4, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=9, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=4, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (9): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=5, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (8): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=3, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=3, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=4, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): Linear(in_features=4097, out_features=3, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_multi_head_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2859af6-56ab-4ef2-b236-f5c616609d45",
   "metadata": {},
   "source": [
    "We train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6172dedf-d8de-49b3-9033-6dc363c29eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_head_loss_hierarchical = MultiHeadLoss(\n",
    "    narrative_criterion,\n",
    "    sub_criterion_dict,\n",
    "    condition_weight=0.3,\n",
    "    sub_weight=0.3\n",
    "    # narrative weight = 0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1d1454ec-f1d3-481b-9f0c-8b37afe40c7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.8674, Validation Loss: 1.2771\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 2/100, Training Loss: 0.6680, Validation Loss: 1.2721\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 3/100, Training Loss: 0.5317, Validation Loss: 1.2869\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 4/100, Training Loss: 0.4475, Validation Loss: 1.3088\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 5/100, Training Loss: 0.4169, Validation Loss: 1.3164\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 6/100, Training Loss: 0.4001, Validation Loss: 1.3077\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Epoch 7/100, Training Loss: 0.3709, Validation Loss: 1.2961\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Epoch 8/100, Training Loss: 0.3558, Validation Loss: 1.2834\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Epoch 9/100, Training Loss: 0.3439, Validation Loss: 1.2712\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Epoch 10/100, Training Loss: 0.3329, Validation Loss: 1.2609\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 11/100, Training Loss: 0.3260, Validation Loss: 1.2528\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 12/100, Training Loss: 0.3204, Validation Loss: 1.2466\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 13/100, Training Loss: 0.3140, Validation Loss: 1.2417\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 14/100, Training Loss: 0.3083, Validation Loss: 1.2375\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 15/100, Training Loss: 0.3019, Validation Loss: 1.2328\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 16/100, Training Loss: 0.2949, Validation Loss: 1.2276\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 17/100, Training Loss: 0.2876, Validation Loss: 1.2223\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 18/100, Training Loss: 0.2825, Validation Loss: 1.2163\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 19/100, Training Loss: 0.2768, Validation Loss: 1.2108\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 20/100, Training Loss: 0.2715, Validation Loss: 1.2057\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 21/100, Training Loss: 0.2642, Validation Loss: 1.2012\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 22/100, Training Loss: 0.2608, Validation Loss: 1.1974\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 23/100, Training Loss: 0.2550, Validation Loss: 1.1941\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 24/100, Training Loss: 0.2512, Validation Loss: 1.1910\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 25/100, Training Loss: 0.2471, Validation Loss: 1.1870\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 26/100, Training Loss: 0.2427, Validation Loss: 1.1835\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 27/100, Training Loss: 0.2381, Validation Loss: 1.1813\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 28/100, Training Loss: 0.2341, Validation Loss: 1.1805\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 29/100, Training Loss: 0.2294, Validation Loss: 1.1803\n",
      "Current Learning Rate: 0.000500\n",
      "Epoch 30/100, Training Loss: 0.2269, Validation Loss: 1.1812\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 31/100, Training Loss: 0.2222, Validation Loss: 1.1839\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 32/100, Training Loss: 0.2174, Validation Loss: 1.1880\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 33/100, Training Loss: 0.2149, Validation Loss: 1.1922\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Epoch 34/100, Training Loss: 0.2116, Validation Loss: 1.1922\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Epoch 35/100, Training Loss: 0.2085, Validation Loss: 1.1919\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Epoch 36/100, Training Loss: 0.2073, Validation Loss: 1.1914\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Epoch 37/100, Training Loss: 0.2049, Validation Loss: 1.1921\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Epoch 38/100, Training Loss: 0.2035, Validation Loss: 1.1920\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Epoch 39/100, Training Loss: 0.2018, Validation Loss: 1.1927\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "trained_model_concat = initialize_and_train_model(\n",
    "    model_multi_head_concat,\n",
    "    loss_fn=multi_head_loss_hierarchical,\n",
    "    patience=10,\n",
    "    use_scheduler=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "abd83ba2-86db-499f-b9e1-ac5167e1a89f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.55\n",
      "Subnarrative threshold: 0.50\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.380\n",
      "F1 st. dev. coarse: 0.337\n",
      "Fine-F1: 0.253\n",
      "F1 st. dev. fine: 0.258\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.00      0.00      0.00         0\n",
      "                      CC: Climate change is beneficial       0.00      0.00      0.00         1\n",
      "              CC: Controversy about green technologies       0.20      0.50      0.29         2\n",
      "                     CC: Criticism of climate movement       0.62      1.00      0.76         8\n",
      "                     CC: Criticism of climate policies       0.20      0.67      0.31         3\n",
      "         CC: Criticism of institutions and authorities       0.38      1.00      0.55         8\n",
      "                        CC: Downplaying climate change       0.00      0.00      0.00         2\n",
      "       CC: Green policies are geopolitical instruments       0.00      0.00      0.00         3\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.30      0.75      0.43         4\n",
      "          CC: Questioning the measurements and science       1.00      0.75      0.86         4\n",
      "                                                 Other       0.50      0.18      0.27        11\n",
      "                     URW: Amplifying war-related fears       0.50      0.67      0.57         3\n",
      "URW: Blaming the war on others rather than the invader       0.50      0.17      0.25         6\n",
      "                             URW: Discrediting Ukraine       1.00      0.57      0.73         7\n",
      "                 URW: Discrediting the West, Diplomacy       0.83      0.56      0.67         9\n",
      "                           URW: Distrust towards Media       0.00      0.00      0.00         4\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.00      0.00      0.00         0\n",
      "               URW: Negative Consequences for the West       0.00      0.00      0.00         1\n",
      "                            URW: Overpraising the West       0.00      0.00      0.00         1\n",
      "                                 URW: Praise of Russia       0.00      0.00      0.00         2\n",
      "                             URW: Russia is the Victim       0.00      0.00      0.00         2\n",
      "                         URW: Speculating war outcomes       0.33      0.25      0.29         4\n",
      "\n",
      "                                             micro avg       0.42      0.47      0.44        85\n",
      "                                             macro avg       0.29      0.32      0.27        85\n",
      "                                          weighted avg       0.47      0.47      0.42        85\n",
      "                                           samples avg       0.41      0.44      0.38        85\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.121\n",
      "Recall: 0.242\n",
      "F1 Samples: 0.253\n"
     ]
    }
   ],
   "source": [
    "_ = evaluator.evaluate(\n",
    "    model=trained_model_concat,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a924dc6-2d24-4835-9812-67346e06cc0a",
   "metadata": {},
   "source": [
    "### Using multiplication instead of concantenation\n",
    "\n",
    "Instead of using concat, we can try an element-wise multiplication. This sounds more logical as multiplication can act as a \"gate\":\n",
    "\n",
    "* If the narrative probability is close to 0, the corresponding subnarrative head’s input will be scaled down, effectively disabling that subnarrative head.\n",
    "* If the narrative probability is close to 1, the shared layer output passes through somewhat unaffected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dee697c4-d795-474f-8a8d-95cf7ffa37f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiTaskClassifierMultiHeadMult(BaseClassifier):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_narratives=len(mlb_narratives.classes_),\n",
    "        narrative_to_sub_map=narrative_to_sub_map,\n",
    "        dropout_rate=network_params['dropout'],\n",
    "        bias=0.1,\n",
    "        model_name=\"MultiTaskClassifierMultiHeadMult\"\n",
    "    ):\n",
    "        super().__init__(input_size)\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.shared_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size * 2),\n",
    "            nn.BatchNorm1d(hidden_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        self.narrative_head = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, num_narratives),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.subnarrative_heads = nn.ModuleDict()\n",
    "        for narr_idx, sub_indices in narrative_to_sub_map.items():\n",
    "            num_subs_for_this_narr = len(sub_indices)\n",
    "            self.subnarrative_heads[str(narr_idx)] = nn.Sequential(\n",
    "                nn.Linear(hidden_size * 2, num_subs_for_this_narr),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "        self.bias = bias\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_out = self.shared_layer(x)\n",
    "        narr_probs = self.narrative_head(shared_out)\n",
    "\n",
    "        # For each narrative head, condition the shared features by multiplying them\n",
    "        # with (narrative probability + bias) before generating subnarrative probabilities.\n",
    "        sub_probs_dict = {}\n",
    "        for narr_idx, head in self.subnarrative_heads.items():\n",
    "            narr_pred = narr_probs[:, int(narr_idx)].unsqueeze(1)\n",
    "            conditioned_input = shared_out * (narr_pred + self.bias)\n",
    "            sub_probs_dict[narr_idx] = head(conditioned_input)\n",
    "\n",
    "        return narr_probs, sub_probs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1a61a372-241e-4bcc-9d81-3b30631ad46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_multi_head_mult = MultiTaskClassifierMultiHeadMult(\n",
    "    input_size=input_size,\n",
    "    hidden_size=2048,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4131069c-03b5-472d-aee4-1d1f2feed017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping visualization\n"
     ]
    }
   ],
   "source": [
    "model_multi_head_mult.visualize(dummy_input=dummy_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4759f6-e4f3-465b-acb3-a31af9331ff0",
   "metadata": {},
   "source": [
    "The results are a bit suprising, but they make sense because concatenation gives the subnarrative heads more \"flexibility\" while multiplication is more restrictive acting as a hard gate.\n",
    "\n",
    "* If our narrative predictions are not confident or even and most importantly, not correct, the subnarrative head will receive very weak input because of the multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bd95c66a-2a4d-4387-9945-02fe88cd9142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.8732, Validation Loss: 1.2766\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 2/100, Training Loss: 0.7147, Validation Loss: 1.2758\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 3/100, Training Loss: 0.6010, Validation Loss: 1.2929\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 4/100, Training Loss: 0.5334, Validation Loss: 1.3136\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 5/100, Training Loss: 0.5008, Validation Loss: 1.3248\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Epoch 6/100, Training Loss: 0.4837, Validation Loss: 1.3261\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Epoch 7/100, Training Loss: 0.4587, Validation Loss: 1.3183\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Epoch 8/100, Training Loss: 0.4480, Validation Loss: 1.3072\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Epoch 9/100, Training Loss: 0.4336, Validation Loss: 1.2957\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Epoch 10/100, Training Loss: 0.4220, Validation Loss: 1.2849\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Epoch 11/100, Training Loss: 0.4132, Validation Loss: 1.2768\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "trained_model_mult = initialize_and_train_model(\n",
    "    model_multi_head_mult,\n",
    "    loss_fn=multi_head_loss_hierarchical\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f8aad116-e748-45b6-91df-c36e0d62a694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.55\n",
      "Subnarrative threshold: 0.50\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.296\n",
      "F1 st. dev. coarse: 0.440\n",
      "Fine-F1: 0.275\n",
      "F1 st. dev. fine: 0.427\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.00      0.00      0.00         0\n",
      "                      CC: Climate change is beneficial       0.00      0.00      0.00         1\n",
      "              CC: Controversy about green technologies       0.00      0.00      0.00         2\n",
      "                     CC: Criticism of climate movement       1.00      0.25      0.40         8\n",
      "                     CC: Criticism of climate policies       0.00      0.00      0.00         3\n",
      "         CC: Criticism of institutions and authorities       0.50      0.25      0.33         8\n",
      "                        CC: Downplaying climate change       0.00      0.00      0.00         2\n",
      "       CC: Green policies are geopolitical instruments       0.00      0.00      0.00         3\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.25      0.25      0.25         4\n",
      "          CC: Questioning the measurements and science       0.00      0.00      0.00         4\n",
      "                                                 Other       0.29      0.91      0.44        11\n",
      "                     URW: Amplifying war-related fears       0.00      0.00      0.00         3\n",
      "URW: Blaming the war on others rather than the invader       0.00      0.00      0.00         6\n",
      "                             URW: Discrediting Ukraine       0.00      0.00      0.00         7\n",
      "                 URW: Discrediting the West, Diplomacy       0.00      0.00      0.00         9\n",
      "                           URW: Distrust towards Media       0.00      0.00      0.00         4\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.00      0.00      0.00         0\n",
      "               URW: Negative Consequences for the West       0.00      0.00      0.00         1\n",
      "                            URW: Overpraising the West       0.00      0.00      0.00         1\n",
      "                                 URW: Praise of Russia       0.00      0.00      0.00         2\n",
      "                             URW: Russia is the Victim       0.00      0.00      0.00         2\n",
      "                         URW: Speculating war outcomes       0.00      0.00      0.00         4\n",
      "\n",
      "                                             micro avg       0.33      0.18      0.23        85\n",
      "                                             macro avg       0.09      0.08      0.06        85\n",
      "                                          weighted avg       0.19      0.18      0.14        85\n",
      "                                           samples avg       0.30      0.30      0.30        85\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.040\n",
      "Recall: 0.039\n",
      "F1 Samples: 0.275\n"
     ]
    }
   ],
   "source": [
    "_ = evaluator.evaluate(\n",
    "    model=trained_model_mult,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1504b42-fecf-4e5e-8281-f295fb0881cb",
   "metadata": {},
   "source": [
    "## Checkpoint Ensemble predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7b237-6969-48a2-b0ec-5ac21c068f23",
   "metadata": {},
   "source": [
    "Another approach we can try is to take different checkpoints of the training phase during the neural network training. Different checkpoints might be better at detecting different types of narratives.\n",
    "\n",
    "* Early stages of our model may be better at capturing some narratives and subnarratives, while later stages might need more training.\n",
    ". With this sapproach we can use multiple \"good\" snapshots of our model.\n",
    "* An obvious improvement we can do the previous ensemble model, is to consider the loss of each checkpoint as a factor to what each one should say.\n",
    "  - This means that model states that didn't do very good, won't get too much \"say\" in the final result, in comparison to better models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "498b0ab6-2c16-41ed-9eab-ba41864f94fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir='checkpoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa55e10-de59-4b16-bb15-6b35fe43b5c2",
   "metadata": {},
   "source": [
    "A checkpoint is a snapshot of our model during training.\n",
    "* We will save the epoch, model state and validation loss during that epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "30a8d649-0a27-4ee0-9db2-72da69e16c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict\n",
    "@dataclass\n",
    "class Checkpoint:\n",
    "    epoch: int              \n",
    "    model_state: Dict\n",
    "    val_loss: float\n",
    "\n",
    "def save_checkpoint(checkpoint):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    file_name = f\"checkpoint_epoch_{checkpoint.epoch}.pt\"\n",
    "    \n",
    "    checkpoint_path = os.path.join(checkpoint_dir, file_name)\n",
    "    \n",
    "    checkpoint_dict = {\n",
    "        'epoch': checkpoint.epoch,\n",
    "        'model_state_dict': checkpoint.model_state,\n",
    "        'val_loss': checkpoint.val_loss\n",
    "    }\n",
    "    with open(checkpoint_path, 'wb') as f:\n",
    "        pickle.dump(checkpoint_dict, f)\n",
    "    \n",
    "    return checkpoint_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2431f6f-d762-40bb-894a-4b40bcc24ab7",
   "metadata": {},
   "source": [
    "There are different strategies out there on how to select checkpoints.\n",
    "* We will start with a very simple one, and that is:\n",
    "   - We select the best checkpoint based on the lowest val loss.\n",
    "   - For the rest checkpoints, select them evenly across the training phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "08df7bcf-4d93-4ac4-9b0a-1d807caf4e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_checkpoints(checkpoints, k=5, strategy='linear'):\n",
    "    if not checkpoints:\n",
    "        print('\\n[WARNING] Found empty checkpoints')\n",
    "        return []\n",
    "    if k == 1 or len(checkpoints) == 1:\n",
    "        return min(checkpoints, key=lambda x: x[0])\n",
    "        \n",
    "    best_checkpoint = min(checkpoints, key=lambda x: x[0])\n",
    "    \n",
    "    sorted_by_epoch = sorted(checkpoints, key=lambda x: x[2])\n",
    "    total_epochs = len(sorted_by_epoch)\n",
    "    \n",
    "    if strategy == 'linear':\n",
    "        indices = np.linspace(0, total_epochs-1, k-1).astype(int)\n",
    "    elif strategy == 'log':\n",
    "        indices = np.logspace(0, np.log10(total_epochs-1), k-1).astype(int)\n",
    "    else:\n",
    "        print('Unsupported strategy.')\n",
    "    \n",
    "    time_diverse = [sorted_by_epoch[i] for i in indices]\n",
    "    \n",
    "    all_checkpoints = [best_checkpoint]\n",
    "    for checkpoint in time_diverse:\n",
    "        if checkpoint not in all_checkpoints:\n",
    "            all_checkpoints.append(checkpoint)\n",
    "    \n",
    "    return all_checkpoints[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ea54a-9be0-49fe-80f1-7554f506b68b",
   "metadata": {},
   "source": [
    "Our model train function is modified so that:\n",
    "* It saves a checkpoint of the model at each epoch.\n",
    "    - This will store the captured epoch, and the validation loss during that epoch.\n",
    "    - At the end of the training phase, we select some of the checkpoints based on a strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bb6fccf9-3abb-4140-a198-fbeedf1a2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "\n",
    "def train_best_checkp(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn=multi_head_loss_fn,\n",
    "    train_embeddings=train_embeddings_tensor,\n",
    "    y_train_nar=y_train_nar,\n",
    "    y_train_sub_heads=y_train_sub_heads,\n",
    "    val_embeddings=val_embeddings_tensor,\n",
    "    y_val_nar=y_val_nar,\n",
    "    y_val_sub_heads=y_val_sub_heads,\n",
    "    patience=10,\n",
    "    num_epochs=100,\n",
    "    scheduler=None,\n",
    "    min_delta=0.001,\n",
    "    clear_prev_checkp=True,\n",
    "    top_k=5,\n",
    "    strategy='linear'\n",
    "):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    all_checkpoints = []\n",
    "    print('Deleting previous checkpoints..')\n",
    "    files = glob.glob(os.path.join(checkpoint_dir, '*'))\n",
    "    for f in files:\n",
    "        try:\n",
    "            if os.path.isfile(f):\n",
    "                os.remove(f)\n",
    "        except Exception as e:\n",
    "            print(f\"\\n[WARNING] Couldn't delete {f}: {e}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_narr_probs, train_sub_probs_dict = model(train_embeddings)\n",
    "        train_loss = loss_fn(train_narr_probs, train_sub_probs_dict, y_train_nar, y_train_sub_heads)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_narr_probs, val_sub_probs_dict = model(val_embeddings)\n",
    "            val_loss = loss_fn(val_narr_probs, val_sub_probs_dict, y_val_nar, y_val_sub_heads)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "              f\"Training Loss: {train_loss.item():.4f}, \"\n",
    "              f\"Validation Loss: {val_loss.item():.4f}\")\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "            current_lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "            print(f\"Current Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "        checkpoint = Checkpoint(\n",
    "            epoch=epoch,\n",
    "            model_state=model.state_dict(),\n",
    "            val_loss=val_loss.item()\n",
    "        )\n",
    "            \n",
    "        checkpoint_path = save_checkpoint(checkpoint)\n",
    "        all_checkpoints.append((val_loss.item(), checkpoint_path, epoch))\n",
    "        \n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Validation loss did not significantly improve for {patience_counter} epoch(s).\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "            \n",
    "    selected_checkpoints = select_checkpoints(all_checkpoints, k=top_k, strategy=strategy)\n",
    "    selected_paths = [cp[1] for cp in selected_checkpoints]\n",
    "    selected_losses = [cp[0] for cp in selected_checkpoints]\n",
    "    \n",
    "    for _, path, _ in all_checkpoints:\n",
    "        if path not in selected_paths:\n",
    "            try:\n",
    "                os.remove(path)\n",
    "            except:\n",
    "                print('\\n[WARNING] Could not remove checkpoint path: ', path)\n",
    "                pass\n",
    "    \n",
    "    print(\"\\nSelected Checkpoints:\")\n",
    "    print(\"Val Loss | Epoch | Checkpoint\")\n",
    "    print(\"-\" * 50)\n",
    "    for val_loss, path, epoch in selected_checkpoints:\n",
    "        print(f\"{val_loss:.4f} | {epoch:5d} | {os.path.basename(path)}\")\n",
    "        \n",
    "    return model, selected_paths, selected_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c16c54c-31b0-4992-8b59-fbb8b809969d",
   "metadata": {},
   "source": [
    "We then define the actual ensemble model.\n",
    "* For the final prediction, each model will have a vote in proportion to it's loss in that checkpoint\n",
    "  - By taking the average, predictions of all votes, we remove any noise by using better checkpoints.\n",
    "  - The final model is also more robust since it is not relying on a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d9b12684-effa-4308-93de-1af1d7c8634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedCheckpointEnsemble:\n",
    "    def __init__(self, checkpoint_paths, val_losses, model_class=MultiTaskClassifierMultiHeadConcat):\n",
    "        self.models = []\n",
    "        self.weights = []\n",
    "        losses = torch.tensor(val_losses)\n",
    "        weights = torch.softmax(-losses, dim=0)\n",
    "        \n",
    "        print('Checkpoint Weights:')\n",
    "        for path, weight in zip(checkpoint_paths, weights):\n",
    "            print(f\"{os.path.basename(path)} weight: {weight:.3f}\")\n",
    "            \n",
    "        checkpoint = self._load_checkpoint(checkpoint_paths[0])\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "        \n",
    "        for checkpoint_path, weight in zip(checkpoint_paths, weights):            \n",
    "            model = model_class(\n",
    "                input_size=input_size,\n",
    "                hidden_size=2048,\n",
    "                dropout_rate=0.4\n",
    "            )\n",
    "            \n",
    "            checkpoint = self._load_checkpoint(checkpoint_path)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            model.eval()\n",
    "            \n",
    "            self.models.append(model)\n",
    "            self.weights.append(weight)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        narrative_probs_sum = None\n",
    "        subnarrative_probs_dict_sum = {}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for model, weight in zip(self.models, self.weights):\n",
    "                narr_probs, sub_probs_dict = model(x)\n",
    "                \n",
    "                weighted_narr_probs = narr_probs * weight\n",
    "                \n",
    "                if narrative_probs_sum is None:\n",
    "                    narrative_probs_sum = weighted_narr_probs\n",
    "                else:\n",
    "                    narrative_probs_sum += weighted_narr_probs\n",
    "                \n",
    "                for narr_idx, sub_probs in sub_probs_dict.items():\n",
    "                    weighted_sub_probs = sub_probs * weight\n",
    "                    if narr_idx not in subnarrative_probs_dict_sum:\n",
    "                        subnarrative_probs_dict_sum[narr_idx] = weighted_sub_probs\n",
    "                    else:\n",
    "                        subnarrative_probs_dict_sum[narr_idx] += weighted_sub_probs\n",
    "        \n",
    "        return narrative_probs_sum, subnarrative_probs_dict_sum\n",
    "    \n",
    "    def _load_checkpoint(self, checkpoint_path):\n",
    "        with open(checkpoint_path, 'rb') as f:\n",
    "            return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c7b0c106-3573-44ac-961b-b21b5540b9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ensemble(\n",
    "    base_evaluator,\n",
    "    ensemble_model,\n",
    "    embeddings=val_embeddings_tensor,\n",
    "    y_nar_true=y_val_nar,\n",
    "    y_sub_hierarchical=y_val_sub_heads,\n",
    "    thresholds=None,\n",
    "    save=False,\n",
    "):\n",
    "    def ensemble_predict(embedding):\n",
    "        return ensemble_model.predict(embedding)\n",
    "    \n",
    "    return base_evaluator.evaluate(\n",
    "        model=ensemble_predict,\n",
    "        embeddings=embeddings,\n",
    "        save=save,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "90fe9064-b195-4b71-8ab7-eb9e45b02384",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_concat_ens = MultiTaskClassifierMultiHeadConcat(\n",
    "    input_size=input_size,\n",
    "    hidden_size=2048,\n",
    "    dropout_rate=0.4\n",
    ")\n",
    "optimizer_ens= AdamW(model_concat_ens.parameters(), lr=0.001)\n",
    "scheduler_ens = ReduceLROnPlateau(optimizer_ens, mode='min', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "86e13478-14dd-467c-8521-932cec62526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_head_loss_hierarchical = MultiHeadLoss(\n",
    "    narrative_criterion,\n",
    "    sub_criterion_dict,\n",
    "    condition_weight = 0.3,\n",
    "    sub_weight=0.3\n",
    "    # narrative weight = 0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "61bbbc41-4b5a-4239-938b-52459eaf3148",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting previous checkpoints..\n",
      "Epoch 1/100, Training Loss: 0.8722, Validation Loss: 1.2756\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 2/100, Training Loss: 0.6658, Validation Loss: 1.2684\n",
      "Current Learning Rate: 0.001000\n",
      "Epoch 3/100, Training Loss: 0.5355, Validation Loss: 1.2803\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 4/100, Training Loss: 0.4522, Validation Loss: 1.3016\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 5/100, Training Loss: 0.4133, Validation Loss: 1.3202\n",
      "Current Learning Rate: 0.001000\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 6/100, Training Loss: 0.3977, Validation Loss: 1.3204\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Epoch 7/100, Training Loss: 0.3737, Validation Loss: 1.3102\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Epoch 8/100, Training Loss: 0.3602, Validation Loss: 1.2966\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Epoch 9/100, Training Loss: 0.3438, Validation Loss: 1.2823\n",
      "Current Learning Rate: 0.000500\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Epoch 10/100, Training Loss: 0.3356, Validation Loss: 1.2687\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Epoch 11/100, Training Loss: 0.3253, Validation Loss: 1.2592\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 12/100, Training Loss: 0.3225, Validation Loss: 1.2504\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 13/100, Training Loss: 0.3189, Validation Loss: 1.2425\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 14/100, Training Loss: 0.3160, Validation Loss: 1.2354\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 15/100, Training Loss: 0.3118, Validation Loss: 1.2291\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 16/100, Training Loss: 0.3087, Validation Loss: 1.2235\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 17/100, Training Loss: 0.3038, Validation Loss: 1.2186\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 18/100, Training Loss: 0.3004, Validation Loss: 1.2140\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 19/100, Training Loss: 0.2956, Validation Loss: 1.2097\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 20/100, Training Loss: 0.2918, Validation Loss: 1.2058\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 21/100, Training Loss: 0.2882, Validation Loss: 1.2020\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 22/100, Training Loss: 0.2841, Validation Loss: 1.1979\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 23/100, Training Loss: 0.2809, Validation Loss: 1.1936\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 24/100, Training Loss: 0.2775, Validation Loss: 1.1891\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 25/100, Training Loss: 0.2740, Validation Loss: 1.1850\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 26/100, Training Loss: 0.2704, Validation Loss: 1.1809\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 27/100, Training Loss: 0.2688, Validation Loss: 1.1767\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 28/100, Training Loss: 0.2659, Validation Loss: 1.1725\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 29/100, Training Loss: 0.2618, Validation Loss: 1.1686\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 30/100, Training Loss: 0.2592, Validation Loss: 1.1653\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 31/100, Training Loss: 0.2550, Validation Loss: 1.1624\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 32/100, Training Loss: 0.2527, Validation Loss: 1.1601\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 33/100, Training Loss: 0.2503, Validation Loss: 1.1584\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 34/100, Training Loss: 0.2470, Validation Loss: 1.1571\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 35/100, Training Loss: 0.2445, Validation Loss: 1.1552\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 36/100, Training Loss: 0.2411, Validation Loss: 1.1533\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 37/100, Training Loss: 0.2382, Validation Loss: 1.1520\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 38/100, Training Loss: 0.2353, Validation Loss: 1.1515\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 39/100, Training Loss: 0.2337, Validation Loss: 1.1511\n",
      "Current Learning Rate: 0.000250\n",
      "Epoch 40/100, Training Loss: 0.2314, Validation Loss: 1.1517\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 1 epoch(s).\n",
      "Epoch 41/100, Training Loss: 0.2286, Validation Loss: 1.1525\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 2 epoch(s).\n",
      "Epoch 42/100, Training Loss: 0.2253, Validation Loss: 1.1549\n",
      "Current Learning Rate: 0.000250\n",
      "Validation loss did not significantly improve for 3 epoch(s).\n",
      "Epoch 43/100, Training Loss: 0.2228, Validation Loss: 1.1594\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 4 epoch(s).\n",
      "Epoch 44/100, Training Loss: 0.2194, Validation Loss: 1.1634\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 5 epoch(s).\n",
      "Epoch 45/100, Training Loss: 0.2188, Validation Loss: 1.1682\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 6 epoch(s).\n",
      "Epoch 46/100, Training Loss: 0.2177, Validation Loss: 1.1739\n",
      "Current Learning Rate: 0.000125\n",
      "Validation loss did not significantly improve for 7 epoch(s).\n",
      "Epoch 47/100, Training Loss: 0.2163, Validation Loss: 1.1800\n",
      "Current Learning Rate: 0.000063\n",
      "Validation loss did not significantly improve for 8 epoch(s).\n",
      "Epoch 48/100, Training Loss: 0.2154, Validation Loss: 1.1856\n",
      "Current Learning Rate: 0.000063\n",
      "Validation loss did not significantly improve for 9 epoch(s).\n",
      "Epoch 49/100, Training Loss: 0.2146, Validation Loss: 1.1921\n",
      "Current Learning Rate: 0.000063\n",
      "Validation loss did not significantly improve for 10 epoch(s).\n",
      "Early stopping triggered.\n",
      "\n",
      "Selected Checkpoints:\n",
      "Val Loss | Epoch | Checkpoint\n",
      "--------------------------------------------------\n",
      "1.1511 |    38 | checkpoint_epoch_38.pt\n",
      "1.2756 |     0 | checkpoint_epoch_0.pt\n",
      "1.2687 |     9 | checkpoint_epoch_9.pt\n",
      "1.2058 |    19 | checkpoint_epoch_19.pt\n",
      "1.1686 |    28 | checkpoint_epoch_28.pt\n",
      "1.1921 |    48 | checkpoint_epoch_48.pt\n"
     ]
    }
   ],
   "source": [
    "trained_concat, checkpoint_paths, val_losses = train_best_checkp(\n",
    "    model=model_concat_ens,\n",
    "    optimizer=optimizer_ens,\n",
    "    scheduler=scheduler_ens,\n",
    "    patience=10,\n",
    "    loss_fn=multi_head_loss_hierarchical,\n",
    "    top_k=7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "83cb5e82-c424-4f42-b6d1-603af56c6b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint Weights:\n",
      "checkpoint_epoch_38.pt weight: 0.177\n",
      "checkpoint_epoch_0.pt weight: 0.156\n",
      "checkpoint_epoch_9.pt weight: 0.157\n",
      "checkpoint_epoch_19.pt weight: 0.167\n",
      "checkpoint_epoch_28.pt weight: 0.174\n",
      "checkpoint_epoch_48.pt weight: 0.170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "ensemble_model = WeightedCheckpointEnsemble(checkpoint_paths, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d0624ee5-4c14-450e-8586-d1f1b1432bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best thresholds found:\n",
      "Narrative threshold: 0.55\n",
      "Subnarrative threshold: 0.50\n",
      "\n",
      "Competition Values\n",
      "Coarse-F1: 0.431\n",
      "F1 st. dev. coarse: 0.351\n",
      "Fine-F1: 0.280\n",
      "F1 st. dev. fine: 0.291\n",
      "\n",
      "Coarse Classification Report:\n",
      "                                                        precision    recall  f1-score   support\n",
      "\n",
      "                          CC: Amplifying Climate Fears       0.00      0.00      0.00         0\n",
      "                      CC: Climate change is beneficial       0.00      0.00      0.00         1\n",
      "              CC: Controversy about green technologies       0.25      0.50      0.33         2\n",
      "                     CC: Criticism of climate movement       0.57      1.00      0.73         8\n",
      "                     CC: Criticism of climate policies       0.22      0.67      0.33         3\n",
      "         CC: Criticism of institutions and authorities       0.40      1.00      0.57         8\n",
      "                        CC: Downplaying climate change       0.00      0.00      0.00         2\n",
      "       CC: Green policies are geopolitical instruments       0.00      0.00      0.00         3\n",
      " CC: Hidden plots by secret schemes of powerful groups       0.30      0.75      0.43         4\n",
      "          CC: Questioning the measurements and science       1.00      0.75      0.86         4\n",
      "                                                 Other       0.57      0.36      0.44        11\n",
      "                     URW: Amplifying war-related fears       0.50      0.67      0.57         3\n",
      "URW: Blaming the war on others rather than the invader       1.00      0.17      0.29         6\n",
      "                             URW: Discrediting Ukraine       1.00      0.57      0.73         7\n",
      "                 URW: Discrediting the West, Diplomacy       0.83      0.56      0.67         9\n",
      "                           URW: Distrust towards Media       0.00      0.00      0.00         4\n",
      "URW: Hidden plots by secret schemes of powerful groups       0.00      0.00      0.00         0\n",
      "               URW: Negative Consequences for the West       0.00      0.00      0.00         1\n",
      "                            URW: Overpraising the West       0.00      0.00      0.00         1\n",
      "                                 URW: Praise of Russia       0.00      0.00      0.00         2\n",
      "                             URW: Russia is the Victim       0.00      0.00      0.00         2\n",
      "                         URW: Speculating war outcomes       0.50      0.25      0.33         4\n",
      "\n",
      "                                             micro avg       0.47      0.49      0.48        85\n",
      "                                             macro avg       0.32      0.33      0.29        85\n",
      "                                          weighted avg       0.52      0.49      0.45        85\n",
      "                                           samples avg       0.46      0.49      0.43        85\n",
      "\n",
      "\n",
      "Fine Metrics:\n",
      "Precision: 0.105\n",
      "Recall: 0.222\n",
      "F1 Samples: 0.280\n"
     ]
    }
   ],
   "source": [
    "_ = evaluate_ensemble(\n",
    "    evaluator,\n",
    "    ensemble_model,\n",
    "    save=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1315c3ac-c265-4c62-a669-b9c8089e1da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>narrative_loss</th>\n",
       "      <th>subnarrative_loss</th>\n",
       "      <th>condition_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.36099255084991455</td>\n",
       "      <td>0.360649</td>\n",
       "      <td>0.344717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5922605991363525</td>\n",
       "      <td>0.513934</td>\n",
       "      <td>0.346187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.2584276795387268</td>\n",
       "      <td>0.321366</td>\n",
       "      <td>0.261415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5867002010345459</td>\n",
       "      <td>0.512261</td>\n",
       "      <td>0.343047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.21988710761070251</td>\n",
       "      <td>0.301783</td>\n",
       "      <td>0.202566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13946</th>\n",
       "      <td>0.7991061210632324</td>\n",
       "      <td>0.293757</td>\n",
       "      <td>0.087136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13947</th>\n",
       "      <td>0.087013378739357</td>\n",
       "      <td>0.078293</td>\n",
       "      <td>0.050120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13948</th>\n",
       "      <td>0.804570734500885</td>\n",
       "      <td>0.295282</td>\n",
       "      <td>0.085783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13949</th>\n",
       "      <td>0.08627437055110931</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.050131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13950</th>\n",
       "      <td>0.8106493949890137</td>\n",
       "      <td>0.296944</td>\n",
       "      <td>0.084467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            narrative_loss  subnarrative_loss  condition_loss\n",
       "8      0.36099255084991455           0.360649        0.344717\n",
       "9       0.5922605991363525           0.513934        0.346187\n",
       "10      0.2584276795387268           0.321366        0.261415\n",
       "11      0.5867002010345459           0.512261        0.343047\n",
       "12     0.21988710761070251           0.301783        0.202566\n",
       "...                    ...                ...             ...\n",
       "13946   0.7991061210632324           0.293757        0.087136\n",
       "13947    0.087013378739357           0.078293        0.050120\n",
       "13948    0.804570734500885           0.295282        0.085783\n",
       "13949  0.08627437055110931           0.078201        0.050131\n",
       "13950   0.8106493949890137           0.296944        0.084467\n",
       "\n",
       "[13800 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_df = pd.read_csv('./logs/loss_logs.log', \n",
    "                        header=None, \n",
    "                        names=['narrative_loss', \n",
    "                               'subnarrative_loss', \n",
    "                               'condition_loss'])\n",
    "losses_df = losses_df.dropna()\n",
    "losses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0d9a626a-a252-4f36-b278-2cb017c4bde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>narrative_loss</th>\n",
       "      <th>subnarrative_loss</th>\n",
       "      <th>condition_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.360993</td>\n",
       "      <td>0.360649</td>\n",
       "      <td>0.344717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.592261</td>\n",
       "      <td>0.513934</td>\n",
       "      <td>0.346187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.258428</td>\n",
       "      <td>0.321366</td>\n",
       "      <td>0.261415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.586700</td>\n",
       "      <td>0.512261</td>\n",
       "      <td>0.343047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.219887</td>\n",
       "      <td>0.301783</td>\n",
       "      <td>0.202566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13946</th>\n",
       "      <td>0.799106</td>\n",
       "      <td>0.293757</td>\n",
       "      <td>0.087136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13947</th>\n",
       "      <td>0.087013</td>\n",
       "      <td>0.078293</td>\n",
       "      <td>0.050120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13948</th>\n",
       "      <td>0.804571</td>\n",
       "      <td>0.295282</td>\n",
       "      <td>0.085783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13949</th>\n",
       "      <td>0.086274</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.050131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13950</th>\n",
       "      <td>0.810649</td>\n",
       "      <td>0.296944</td>\n",
       "      <td>0.084467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       narrative_loss  subnarrative_loss  condition_loss\n",
       "8            0.360993           0.360649        0.344717\n",
       "9            0.592261           0.513934        0.346187\n",
       "10           0.258428           0.321366        0.261415\n",
       "11           0.586700           0.512261        0.343047\n",
       "12           0.219887           0.301783        0.202566\n",
       "...               ...                ...             ...\n",
       "13946        0.799106           0.293757        0.087136\n",
       "13947        0.087013           0.078293        0.050120\n",
       "13948        0.804571           0.295282        0.085783\n",
       "13949        0.086274           0.078201        0.050131\n",
       "13950        0.810649           0.296944        0.084467\n",
       "\n",
       "[13800 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_df = losses_df.astype(float)\n",
    "losses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b2e55865-15af-472d-afed-4af8ec740fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>narrative_loss</th>\n",
       "      <th>subnarrative_loss</th>\n",
       "      <th>condition_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.338528</td>\n",
       "      <td>0.338206</td>\n",
       "      <td>0.323265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.407786</td>\n",
       "      <td>0.353856</td>\n",
       "      <td>0.238358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.307210</td>\n",
       "      <td>0.382029</td>\n",
       "      <td>0.310761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.406863</td>\n",
       "      <td>0.355241</td>\n",
       "      <td>0.237895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.303612</td>\n",
       "      <td>0.416692</td>\n",
       "      <td>0.279696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13946</th>\n",
       "      <td>0.677210</td>\n",
       "      <td>0.248947</td>\n",
       "      <td>0.073844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13947</th>\n",
       "      <td>0.403912</td>\n",
       "      <td>0.363431</td>\n",
       "      <td>0.232657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13948</th>\n",
       "      <td>0.678598</td>\n",
       "      <td>0.249050</td>\n",
       "      <td>0.072352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13949</th>\n",
       "      <td>0.402012</td>\n",
       "      <td>0.364394</td>\n",
       "      <td>0.233594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13950</th>\n",
       "      <td>0.680040</td>\n",
       "      <td>0.249102</td>\n",
       "      <td>0.070858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       narrative_loss  subnarrative_loss  condition_loss\n",
       "8            0.338528           0.338206        0.323265\n",
       "9            0.407786           0.353856        0.238358\n",
       "10           0.307210           0.382029        0.310761\n",
       "11           0.406863           0.355241        0.237895\n",
       "12           0.303612           0.416692        0.279696\n",
       "...               ...                ...             ...\n",
       "13946        0.677210           0.248947        0.073844\n",
       "13947        0.403912           0.363431        0.232657\n",
       "13948        0.678598           0.249050        0.072352\n",
       "13949        0.402012           0.364394        0.233594\n",
       "13950        0.680040           0.249102        0.070858\n",
       "\n",
       "[13800 rows x 3 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_sum = losses_df.sum(axis=1)\n",
    "\n",
    "losses_df = losses_df.div(row_sum, axis=0)\n",
    "losses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e747318d-9d6c-45c5-8c34-d12d846f6112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8        0.323265\n",
       "9        0.238358\n",
       "10       0.310761\n",
       "11       0.237895\n",
       "12       0.279696\n",
       "           ...   \n",
       "13946    0.073844\n",
       "13947    0.232657\n",
       "13948    0.072352\n",
       "13949    0.233594\n",
       "13950    0.070858\n",
       "Name: condition_loss, Length: 13800, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_df['condition_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "507d6a42-fa36-4dd0-9ff2-dfe543aac2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x17f7ffe30>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_melted = losses_df.melt(var_name='Column', value_name='Percentage')\n",
    "\n",
    "g = sns.FacetGrid(df_melted, col='Column', height=4, sharey=True, sharex=False)\n",
    "\n",
    "g.map(sns.histplot, 'Percentage', kde=True, bins=20, color='blue', alpha=0.5)\n",
    "\n",
    "g.set_titles(\"{col_name}\")\n",
    "g.set_axis_labels(\"Percentage of Total Loss\", \"Density\")\n",
    "\n",
    "g.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
