{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb24de54-f1cc-41e3-b71a-1e18cc7fd1bf",
   "metadata": {},
   "source": [
    "# Semeval 2025 Task 10\n",
    "### Subtask 1: Entity Framing -- Multilingual Model\n",
    "\n",
    "Given a news article and a list of mentions of named entities (NEs) in the article, assign for each such mention one or more roles using a predefined taxonomy of fine-grained roles covering three main type of roles: protagonists, antagonists, and innocent. This is a multi-label multi-class text-span classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b7bbb9-ca9c-4d37-9cf3-e84fdc1e9509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fea70e59-e0a8-4ee0-9739-60f53274423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "ignore_folders = ['.DS_Store']\n",
    "\n",
    "base_dir_documents = 'data/semeval_data/raw-documents'\n",
    "\n",
    "for language_folder in os.listdir(base_dir_documents):\n",
    "    \n",
    "    if language_folder in ignore_folders:\n",
    "        continue\n",
    "\n",
    "    language_path = os.path.join(base_dir_documents, language_folder)\n",
    "    if os.path.isdir(language_path):\n",
    "        for root, _, files in os.walk(language_path):\n",
    "            for file in files:\n",
    "                if file.endswith('.txt'):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    \n",
    "                    article_id = file\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        content = f.read()\n",
    "                    \n",
    "                    data.append({\n",
    "                        'language': language_folder,\n",
    "                        'article_id': article_id,\n",
    "                        'content': content\n",
    "                    })\n",
    "\n",
    "documents_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac14cdd9-6e72-408a-96a5-702fc3a77cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(726, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c229ff5b-a241-4413-a7a9-7cf035d14d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>EN</td>\n",
       "      <td>EN_UA_102655.txt</td>\n",
       "      <td>BIOWARFARE ON AMERICANS: RFK Jr. says CIA was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>BG</td>\n",
       "      <td>A9_BG_3762.txt</td>\n",
       "      <td>Американски професор: Зеленски е убиец, Русия ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>BG</td>\n",
       "      <td>BG_1390.txt</td>\n",
       "      <td>Шефове на най-големите световни петролни компа...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>HI</td>\n",
       "      <td>HI_138.txt</td>\n",
       "      <td>Climate Change: सीएम विष्णुदेव साय ने किसे बता...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>HI</td>\n",
       "      <td>HI_6.txt</td>\n",
       "      <td>- Hindi News\\n- International\\n- Russia Ukrain...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    language        article_id  \\\n",
       "610       EN  EN_UA_102655.txt   \n",
       "317       BG    A9_BG_3762.txt   \n",
       "407       BG       BG_1390.txt   \n",
       "445       HI        HI_138.txt   \n",
       "486       HI          HI_6.txt   \n",
       "\n",
       "                                               content  \n",
       "610  BIOWARFARE ON AMERICANS: RFK Jr. says CIA was ...  \n",
       "317  Американски професор: Зеленски е убиец, Русия ...  \n",
       "407  Шефове на най-големите световни петролни компа...  \n",
       "445  Climate Change: सीएम विष्णुदेव साय ने किसे बता...  \n",
       "486  - Hindi News\\n- International\\n- Russia Ukrain...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a93f0e9-23f8-47ad-96cf-7a8bc1c84375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0             PT_53.txt\n",
       "1             PT_47.txt\n",
       "2             PT_90.txt\n",
       "3             PT_84.txt\n",
       "4            PT_166.txt\n",
       "             ...       \n",
       "721    EN_CC_100076.txt\n",
       "722    EN_UA_103251.txt\n",
       "723    EN_UA_002991.txt\n",
       "724    EN_UA_008072.txt\n",
       "725    EN_UA_015962.txt\n",
       "Name: article_id, Length: 726, dtype: object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df['article_id'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d235446f-3189-4d83-b6fe-aa8b703f1697",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir_labels = 'data/semeval_data/labels'\n",
    "\n",
    "raw_annotation_data = []\n",
    "\n",
    "for language_folder in os.listdir(base_dir_labels):\n",
    "    \n",
    "    if language_folder in ignore_folders:\n",
    "        continue\n",
    "    \n",
    "    language_path = os.path.join(base_dir_labels, language_folder)\n",
    "    if os.path.isdir(language_path):\n",
    "        for root, _, files in os.walk(language_path):\n",
    "            label_file = 'subtask-1-annotations.txt'\n",
    "            file_path = os.path.join(root, label_file)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                for line in file:\n",
    "                    parts = line.strip().split('\\t')\n",
    "                    article_id = parts[0]\n",
    "                    entity_mention = parts[1]\n",
    "                    start_offset = int(parts[2])\n",
    "                    end_offset = int(parts[3])\n",
    "                    main_role = parts[4]\n",
    "                                \n",
    "                    sub_roles = parts[5:] \n",
    "                    raw_annotation_data.append({\n",
    "                        \"article_id\": article_id,\n",
    "                        \"entity_mention\": entity_mention,\n",
    "                        \"start_offset\": start_offset,\n",
    "                        \"end_offset\": end_offset,\n",
    "                        \"main_role\": main_role,\n",
    "                        \"sub_roles\": sub_roles,\n",
    "                    })\n",
    "   \n",
    "annotations_df = pd.DataFrame(raw_annotation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc6c6b0d-6648-4d00-96fe-bd5126d5231c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>entity_mention</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>main_role</th>\n",
       "      <th>sub_roles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PT_161.txt</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>377</td>\n",
       "      <td>384</td>\n",
       "      <td>Innocent</td>\n",
       "      <td>[Victim]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PT_161.txt</td>\n",
       "      <td>França</td>\n",
       "      <td>1072</td>\n",
       "      <td>1077</td>\n",
       "      <td>Innocent</td>\n",
       "      <td>[Victim]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PT_161.txt</td>\n",
       "      <td>IPMA</td>\n",
       "      <td>2158</td>\n",
       "      <td>2161</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Guardian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PT_13.txt</td>\n",
       "      <td>Ucrânia</td>\n",
       "      <td>184</td>\n",
       "      <td>190</td>\n",
       "      <td>Innocent</td>\n",
       "      <td>[Victim]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PT_196.txt</td>\n",
       "      <td>Engajamundo</td>\n",
       "      <td>421</td>\n",
       "      <td>431</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Rebel]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id entity_mention  start_offset  end_offset    main_role  \\\n",
       "0  PT_161.txt       Portugal           377         384     Innocent   \n",
       "1  PT_161.txt         França          1072        1077     Innocent   \n",
       "2  PT_161.txt           IPMA          2158        2161  Protagonist   \n",
       "3   PT_13.txt        Ucrânia           184         190     Innocent   \n",
       "4  PT_196.txt    Engajamundo           421         431  Protagonist   \n",
       "\n",
       "    sub_roles  \n",
       "0    [Victim]  \n",
       "1    [Victim]  \n",
       "2  [Guardian]  \n",
       "3    [Victim]  \n",
       "4     [Rebel]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f25265a8-32d2-4f2c-86e7-4d855a930828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2535, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5065796a-e88c-4662-9cbc-81a9f92f0c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "      <th>entity_mention</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>main_role</th>\n",
       "      <th>sub_roles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PT</td>\n",
       "      <td>PT_53.txt</td>\n",
       "      <td>Mais de 1600 Cientistas Negam a Emergência Cli...</td>\n",
       "      <td>Ivar Giaever</td>\n",
       "      <td>937</td>\n",
       "      <td>948</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Guardian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PT</td>\n",
       "      <td>PT_53.txt</td>\n",
       "      <td>Mais de 1600 Cientistas Negam a Emergência Cli...</td>\n",
       "      <td>John F. Clauser</td>\n",
       "      <td>952</td>\n",
       "      <td>966</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Guardian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PT</td>\n",
       "      <td>PT_47.txt</td>\n",
       "      <td>Zelensky admite a inevitabilidade da retirada ...</td>\n",
       "      <td>Ucrânia</td>\n",
       "      <td>857</td>\n",
       "      <td>863</td>\n",
       "      <td>Innocent</td>\n",
       "      <td>[Forgotten]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PT</td>\n",
       "      <td>PT_84.txt</td>\n",
       "      <td>Zelensky planeia segunda cimeira de paz em nov...</td>\n",
       "      <td>Volodymyr Zelensky</td>\n",
       "      <td>113</td>\n",
       "      <td>130</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Peacemaker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PT</td>\n",
       "      <td>PT_84.txt</td>\n",
       "      <td>Zelensky planeia segunda cimeira de paz em nov...</td>\n",
       "      <td>Rússia</td>\n",
       "      <td>372</td>\n",
       "      <td>377</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Foreign Adversary]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language article_id                                            content  \\\n",
       "0       PT  PT_53.txt  Mais de 1600 Cientistas Negam a Emergência Cli...   \n",
       "1       PT  PT_53.txt  Mais de 1600 Cientistas Negam a Emergência Cli...   \n",
       "2       PT  PT_47.txt  Zelensky admite a inevitabilidade da retirada ...   \n",
       "3       PT  PT_84.txt  Zelensky planeia segunda cimeira de paz em nov...   \n",
       "4       PT  PT_84.txt  Zelensky planeia segunda cimeira de paz em nov...   \n",
       "\n",
       "       entity_mention  start_offset  end_offset    main_role  \\\n",
       "0        Ivar Giaever           937         948  Protagonist   \n",
       "1     John F. Clauser           952         966  Protagonist   \n",
       "2             Ucrânia           857         863     Innocent   \n",
       "3  Volodymyr Zelensky           113         130  Protagonist   \n",
       "4              Rússia           372         377   Antagonist   \n",
       "\n",
       "             sub_roles  \n",
       "0           [Guardian]  \n",
       "1           [Guardian]  \n",
       "2          [Forgotten]  \n",
       "3         [Peacemaker]  \n",
       "4  [Foreign Adversary]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.merge(documents_df, annotations_df, on='article_id')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f45bdcb1-f5ba-448a-b57e-604f584f467b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103861\n"
     ]
    }
   ],
   "source": [
    "def extract_article_id(filename):\n",
    "    number_part = filename.split('_')[-1].split('.')[0]\n",
    "    return number_part\n",
    "\n",
    "print(extract_article_id('EN_UA_103861.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99bf53f1-5c74-4596-bf41-9b6809967ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['article_id'] = dataset['article_id'].apply(extract_article_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cb31718-ca93-41f0-b37e-e6e3f47406c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "      <th>entity_mention</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>main_role</th>\n",
       "      <th>sub_roles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PT</td>\n",
       "      <td>53</td>\n",
       "      <td>Mais de 1600 Cientistas Negam a Emergência Cli...</td>\n",
       "      <td>Ivar Giaever</td>\n",
       "      <td>937</td>\n",
       "      <td>948</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Guardian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PT</td>\n",
       "      <td>53</td>\n",
       "      <td>Mais de 1600 Cientistas Negam a Emergência Cli...</td>\n",
       "      <td>John F. Clauser</td>\n",
       "      <td>952</td>\n",
       "      <td>966</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Guardian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PT</td>\n",
       "      <td>47</td>\n",
       "      <td>Zelensky admite a inevitabilidade da retirada ...</td>\n",
       "      <td>Ucrânia</td>\n",
       "      <td>857</td>\n",
       "      <td>863</td>\n",
       "      <td>Innocent</td>\n",
       "      <td>[Forgotten]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PT</td>\n",
       "      <td>84</td>\n",
       "      <td>Zelensky planeia segunda cimeira de paz em nov...</td>\n",
       "      <td>Volodymyr Zelensky</td>\n",
       "      <td>113</td>\n",
       "      <td>130</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Peacemaker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PT</td>\n",
       "      <td>84</td>\n",
       "      <td>Zelensky planeia segunda cimeira de paz em nov...</td>\n",
       "      <td>Rússia</td>\n",
       "      <td>372</td>\n",
       "      <td>377</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Foreign Adversary]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language article_id                                            content  \\\n",
       "0       PT         53  Mais de 1600 Cientistas Negam a Emergência Cli...   \n",
       "1       PT         53  Mais de 1600 Cientistas Negam a Emergência Cli...   \n",
       "2       PT         47  Zelensky admite a inevitabilidade da retirada ...   \n",
       "3       PT         84  Zelensky planeia segunda cimeira de paz em nov...   \n",
       "4       PT         84  Zelensky planeia segunda cimeira de paz em nov...   \n",
       "\n",
       "       entity_mention  start_offset  end_offset    main_role  \\\n",
       "0        Ivar Giaever           937         948  Protagonist   \n",
       "1     John F. Clauser           952         966  Protagonist   \n",
       "2             Ucrânia           857         863     Innocent   \n",
       "3  Volodymyr Zelensky           113         130  Protagonist   \n",
       "4              Rússia           372         377   Antagonist   \n",
       "\n",
       "             sub_roles  \n",
       "0           [Guardian]  \n",
       "1           [Guardian]  \n",
       "2          [Forgotten]  \n",
       "3         [Peacemaker]  \n",
       "4  [Foreign Adversary]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aa8efed-27c8-4981-9464-1f08a5e9dc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2535, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7b2deab-4216-4afb-b827-143c8d64cbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_role\n",
       "Antagonist     1234\n",
       "Protagonist     737\n",
       "Innocent        564\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['main_role'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24cfb27b-064c-4822-992c-339f1a6d468c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sub_roles\n",
       "Victim               478\n",
       "Foreign Adversary    363\n",
       "Guardian             285\n",
       "Virtuous             218\n",
       "Instigator           207\n",
       "Peacemaker           163\n",
       "Incompetent          144\n",
       "Tyrant               127\n",
       "Conspirator          120\n",
       "Deceiver             112\n",
       "Terrorist            101\n",
       "Corrupt               90\n",
       "Rebel                 60\n",
       "Saboteur              52\n",
       "Exploited             49\n",
       "Underdog              43\n",
       "Traitor               31\n",
       "Scapegoat             26\n",
       "Forgotten             24\n",
       "Bigot                 23\n",
       "Martyr                20\n",
       "Spy                   16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sub_roles'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad79c873-d846-4a57-9e49-e96d4dcc1320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(row, window=150):\n",
    "    content = row['content']\n",
    "    start = int(row['start_offset'])\n",
    "    end = int(row['end_offset'])\n",
    "\n",
    "    words = content.split()\n",
    "\n",
    "    pre_entity_text = content[:start].split()\n",
    "    post_entity_text = content[end + 1:].split()\n",
    "\n",
    "    context_before = \" \".join(pre_entity_text[-window:])\n",
    "    context_after = \" \".join(post_entity_text[:window])\n",
    "\n",
    "    return context_before, context_after\n",
    "\n",
    "dataset['context_before'], dataset['context_after'] = zip(*dataset.apply(get_context, axis=1))\n",
    "dataset['entity_context'] = dataset['context_before'] + \" \" + dataset['entity_mention'] + \" \" + dataset['context_after']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94158214-c5b5-4d90-ac0e-93a586d96d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "      <th>entity_mention</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>main_role</th>\n",
       "      <th>sub_roles</th>\n",
       "      <th>entity_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PT</td>\n",
       "      <td>53</td>\n",
       "      <td>Mais de 1600 Cientistas Negam a Emergência Cli...</td>\n",
       "      <td>Ivar Giaever</td>\n",
       "      <td>937</td>\n",
       "      <td>948</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Guardian]</td>\n",
       "      <td>Mais de 1600 Cientistas Negam a Emergência Cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PT</td>\n",
       "      <td>53</td>\n",
       "      <td>Mais de 1600 Cientistas Negam a Emergência Cli...</td>\n",
       "      <td>John F. Clauser</td>\n",
       "      <td>952</td>\n",
       "      <td>966</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Guardian]</td>\n",
       "      <td>Mais de 1600 Cientistas Negam a Emergência Cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PT</td>\n",
       "      <td>47</td>\n",
       "      <td>Zelensky admite a inevitabilidade da retirada ...</td>\n",
       "      <td>Ucrânia</td>\n",
       "      <td>857</td>\n",
       "      <td>863</td>\n",
       "      <td>Innocent</td>\n",
       "      <td>[Forgotten]</td>\n",
       "      <td>Zelensky admite a inevitabilidade da retirada ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PT</td>\n",
       "      <td>84</td>\n",
       "      <td>Zelensky planeia segunda cimeira de paz em nov...</td>\n",
       "      <td>Volodymyr Zelensky</td>\n",
       "      <td>113</td>\n",
       "      <td>130</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Peacemaker]</td>\n",
       "      <td>Zelensky planeia segunda cimeira de paz em nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PT</td>\n",
       "      <td>84</td>\n",
       "      <td>Zelensky planeia segunda cimeira de paz em nov...</td>\n",
       "      <td>Rússia</td>\n",
       "      <td>372</td>\n",
       "      <td>377</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Foreign Adversary]</td>\n",
       "      <td>Zelensky planeia segunda cimeira de paz em nov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language article_id                                            content  \\\n",
       "0       PT         53  Mais de 1600 Cientistas Negam a Emergência Cli...   \n",
       "1       PT         53  Mais de 1600 Cientistas Negam a Emergência Cli...   \n",
       "2       PT         47  Zelensky admite a inevitabilidade da retirada ...   \n",
       "3       PT         84  Zelensky planeia segunda cimeira de paz em nov...   \n",
       "4       PT         84  Zelensky planeia segunda cimeira de paz em nov...   \n",
       "\n",
       "       entity_mention  start_offset  end_offset    main_role  \\\n",
       "0        Ivar Giaever           937         948  Protagonist   \n",
       "1     John F. Clauser           952         966  Protagonist   \n",
       "2             Ucrânia           857         863     Innocent   \n",
       "3  Volodymyr Zelensky           113         130  Protagonist   \n",
       "4              Rússia           372         377   Antagonist   \n",
       "\n",
       "             sub_roles                                     entity_context  \n",
       "0           [Guardian]  Mais de 1600 Cientistas Negam a Emergência Cli...  \n",
       "1           [Guardian]  Mais de 1600 Cientistas Negam a Emergência Cli...  \n",
       "2          [Forgotten]  Zelensky admite a inevitabilidade da retirada ...  \n",
       "3         [Peacemaker]  Zelensky planeia segunda cimeira de paz em nov...  \n",
       "4  [Foreign Adversary]  Zelensky planeia segunda cimeira de paz em nov...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.drop(columns=['context_before', 'context_after'], inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b2c3cd0-9e79-4960-bfe7-347211a4b48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: python\n",
      "zsh:1: command not found: python\n",
      "zsh:1: command not found: python\n"
     ]
    }
   ],
   "source": [
    "!python -m  spacy download xx_ent_wiki_sm\n",
    "!python -m  spacy download en_core_web_sm\n",
    "!python -m  spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e14061b7-9949-4577-99a2-c13141d617be",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model_map = {\n",
    "    \"BG\": \"xx_ent_wiki_sm\",\n",
    "    \"EN\": \"en_core_web_sm\",\n",
    "    \"HI\": \"xx_ent_wiki_sm\", \n",
    "    \"PT\": \"pt_core_news_sm\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "914ad703-e2ec-4390-b99d-625665779423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5b5ba80-e193-444b-b3da-805d15c4bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "nlp_models = {lang: spacy.load(model) for lang, model in language_model_map.items()}\n",
    "\n",
    "def clean_article(article_text, language_code):\n",
    "    nlp = nlp_models.get(language_code, nlp_models[\"BG\"])\n",
    "\n",
    "    article_text = re.sub(r'http\\S+|www\\S+|https\\S+|[a-zA-Z0-9.-]+\\.com', '', article_text, flags=re.MULTILINE)\n",
    "    doc = nlp(article_text)\n",
    "    cleaned_tokens = [\n",
    "        token.text + token.whitespace_ for token in doc\n",
    "        if not (token.is_space or '@' in token.text or emoji.is_emoji(token.text) or token.like_num)\n",
    "    ]\n",
    "    return \"\".join(cleaned_tokens).strip()\n",
    "\n",
    "dataset[\"entity_context\"] = dataset.apply(lambda row: clean_article(row[\"entity_context\"], row[\"language\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ec178e8-714f-458e-ab77-c7c47177ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "main_role_encoder = LabelEncoder()\n",
    "dataset['main_role_encoded'] = main_role_encoder.fit_transform(dataset['main_role'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36c08761-aea6-4014-b4fe-c75341d7e1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "      <th>entity_mention</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>main_role</th>\n",
       "      <th>sub_roles</th>\n",
       "      <th>entity_context</th>\n",
       "      <th>main_role_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PT</td>\n",
       "      <td>53</td>\n",
       "      <td>Mais de 1600 Cientistas Negam a Emergência Cli...</td>\n",
       "      <td>Ivar Giaever</td>\n",
       "      <td>937</td>\n",
       "      <td>948</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Guardian]</td>\n",
       "      <td>Mais de Cientistas Negam a Emergência Climátic...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PT</td>\n",
       "      <td>53</td>\n",
       "      <td>Mais de 1600 Cientistas Negam a Emergência Cli...</td>\n",
       "      <td>John F. Clauser</td>\n",
       "      <td>952</td>\n",
       "      <td>966</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Guardian]</td>\n",
       "      <td>Mais de Cientistas Negam a Emergência Climátic...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PT</td>\n",
       "      <td>47</td>\n",
       "      <td>Zelensky admite a inevitabilidade da retirada ...</td>\n",
       "      <td>Ucrânia</td>\n",
       "      <td>857</td>\n",
       "      <td>863</td>\n",
       "      <td>Innocent</td>\n",
       "      <td>[Forgotten]</td>\n",
       "      <td>Zelensky admite a inevitabilidade da retirada ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PT</td>\n",
       "      <td>84</td>\n",
       "      <td>Zelensky planeia segunda cimeira de paz em nov...</td>\n",
       "      <td>Volodymyr Zelensky</td>\n",
       "      <td>113</td>\n",
       "      <td>130</td>\n",
       "      <td>Protagonist</td>\n",
       "      <td>[Peacemaker]</td>\n",
       "      <td>Zelensky planeia segunda cimeira de paz em nov...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PT</td>\n",
       "      <td>84</td>\n",
       "      <td>Zelensky planeia segunda cimeira de paz em nov...</td>\n",
       "      <td>Rússia</td>\n",
       "      <td>372</td>\n",
       "      <td>377</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>[Foreign Adversary]</td>\n",
       "      <td>Zelensky planeia segunda cimeira de paz em nov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language article_id                                            content  \\\n",
       "0       PT         53  Mais de 1600 Cientistas Negam a Emergência Cli...   \n",
       "1       PT         53  Mais de 1600 Cientistas Negam a Emergência Cli...   \n",
       "2       PT         47  Zelensky admite a inevitabilidade da retirada ...   \n",
       "3       PT         84  Zelensky planeia segunda cimeira de paz em nov...   \n",
       "4       PT         84  Zelensky planeia segunda cimeira de paz em nov...   \n",
       "\n",
       "       entity_mention  start_offset  end_offset    main_role  \\\n",
       "0        Ivar Giaever           937         948  Protagonist   \n",
       "1     John F. Clauser           952         966  Protagonist   \n",
       "2             Ucrânia           857         863     Innocent   \n",
       "3  Volodymyr Zelensky           113         130  Protagonist   \n",
       "4              Rússia           372         377   Antagonist   \n",
       "\n",
       "             sub_roles                                     entity_context  \\\n",
       "0           [Guardian]  Mais de Cientistas Negam a Emergência Climátic...   \n",
       "1           [Guardian]  Mais de Cientistas Negam a Emergência Climátic...   \n",
       "2          [Forgotten]  Zelensky admite a inevitabilidade da retirada ...   \n",
       "3         [Peacemaker]  Zelensky planeia segunda cimeira de paz em nov...   \n",
       "4  [Foreign Adversary]  Zelensky planeia segunda cimeira de paz em nov...   \n",
       "\n",
       "   main_role_encoded  \n",
       "0                  2  \n",
       "1                  2  \n",
       "2                  1  \n",
       "3                  2  \n",
       "4                  0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f41a0641-7aaa-4397-a5ff-4bf18c54ea3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1602: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaTokenizer\n",
    "\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf686c3c-8caa-4051-a460-b33501d135d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(entity_contexts, max_length=512):\n",
    "    encodings = tokenizer(entity_contexts, truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ba2fee4-18d7-4042-9520-f14df704e713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(data, train_size=0.8, val_size_ratio=0.5):\n",
    "    train, temp = train_test_split(data, train_size=train_size, shuffle=True)\n",
    "    \n",
    "    val_size = (1 - train_size) * val_size_ratio\n",
    "    \n",
    "    test, val = train_test_split(temp, train_size=val_size, shuffle=True)\n",
    "    \n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "429526a4-8d0e-4a27-8c96-20b3b340cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_val, dataset_test = split_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35e61b16-19ce-4090-99ee-ce39c078e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenize_data(dataset_train['entity_context'].tolist())\n",
    "val_encodings = tokenize_data(dataset_val['entity_context'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "935e18f6-c7b0-40be-85f9-98321255a33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_main_roles_truths = dataset_train['main_role_encoded'].tolist()\n",
    "\n",
    "train_main_roles_truths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "846733e2-47aa-403c-b931-cfb9c15f0cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 0, 0, 0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_main_roles_truths = dataset_val['main_role_encoded'].tolist()\n",
    "\n",
    "val_main_roles_truths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "507f2f7e-ba6f-471e-bf2a-3cca43ca0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaModel\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultilingualRoleClassifier(nn.Module):\n",
    "    def __init__(self, main_roles_len):\n",
    "        super(MultilingualRoleClassifier, self).__init__()\n",
    "        self.backbone = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\")\n",
    "        self.main_role_classifier = nn.Linear(self.backbone.config.hidden_size, main_roles_len)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]\n",
    "        main_role_logits = self.main_role_classifier(pooled_output)\n",
    "        return main_role_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5372241a-f15d-4063-8cc9-199a9ca644c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "model_config = {\n",
    "    'batch_size': 8,\n",
    "    'lr': 5e-5\n",
    "}\n",
    "\n",
    "class RoleDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_mask, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_mask[idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "\n",
    "train_dataset = RoleDataset(input_ids=train_encodings['input_ids'],\n",
    "                             attention_mask=train_encodings['attention_mask'],\n",
    "                             labels=train_main_roles_truths\n",
    "                           )\n",
    "train_loader = DataLoader(train_dataset, batch_size=model_config['batch_size'], shuffle=True)\n",
    "\n",
    "val_dataset = RoleDataset(input_ids=val_encodings['input_ids'],\n",
    "                             attention_mask=val_encodings['attention_mask'],\n",
    "                             labels=val_main_roles_truths\n",
    "                           )\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=model_config['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f33531a0-383f-4806-af1d-aefb0c02d34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultilingualRoleClassifier(main_roles_len=len(main_role_encoder.classes_))\n",
    "optimizer = optim.AdamW(model.parameters(), lr=model_config['lr'])\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30bb49b3-b925-4c42-b158-6dcb534ab986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_roberta_layers(model, num_layers_to_freeze=4):\n",
    "  for i in range(num_layers_to_freeze):\n",
    "    for param in model.backbone.encoder.layer[i].parameters():\n",
    "      param.requires_grad = False\n",
    "\n",
    "  for param in model.main_role_classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed627b41-dc8c-4825-9805-94f13b3b2aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_roberta_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7efa5e65-6387-46ae-a585-b1d105e3990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, model, optimizer, num_epochs=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss (Avg): {train_loss/len(train_loader)}, Val Loss (Avg): {val_loss/len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b0516a-e581-4844-8b17-cf2519c37a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_loader, val_loader, model, optimizer, num_epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
